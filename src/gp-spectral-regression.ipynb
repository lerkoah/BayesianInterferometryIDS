{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "x = np.linspace(0,1,50)\n",
    "x_tensor = Variable(torch.from_numpy(x).float())\n",
    "all_index = np.arange(x.shape[0])\n",
    "\n",
    "train_x_index = np.sort(np.random.choice(np.arange(x.shape[0]),11, replace=False))\n",
    "H = np.zeros((x.shape[0], train_x_index.shape[0])).T\n",
    "\n",
    "for q in range(train_x_index.shape[0]):\n",
    "    for p in range(x.shape[0]):\n",
    "        if train_x_index[q] == all_index[p]:\n",
    "            H[q,p] = 1\n",
    "H = H.T\n",
    "\n",
    "train_x = x[train_x_index]\n",
    "train_x = Variable(torch.from_numpy(train_x).float())\n",
    "\n",
    "# True function is sin(2*pi*x) with Gaussian noise N(0,0.04)\n",
    "train_y = Variable(torch.sin(train_x.data * (2 * np.pi)) + torch.randn(train_x.size()) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, W, H):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Our mean function is constant in the interval [-1,1]\n",
    "        self.mean_module = ConstantMean(constant_bounds=(-1, 1))\n",
    "        # We use the RBF kernel as a universal approximator\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-10, 10))\n",
    "        \n",
    "        self.W = torch.from_numpy(W).float()\n",
    "        self.H = torch.from_numpy(H).float()\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "#         print(covar_x.type())\n",
    "#         print(self.W.type())\n",
    "        if self.training:\n",
    "#             print(covar_x.shape)\n",
    "            covar_x = self.H.t().matmul(self.W.t().matmul(covar_x.matmul(self.W.matmul(self.H))))\n",
    "        # Return moddl output as GaussianRandomVariable\n",
    "        return GaussianRandomVariable(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\n",
    "# W = 1*np.ones((train_x.data.shape[0], train_x.data.shape[0]), dtype=np.float)\n",
    "W = np.random.randn(x.shape[0], x.shape[0])\n",
    "W = np.matmul(W.T,W)\n",
    "\n",
    "model = ExactGPModel(x_tensor.data, train_y.data, likelihood, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lerko/anaconda3/lib/python3.6/site-packages/gpytorch/functions/add_diag.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  val = diag.squeeze()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/1000 - Loss: 2.033   log_lengthscale: 0.000   log_noise: 0.000\n",
      "Iter 2/1000 - Loss: 1.934   log_lengthscale: 0.100   log_noise: -0.100\n",
      "Iter 3/1000 - Loss: 2.541   log_lengthscale: 0.200   log_noise: -0.200\n",
      "Iter 4/1000 - Loss: 1.952   log_lengthscale: 0.208   log_noise: -0.297\n",
      "Iter 5/1000 - Loss: 2.214   log_lengthscale: 0.256   log_noise: -0.394\n",
      "Iter 6/1000 - Loss: 2.141   log_lengthscale: 0.272   log_noise: -0.492\n",
      "Iter 7/1000 - Loss: 2.040   log_lengthscale: 0.240   log_noise: -0.588\n",
      "Iter 8/1000 - Loss: 1.900   log_lengthscale: 0.228   log_noise: -0.685\n",
      "Iter 9/1000 - Loss: 2.149   log_lengthscale: 0.222   log_noise: -0.780\n",
      "Iter 10/1000 - Loss: 2.037   log_lengthscale: 0.215   log_noise: -0.874\n",
      "Iter 11/1000 - Loss: 2.186   log_lengthscale: 0.244   log_noise: -0.965\n",
      "Iter 12/1000 - Loss: 1.823   log_lengthscale: 0.293   log_noise: -1.052\n",
      "Iter 13/1000 - Loss: 1.524   log_lengthscale: 0.344   log_noise: -1.137\n",
      "Iter 14/1000 - Loss: 1.604   log_lengthscale: 0.374   log_noise: -1.222\n",
      "Iter 15/1000 - Loss: 1.842   log_lengthscale: 0.395   log_noise: -1.305\n",
      "Iter 16/1000 - Loss: 2.039   log_lengthscale: 0.439   log_noise: -1.382\n",
      "Iter 17/1000 - Loss: 2.018   log_lengthscale: 0.485   log_noise: -1.452\n",
      "Iter 18/1000 - Loss: 2.527   log_lengthscale: 0.505   log_noise: -1.511\n",
      "Iter 19/1000 - Loss: 2.350   log_lengthscale: 0.547   log_noise: -1.555\n",
      "Iter 20/1000 - Loss: 2.211   log_lengthscale: 0.593   log_noise: -1.587\n",
      "Iter 21/1000 - Loss: 2.087   log_lengthscale: 0.636   log_noise: -1.611\n",
      "Iter 22/1000 - Loss: 1.833   log_lengthscale: 0.679   log_noise: -1.623\n",
      "Iter 23/1000 - Loss: 1.821   log_lengthscale: 0.700   log_noise: -1.629\n",
      "Iter 24/1000 - Loss: 1.660   log_lengthscale: 0.718   log_noise: -1.627\n",
      "Iter 25/1000 - Loss: 1.894   log_lengthscale: 0.741   log_noise: -1.621\n",
      "Iter 26/1000 - Loss: 2.164   log_lengthscale: 0.770   log_noise: -1.609\n",
      "Iter 27/1000 - Loss: 2.273   log_lengthscale: 0.813   log_noise: -1.591\n",
      "Iter 28/1000 - Loss: 1.574   log_lengthscale: 0.860   log_noise: -1.565\n",
      "Iter 29/1000 - Loss: 1.835   log_lengthscale: 0.902   log_noise: -1.539\n",
      "Iter 30/1000 - Loss: 2.178   log_lengthscale: 0.957   log_noise: -1.513\n",
      "Iter 31/1000 - Loss: 1.602   log_lengthscale: 1.007   log_noise: -1.484\n",
      "Iter 32/1000 - Loss: 2.260   log_lengthscale: 1.052   log_noise: -1.458\n",
      "Iter 33/1000 - Loss: 1.665   log_lengthscale: 1.102   log_noise: -1.430\n",
      "Iter 34/1000 - Loss: 1.749   log_lengthscale: 1.130   log_noise: -1.404\n",
      "Iter 35/1000 - Loss: 1.627   log_lengthscale: 1.165   log_noise: -1.379\n",
      "Iter 36/1000 - Loss: 1.981   log_lengthscale: 1.210   log_noise: -1.360\n",
      "Iter 37/1000 - Loss: 1.753   log_lengthscale: 1.262   log_noise: -1.340\n",
      "Iter 38/1000 - Loss: 1.629   log_lengthscale: 1.308   log_noise: -1.324\n",
      "Iter 39/1000 - Loss: 1.906   log_lengthscale: 1.341   log_noise: -1.310\n",
      "Iter 40/1000 - Loss: 1.798   log_lengthscale: 1.380   log_noise: -1.297\n",
      "Iter 41/1000 - Loss: 1.854   log_lengthscale: 1.415   log_noise: -1.285\n",
      "Iter 42/1000 - Loss: 1.974   log_lengthscale: 1.453   log_noise: -1.273\n",
      "Iter 43/1000 - Loss: 1.785   log_lengthscale: 1.490   log_noise: -1.262\n",
      "Iter 44/1000 - Loss: 1.941   log_lengthscale: 1.529   log_noise: -1.249\n",
      "Iter 45/1000 - Loss: 2.228   log_lengthscale: 1.567   log_noise: -1.235\n",
      "Iter 46/1000 - Loss: 1.594   log_lengthscale: 1.617   log_noise: -1.216\n",
      "Iter 47/1000 - Loss: 1.561   log_lengthscale: 1.650   log_noise: -1.198\n",
      "Iter 48/1000 - Loss: 1.898   log_lengthscale: 1.683   log_noise: -1.183\n",
      "Iter 49/1000 - Loss: 1.920   log_lengthscale: 1.714   log_noise: -1.167\n",
      "Iter 50/1000 - Loss: 1.563   log_lengthscale: 1.741   log_noise: -1.150\n",
      "Iter 51/1000 - Loss: 2.079   log_lengthscale: 1.781   log_noise: -1.135\n",
      "Iter 52/1000 - Loss: 2.154   log_lengthscale: 1.832   log_noise: -1.115\n",
      "Iter 53/1000 - Loss: 1.868   log_lengthscale: 1.865   log_noise: -1.090\n",
      "Iter 54/1000 - Loss: 1.779   log_lengthscale: 1.890   log_noise: -1.061\n",
      "Iter 55/1000 - Loss: 2.073   log_lengthscale: 1.909   log_noise: -1.032\n",
      "Iter 56/1000 - Loss: 1.831   log_lengthscale: 1.934   log_noise: -1.001\n",
      "Iter 57/1000 - Loss: 2.010   log_lengthscale: 1.970   log_noise: -0.970\n",
      "Iter 58/1000 - Loss: 1.663   log_lengthscale: 2.015   log_noise: -0.938\n",
      "Iter 59/1000 - Loss: 1.984   log_lengthscale: 2.052   log_noise: -0.910\n",
      "Iter 60/1000 - Loss: 1.781   log_lengthscale: 2.081   log_noise: -0.882\n",
      "Iter 61/1000 - Loss: 2.061   log_lengthscale: 2.113   log_noise: -0.857\n",
      "Iter 62/1000 - Loss: 2.037   log_lengthscale: 2.132   log_noise: -0.831\n",
      "Iter 63/1000 - Loss: 1.683   log_lengthscale: 2.139   log_noise: -0.805\n",
      "Iter 64/1000 - Loss: 2.082   log_lengthscale: 2.146   log_noise: -0.786\n",
      "Iter 65/1000 - Loss: 1.972   log_lengthscale: 2.158   log_noise: -0.771\n",
      "Iter 66/1000 - Loss: 1.583   log_lengthscale: 2.178   log_noise: -0.757\n",
      "Iter 67/1000 - Loss: 1.694   log_lengthscale: 2.205   log_noise: -0.752\n",
      "Iter 68/1000 - Loss: 1.891   log_lengthscale: 2.248   log_noise: -0.750\n",
      "Iter 69/1000 - Loss: 1.659   log_lengthscale: 2.289   log_noise: -0.751\n",
      "Iter 70/1000 - Loss: 1.597   log_lengthscale: 2.326   log_noise: -0.756\n",
      "Iter 71/1000 - Loss: 1.868   log_lengthscale: 2.361   log_noise: -0.765\n",
      "Iter 72/1000 - Loss: 1.781   log_lengthscale: 2.401   log_noise: -0.773\n",
      "Iter 73/1000 - Loss: 1.818   log_lengthscale: 2.432   log_noise: -0.782\n",
      "Iter 74/1000 - Loss: 1.901   log_lengthscale: 2.470   log_noise: -0.788\n",
      "Iter 75/1000 - Loss: 1.920   log_lengthscale: 2.499   log_noise: -0.792\n",
      "Iter 76/1000 - Loss: 1.457   log_lengthscale: 2.532   log_noise: -0.793\n",
      "Iter 77/1000 - Loss: 2.025   log_lengthscale: 2.575   log_noise: -0.798\n",
      "Iter 78/1000 - Loss: 1.604   log_lengthscale: 2.627   log_noise: -0.799\n",
      "Iter 79/1000 - Loss: 1.416   log_lengthscale: 2.672   log_noise: -0.800\n",
      "Iter 80/1000 - Loss: 1.633   log_lengthscale: 2.721   log_noise: -0.804\n",
      "Iter 81/1000 - Loss: 1.372   log_lengthscale: 2.770   log_noise: -0.808\n",
      "Iter 82/1000 - Loss: 1.644   log_lengthscale: 2.810   log_noise: -0.817\n",
      "Iter 83/1000 - Loss: 1.879   log_lengthscale: 2.844   log_noise: -0.825\n",
      "Iter 84/1000 - Loss: 1.451   log_lengthscale: 2.894   log_noise: -0.827\n",
      "Iter 85/1000 - Loss: 1.693   log_lengthscale: 2.946   log_noise: -0.829\n",
      "Iter 86/1000 - Loss: 1.715   log_lengthscale: 2.991   log_noise: -0.830\n",
      "Iter 87/1000 - Loss: 1.694   log_lengthscale: 3.025   log_noise: -0.827\n",
      "Iter 88/1000 - Loss: 1.692   log_lengthscale: 3.055   log_noise: -0.823\n",
      "Iter 89/1000 - Loss: 1.582   log_lengthscale: 3.079   log_noise: -0.818\n",
      "Iter 90/1000 - Loss: 1.591   log_lengthscale: 3.106   log_noise: -0.813\n",
      "Iter 91/1000 - Loss: 1.554   log_lengthscale: 3.126   log_noise: -0.805\n",
      "Iter 92/1000 - Loss: 2.021   log_lengthscale: 3.154   log_noise: -0.799\n",
      "Iter 93/1000 - Loss: 1.557   log_lengthscale: 3.175   log_noise: -0.791\n",
      "Iter 94/1000 - Loss: 1.519   log_lengthscale: 3.200   log_noise: -0.786\n",
      "Iter 95/1000 - Loss: 1.989   log_lengthscale: 3.238   log_noise: -0.784\n",
      "Iter 96/1000 - Loss: 1.714   log_lengthscale: 3.258   log_noise: -0.782\n",
      "Iter 97/1000 - Loss: 1.670   log_lengthscale: 3.281   log_noise: -0.779\n",
      "Iter 98/1000 - Loss: 1.970   log_lengthscale: 3.289   log_noise: -0.779\n",
      "Iter 99/1000 - Loss: 1.684   log_lengthscale: 3.279   log_noise: -0.775\n",
      "Iter 100/1000 - Loss: 1.650   log_lengthscale: 3.248   log_noise: -0.773\n",
      "Iter 101/1000 - Loss: 1.640   log_lengthscale: 3.229   log_noise: -0.772\n",
      "Iter 102/1000 - Loss: 1.793   log_lengthscale: 3.207   log_noise: -0.773\n",
      "Iter 103/1000 - Loss: 1.735   log_lengthscale: 3.189   log_noise: -0.770\n",
      "Iter 104/1000 - Loss: 1.847   log_lengthscale: 3.163   log_noise: -0.770\n",
      "Iter 105/1000 - Loss: 1.663   log_lengthscale: 3.168   log_noise: -0.767\n",
      "Iter 106/1000 - Loss: 1.826   log_lengthscale: 3.169   log_noise: -0.764\n",
      "Iter 107/1000 - Loss: 1.471   log_lengthscale: 3.169   log_noise: -0.762\n",
      "Iter 108/1000 - Loss: 1.659   log_lengthscale: 3.161   log_noise: -0.765\n",
      "Iter 109/1000 - Loss: 1.596   log_lengthscale: 3.144   log_noise: -0.768\n",
      "Iter 110/1000 - Loss: 2.085   log_lengthscale: 3.114   log_noise: -0.773\n",
      "Iter 111/1000 - Loss: 1.715   log_lengthscale: 3.080   log_noise: -0.773\n",
      "Iter 112/1000 - Loss: 2.168   log_lengthscale: 3.064   log_noise: -0.773\n",
      "Iter 113/1000 - Loss: 1.651   log_lengthscale: 3.032   log_noise: -0.770\n",
      "Iter 114/1000 - Loss: 1.712   log_lengthscale: 3.015   log_noise: -0.771\n",
      "Iter 115/1000 - Loss: 1.934   log_lengthscale: 2.983   log_noise: -0.772\n",
      "Iter 116/1000 - Loss: 1.482   log_lengthscale: 2.946   log_noise: -0.769\n",
      "Iter 117/1000 - Loss: 1.427   log_lengthscale: 2.903   log_noise: -0.775\n",
      "Iter 118/1000 - Loss: 1.668   log_lengthscale: 2.863   log_noise: -0.784\n",
      "Iter 119/1000 - Loss: 1.732   log_lengthscale: 2.830   log_noise: -0.796\n",
      "Iter 120/1000 - Loss: 1.827   log_lengthscale: 2.794   log_noise: -0.807\n",
      "Iter 121/1000 - Loss: 1.990   log_lengthscale: 2.781   log_noise: -0.814\n",
      "Iter 122/1000 - Loss: 1.480   log_lengthscale: 2.766   log_noise: -0.818\n",
      "Iter 123/1000 - Loss: 1.940   log_lengthscale: 2.779   log_noise: -0.825\n",
      "Iter 124/1000 - Loss: 1.816   log_lengthscale: 2.787   log_noise: -0.828\n",
      "Iter 125/1000 - Loss: 1.962   log_lengthscale: 2.792   log_noise: -0.830\n",
      "Iter 126/1000 - Loss: 1.743   log_lengthscale: 2.783   log_noise: -0.829\n",
      "Iter 127/1000 - Loss: 1.475   log_lengthscale: 2.789   log_noise: -0.825\n",
      "Iter 128/1000 - Loss: 1.682   log_lengthscale: 2.791   log_noise: -0.825\n",
      "Iter 129/1000 - Loss: 1.707   log_lengthscale: 2.805   log_noise: -0.827\n",
      "Iter 130/1000 - Loss: 1.546   log_lengthscale: 2.813   log_noise: -0.826\n",
      "Iter 131/1000 - Loss: 1.790   log_lengthscale: 2.820   log_noise: -0.827\n",
      "Iter 132/1000 - Loss: 1.957   log_lengthscale: 2.828   log_noise: -0.827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 133/1000 - Loss: 1.664   log_lengthscale: 2.837   log_noise: -0.823\n",
      "Iter 134/1000 - Loss: 1.582   log_lengthscale: 2.845   log_noise: -0.819\n",
      "Iter 135/1000 - Loss: 1.720   log_lengthscale: 2.855   log_noise: -0.816\n",
      "Iter 136/1000 - Loss: 1.574   log_lengthscale: 2.860   log_noise: -0.812\n",
      "Iter 137/1000 - Loss: 1.850   log_lengthscale: 2.875   log_noise: -0.810\n",
      "Iter 138/1000 - Loss: 1.886   log_lengthscale: 2.899   log_noise: -0.804\n",
      "Iter 139/1000 - Loss: 1.648   log_lengthscale: 2.936   log_noise: -0.790\n",
      "Iter 140/1000 - Loss: 1.947   log_lengthscale: 2.977   log_noise: -0.777\n",
      "Iter 141/1000 - Loss: 2.062   log_lengthscale: 2.999   log_noise: -0.764\n",
      "Iter 142/1000 - Loss: 2.109   log_lengthscale: 3.021   log_noise: -0.747\n",
      "Iter 143/1000 - Loss: 1.868   log_lengthscale: 3.044   log_noise: -0.730\n",
      "Iter 144/1000 - Loss: 1.537   log_lengthscale: 3.054   log_noise: -0.717\n",
      "Iter 145/1000 - Loss: 1.360   log_lengthscale: 3.063   log_noise: -0.712\n",
      "Iter 146/1000 - Loss: 1.822   log_lengthscale: 3.057   log_noise: -0.719\n",
      "Iter 147/1000 - Loss: 2.093   log_lengthscale: 3.041   log_noise: -0.726\n",
      "Iter 148/1000 - Loss: 1.648   log_lengthscale: 3.026   log_noise: -0.731\n",
      "Iter 149/1000 - Loss: 2.328   log_lengthscale: 3.026   log_noise: -0.738\n",
      "Iter 150/1000 - Loss: 1.603   log_lengthscale: 3.038   log_noise: -0.736\n",
      "Iter 151/1000 - Loss: 1.971   log_lengthscale: 3.047   log_noise: -0.739\n",
      "Iter 152/1000 - Loss: 1.403   log_lengthscale: 3.049   log_noise: -0.739\n",
      "Iter 153/1000 - Loss: 1.637   log_lengthscale: 3.062   log_noise: -0.748\n",
      "Iter 154/1000 - Loss: 1.448   log_lengthscale: 3.077   log_noise: -0.761\n",
      "Iter 155/1000 - Loss: 1.620   log_lengthscale: 3.111   log_noise: -0.781\n",
      "Iter 156/1000 - Loss: 1.619   log_lengthscale: 3.144   log_noise: -0.802\n",
      "Iter 157/1000 - Loss: 1.804   log_lengthscale: 3.174   log_noise: -0.822\n",
      "Iter 158/1000 - Loss: 1.572   log_lengthscale: 3.212   log_noise: -0.836\n",
      "Iter 159/1000 - Loss: 1.762   log_lengthscale: 3.237   log_noise: -0.845\n",
      "Iter 160/1000 - Loss: 1.476   log_lengthscale: 3.249   log_noise: -0.850\n",
      "Iter 161/1000 - Loss: 1.985   log_lengthscale: 3.263   log_noise: -0.853\n",
      "Iter 162/1000 - Loss: 1.617   log_lengthscale: 3.285   log_noise: -0.847\n",
      "Iter 163/1000 - Loss: 2.152   log_lengthscale: 3.300   log_noise: -0.840\n",
      "Iter 164/1000 - Loss: 1.852   log_lengthscale: 3.363   log_noise: -0.818\n",
      "Iter 165/1000 - Loss: 1.661   log_lengthscale: 3.411   log_noise: -0.796\n",
      "Iter 166/1000 - Loss: 1.786   log_lengthscale: 3.461   log_noise: -0.778\n",
      "Iter 167/1000 - Loss: 1.531   log_lengthscale: 3.520   log_noise: -0.757\n",
      "Iter 168/1000 - Loss: 1.813   log_lengthscale: 3.577   log_noise: -0.746\n",
      "Iter 169/1000 - Loss: 1.409   log_lengthscale: 3.643   log_noise: -0.736\n",
      "Iter 170/1000 - Loss: 1.848   log_lengthscale: 3.722   log_noise: -0.734\n",
      "Iter 171/1000 - Loss: 1.534   log_lengthscale: 3.803   log_noise: -0.732\n",
      "Iter 172/1000 - Loss: 1.644   log_lengthscale: 3.862   log_noise: -0.737\n",
      "Iter 173/1000 - Loss: 1.594   log_lengthscale: 3.922   log_noise: -0.747\n",
      "Iter 174/1000 - Loss: 1.765   log_lengthscale: 3.982   log_noise: -0.760\n",
      "Iter 175/1000 - Loss: 1.475   log_lengthscale: 4.028   log_noise: -0.773\n",
      "Iter 176/1000 - Loss: 1.742   log_lengthscale: 4.057   log_noise: -0.789\n",
      "Iter 177/1000 - Loss: 1.574   log_lengthscale: 4.081   log_noise: -0.803\n",
      "Iter 178/1000 - Loss: 1.880   log_lengthscale: 4.126   log_noise: -0.820\n",
      "Iter 179/1000 - Loss: 1.573   log_lengthscale: 4.165   log_noise: -0.831\n",
      "Iter 180/1000 - Loss: 1.548   log_lengthscale: 4.199   log_noise: -0.839\n",
      "Iter 181/1000 - Loss: 1.365   log_lengthscale: 4.250   log_noise: -0.845\n",
      "Iter 182/1000 - Loss: 1.557   log_lengthscale: 4.292   log_noise: -0.853\n",
      "Iter 183/1000 - Loss: 1.311   log_lengthscale: 4.335   log_noise: -0.859\n",
      "Iter 184/1000 - Loss: 1.574   log_lengthscale: 4.360   log_noise: -0.868\n",
      "Iter 185/1000 - Loss: 1.534   log_lengthscale: 4.389   log_noise: -0.872\n",
      "Iter 186/1000 - Loss: 1.487   log_lengthscale: 4.396   log_noise: -0.874\n",
      "Iter 187/1000 - Loss: 1.542   log_lengthscale: 4.394   log_noise: -0.874\n",
      "Iter 188/1000 - Loss: 1.929   log_lengthscale: 4.407   log_noise: -0.871\n",
      "Iter 189/1000 - Loss: 1.813   log_lengthscale: 4.395   log_noise: -0.858\n",
      "Iter 190/1000 - Loss: 1.793   log_lengthscale: 4.360   log_noise: -0.839\n",
      "Iter 191/1000 - Loss: 1.408   log_lengthscale: 4.322   log_noise: -0.816\n",
      "Iter 192/1000 - Loss: 1.927   log_lengthscale: 4.291   log_noise: -0.796\n",
      "Iter 193/1000 - Loss: 1.433   log_lengthscale: 4.271   log_noise: -0.773\n",
      "Iter 194/1000 - Loss: 1.952   log_lengthscale: 4.237   log_noise: -0.760\n",
      "Iter 195/1000 - Loss: 1.739   log_lengthscale: 4.203   log_noise: -0.749\n",
      "Iter 196/1000 - Loss: 1.550   log_lengthscale: 4.160   log_noise: -0.741\n",
      "Iter 197/1000 - Loss: 1.599   log_lengthscale: 4.119   log_noise: -0.737\n",
      "Iter 198/1000 - Loss: 1.508   log_lengthscale: 4.084   log_noise: -0.737\n",
      "Iter 199/1000 - Loss: 1.440   log_lengthscale: 4.020   log_noise: -0.744\n",
      "Iter 200/1000 - Loss: 1.440   log_lengthscale: 3.970   log_noise: -0.760\n",
      "Iter 201/1000 - Loss: 1.420   log_lengthscale: 3.909   log_noise: -0.783\n",
      "Iter 202/1000 - Loss: 1.692   log_lengthscale: 3.861   log_noise: -0.809\n",
      "Iter 203/1000 - Loss: 1.370   log_lengthscale: 3.805   log_noise: -0.831\n",
      "Iter 204/1000 - Loss: 2.327   log_lengthscale: 3.749   log_noise: -0.853\n",
      "Iter 205/1000 - Loss: 1.477   log_lengthscale: 3.704   log_noise: -0.858\n",
      "Iter 206/1000 - Loss: 1.624   log_lengthscale: 3.671   log_noise: -0.862\n",
      "Iter 207/1000 - Loss: 1.667   log_lengthscale: 3.661   log_noise: -0.861\n",
      "Iter 208/1000 - Loss: 1.678   log_lengthscale: 3.674   log_noise: -0.855\n",
      "Iter 209/1000 - Loss: 1.835   log_lengthscale: 3.685   log_noise: -0.847\n",
      "Iter 210/1000 - Loss: 1.858   log_lengthscale: 3.712   log_noise: -0.832\n",
      "Iter 211/1000 - Loss: 1.878   log_lengthscale: 3.723   log_noise: -0.812\n",
      "Iter 212/1000 - Loss: 1.530   log_lengthscale: 3.743   log_noise: -0.789\n",
      "Iter 213/1000 - Loss: 1.679   log_lengthscale: 3.777   log_noise: -0.769\n",
      "Iter 214/1000 - Loss: 1.238   log_lengthscale: 3.812   log_noise: -0.754\n",
      "Iter 215/1000 - Loss: 1.789   log_lengthscale: 3.833   log_noise: -0.752\n",
      "Iter 216/1000 - Loss: 1.506   log_lengthscale: 3.864   log_noise: -0.751\n",
      "Iter 217/1000 - Loss: 1.680   log_lengthscale: 3.901   log_noise: -0.757\n",
      "Iter 218/1000 - Loss: 1.541   log_lengthscale: 3.938   log_noise: -0.764\n",
      "Iter 219/1000 - Loss: 1.742   log_lengthscale: 3.981   log_noise: -0.774\n",
      "Iter 220/1000 - Loss: 1.484   log_lengthscale: 4.013   log_noise: -0.785\n",
      "Iter 221/1000 - Loss: 1.643   log_lengthscale: 4.060   log_noise: -0.801\n",
      "Iter 222/1000 - Loss: 1.502   log_lengthscale: 4.086   log_noise: -0.820\n",
      "Iter 223/1000 - Loss: 1.841   log_lengthscale: 4.084   log_noise: -0.838\n",
      "Iter 224/1000 - Loss: 1.335   log_lengthscale: 4.083   log_noise: -0.846\n",
      "Iter 225/1000 - Loss: 1.369   log_lengthscale: 4.087   log_noise: -0.856\n",
      "Iter 226/1000 - Loss: 1.220   log_lengthscale: 4.084   log_noise: -0.866\n",
      "Iter 227/1000 - Loss: 1.572   log_lengthscale: 4.089   log_noise: -0.879\n",
      "Iter 228/1000 - Loss: 1.781   log_lengthscale: 4.114   log_noise: -0.887\n",
      "Iter 229/1000 - Loss: 2.149   log_lengthscale: 4.139   log_noise: -0.889\n",
      "Iter 230/1000 - Loss: 1.752   log_lengthscale: 4.143   log_noise: -0.872\n",
      "Iter 231/1000 - Loss: 1.839   log_lengthscale: 4.160   log_noise: -0.850\n",
      "Iter 232/1000 - Loss: 1.538   log_lengthscale: 4.163   log_noise: -0.824\n",
      "Iter 233/1000 - Loss: 1.792   log_lengthscale: 4.175   log_noise: -0.800\n",
      "Iter 234/1000 - Loss: 1.641   log_lengthscale: 4.180   log_noise: -0.777\n",
      "Iter 235/1000 - Loss: 2.038   log_lengthscale: 4.174   log_noise: -0.760\n",
      "Iter 236/1000 - Loss: 1.708   log_lengthscale: 4.183   log_noise: -0.740\n",
      "Iter 237/1000 - Loss: 2.175   log_lengthscale: 4.199   log_noise: -0.722\n",
      "Iter 238/1000 - Loss: 1.750   log_lengthscale: 4.206   log_noise: -0.702\n",
      "Iter 239/1000 - Loss: 1.953   log_lengthscale: 4.216   log_noise: -0.688\n",
      "Iter 240/1000 - Loss: 1.513   log_lengthscale: 4.227   log_noise: -0.678\n",
      "Iter 241/1000 - Loss: 1.786   log_lengthscale: 4.241   log_noise: -0.683\n",
      "Iter 242/1000 - Loss: 1.889   log_lengthscale: 4.245   log_noise: -0.694\n",
      "Iter 243/1000 - Loss: 1.723   log_lengthscale: 4.258   log_noise: -0.707\n",
      "Iter 244/1000 - Loss: 1.465   log_lengthscale: 4.294   log_noise: -0.723\n",
      "Iter 245/1000 - Loss: 1.793   log_lengthscale: 4.329   log_noise: -0.747\n",
      "Iter 246/1000 - Loss: 1.843   log_lengthscale: 4.375   log_noise: -0.769\n",
      "Iter 247/1000 - Loss: 1.743   log_lengthscale: 4.417   log_noise: -0.787\n",
      "Iter 248/1000 - Loss: 1.681   log_lengthscale: 4.454   log_noise: -0.805\n",
      "Iter 249/1000 - Loss: 1.357   log_lengthscale: 4.493   log_noise: -0.824\n",
      "Iter 250/1000 - Loss: 1.346   log_lengthscale: 4.526   log_noise: -0.846\n",
      "Iter 251/1000 - Loss: 1.454   log_lengthscale: 4.549   log_noise: -0.868\n",
      "Iter 252/1000 - Loss: 1.504   log_lengthscale: 4.571   log_noise: -0.888\n",
      "Iter 253/1000 - Loss: 1.633   log_lengthscale: 4.590   log_noise: -0.904\n",
      "Iter 254/1000 - Loss: 1.811   log_lengthscale: 4.611   log_noise: -0.911\n",
      "Iter 255/1000 - Loss: 1.466   log_lengthscale: 4.620   log_noise: -0.906\n",
      "Iter 256/1000 - Loss: 1.278   log_lengthscale: 4.613   log_noise: -0.898\n",
      "Iter 257/1000 - Loss: 1.524   log_lengthscale: 4.618   log_noise: -0.892\n",
      "Iter 258/1000 - Loss: 1.677   log_lengthscale: 4.626   log_noise: -0.884\n",
      "Iter 259/1000 - Loss: 1.745   log_lengthscale: 4.649   log_noise: -0.871\n",
      "Iter 260/1000 - Loss: 1.706   log_lengthscale: 4.673   log_noise: -0.853\n",
      "Iter 261/1000 - Loss: 1.392   log_lengthscale: 4.696   log_noise: -0.832\n",
      "Iter 262/1000 - Loss: 1.507   log_lengthscale: 4.739   log_noise: -0.817\n",
      "Iter 263/1000 - Loss: 1.504   log_lengthscale: 4.797   log_noise: -0.805\n",
      "Iter 264/1000 - Loss: 1.557   log_lengthscale: 4.842   log_noise: -0.799\n",
      "Iter 265/1000 - Loss: 1.588   log_lengthscale: 4.874   log_noise: -0.799\n",
      "Iter 266/1000 - Loss: 1.348   log_lengthscale: 4.911   log_noise: -0.802\n",
      "Iter 267/1000 - Loss: 1.824   log_lengthscale: 4.933   log_noise: -0.812\n",
      "Iter 268/1000 - Loss: 1.546   log_lengthscale: 4.944   log_noise: -0.817\n",
      "Iter 269/1000 - Loss: 1.603   log_lengthscale: 4.949   log_noise: -0.816\n",
      "Iter 270/1000 - Loss: 1.436   log_lengthscale: 4.947   log_noise: -0.816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 271/1000 - Loss: 1.649   log_lengthscale: 4.946   log_noise: -0.824\n",
      "Iter 272/1000 - Loss: 1.892   log_lengthscale: 4.944   log_noise: -0.829\n",
      "Iter 273/1000 - Loss: 1.550   log_lengthscale: 4.945   log_noise: -0.828\n",
      "Iter 274/1000 - Loss: 1.849   log_lengthscale: 4.942   log_noise: -0.829\n",
      "Iter 275/1000 - Loss: 1.800   log_lengthscale: 4.934   log_noise: -0.823\n",
      "Iter 276/1000 - Loss: 1.552   log_lengthscale: 4.926   log_noise: -0.815\n",
      "Iter 277/1000 - Loss: 1.550   log_lengthscale: 4.919   log_noise: -0.809\n",
      "Iter 278/1000 - Loss: 1.295   log_lengthscale: 4.909   log_noise: -0.807\n",
      "Iter 279/1000 - Loss: 1.414   log_lengthscale: 4.902   log_noise: -0.812\n",
      "Iter 280/1000 - Loss: 1.353   log_lengthscale: 4.897   log_noise: -0.822\n",
      "Iter 281/1000 - Loss: 1.307   log_lengthscale: 4.892   log_noise: -0.837\n",
      "Iter 282/1000 - Loss: 1.969   log_lengthscale: 4.897   log_noise: -0.856\n",
      "Iter 283/1000 - Loss: 1.670   log_lengthscale: 4.892   log_noise: -0.861\n",
      "Iter 284/1000 - Loss: 1.235   log_lengthscale: 4.882   log_noise: -0.859\n",
      "Iter 285/1000 - Loss: 1.857   log_lengthscale: 4.871   log_noise: -0.864\n",
      "Iter 286/1000 - Loss: 1.345   log_lengthscale: 4.870   log_noise: -0.857\n",
      "Iter 287/1000 - Loss: 1.401   log_lengthscale: 4.869   log_noise: -0.851\n",
      "Iter 288/1000 - Loss: 1.666   log_lengthscale: 4.872   log_noise: -0.849\n",
      "Iter 289/1000 - Loss: 2.079   log_lengthscale: 4.878   log_noise: -0.841\n",
      "Iter 290/1000 - Loss: 1.459   log_lengthscale: 4.880   log_noise: -0.821\n",
      "Iter 291/1000 - Loss: 1.454   log_lengthscale: 4.901   log_noise: -0.805\n",
      "Iter 292/1000 - Loss: 1.891   log_lengthscale: 4.918   log_noise: -0.797\n",
      "Iter 293/1000 - Loss: 1.893   log_lengthscale: 4.934   log_noise: -0.783\n",
      "Iter 294/1000 - Loss: 1.706   log_lengthscale: 4.955   log_noise: -0.767\n",
      "Iter 295/1000 - Loss: 1.534   log_lengthscale: 4.985   log_noise: -0.754\n",
      "Iter 296/1000 - Loss: 1.351   log_lengthscale: 5.014   log_noise: -0.746\n",
      "Iter 297/1000 - Loss: 1.654   log_lengthscale: 5.039   log_noise: -0.749\n",
      "Iter 298/1000 - Loss: 1.617   log_lengthscale: 5.066   log_noise: -0.755\n",
      "Iter 299/1000 - Loss: 1.287   log_lengthscale: 5.094   log_noise: -0.768\n",
      "Iter 300/1000 - Loss: 1.930   log_lengthscale: 5.101   log_noise: -0.792\n",
      "Iter 301/1000 - Loss: 1.590   log_lengthscale: 5.103   log_noise: -0.810\n",
      "Iter 302/1000 - Loss: 1.648   log_lengthscale: 5.098   log_noise: -0.824\n",
      "Iter 303/1000 - Loss: 1.308   log_lengthscale: 5.102   log_noise: -0.833\n",
      "Iter 304/1000 - Loss: 1.625   log_lengthscale: 5.111   log_noise: -0.845\n",
      "Iter 305/1000 - Loss: 1.662   log_lengthscale: 5.107   log_noise: -0.853\n",
      "Iter 306/1000 - Loss: 1.599   log_lengthscale: 5.097   log_noise: -0.860\n",
      "Iter 307/1000 - Loss: 1.694   log_lengthscale: 5.092   log_noise: -0.861\n",
      "Iter 308/1000 - Loss: 1.437   log_lengthscale: 5.084   log_noise: -0.855\n",
      "Iter 309/1000 - Loss: 1.762   log_lengthscale: 5.078   log_noise: -0.851\n",
      "Iter 310/1000 - Loss: 1.812   log_lengthscale: 5.069   log_noise: -0.839\n",
      "Iter 311/1000 - Loss: 1.713   log_lengthscale: 5.061   log_noise: -0.823\n",
      "Iter 312/1000 - Loss: 1.336   log_lengthscale: 5.038   log_noise: -0.803\n",
      "Iter 313/1000 - Loss: 1.373   log_lengthscale: 5.017   log_noise: -0.790\n",
      "Iter 314/1000 - Loss: 1.502   log_lengthscale: 5.009   log_noise: -0.786\n",
      "Iter 315/1000 - Loss: 1.964   log_lengthscale: 5.012   log_noise: -0.787\n",
      "Iter 316/1000 - Loss: 1.475   log_lengthscale: 5.015   log_noise: -0.784\n",
      "Iter 317/1000 - Loss: 1.784   log_lengthscale: 5.023   log_noise: -0.788\n",
      "Iter 318/1000 - Loss: 1.767   log_lengthscale: 5.034   log_noise: -0.794\n",
      "Iter 319/1000 - Loss: 1.523   log_lengthscale: 5.056   log_noise: -0.791\n",
      "Iter 320/1000 - Loss: 1.264   log_lengthscale: 5.082   log_noise: -0.792\n",
      "Iter 321/1000 - Loss: 1.380   log_lengthscale: 5.095   log_noise: -0.805\n",
      "Iter 322/1000 - Loss: 1.749   log_lengthscale: 5.110   log_noise: -0.822\n",
      "Iter 323/1000 - Loss: 1.675   log_lengthscale: 5.133   log_noise: -0.833\n",
      "Iter 324/1000 - Loss: 1.666   log_lengthscale: 5.156   log_noise: -0.839\n",
      "Iter 325/1000 - Loss: 1.645   log_lengthscale: 5.175   log_noise: -0.841\n",
      "Iter 326/1000 - Loss: 2.065   log_lengthscale: 5.187   log_noise: -0.837\n",
      "Iter 327/1000 - Loss: 1.386   log_lengthscale: 5.194   log_noise: -0.821\n",
      "Iter 328/1000 - Loss: 1.386   log_lengthscale: 5.191   log_noise: -0.811\n",
      "Iter 329/1000 - Loss: 1.521   log_lengthscale: 5.183   log_noise: -0.804\n",
      "Iter 330/1000 - Loss: 1.382   log_lengthscale: 5.183   log_noise: -0.801\n",
      "Iter 331/1000 - Loss: 1.616   log_lengthscale: 5.184   log_noise: -0.808\n",
      "Iter 332/1000 - Loss: 1.679   log_lengthscale: 5.178   log_noise: -0.813\n",
      "Iter 333/1000 - Loss: 1.727   log_lengthscale: 5.175   log_noise: -0.813\n",
      "Iter 334/1000 - Loss: 1.810   log_lengthscale: 5.170   log_noise: -0.806\n",
      "Iter 335/1000 - Loss: 1.451   log_lengthscale: 5.170   log_noise: -0.795\n",
      "Iter 336/1000 - Loss: 1.366   log_lengthscale: 5.162   log_noise: -0.788\n",
      "Iter 337/1000 - Loss: 1.556   log_lengthscale: 5.158   log_noise: -0.785\n",
      "Iter 338/1000 - Loss: 1.438   log_lengthscale: 5.152   log_noise: -0.787\n",
      "Iter 339/1000 - Loss: 1.574   log_lengthscale: 5.143   log_noise: -0.793\n",
      "Iter 340/1000 - Loss: 1.416   log_lengthscale: 5.145   log_noise: -0.798\n",
      "Iter 341/1000 - Loss: 1.796   log_lengthscale: 5.148   log_noise: -0.808\n",
      "Iter 342/1000 - Loss: 1.560   log_lengthscale: 5.151   log_noise: -0.815\n",
      "Iter 343/1000 - Loss: 1.829   log_lengthscale: 5.161   log_noise: -0.822\n",
      "Iter 344/1000 - Loss: 1.411   log_lengthscale: 5.167   log_noise: -0.824\n",
      "Iter 345/1000 - Loss: 1.399   log_lengthscale: 5.165   log_noise: -0.828\n",
      "Iter 346/1000 - Loss: 1.425   log_lengthscale: 5.155   log_noise: -0.832\n",
      "Iter 347/1000 - Loss: 1.415   log_lengthscale: 5.145   log_noise: -0.837\n",
      "Iter 348/1000 - Loss: 1.233   log_lengthscale: 5.139   log_noise: -0.839\n",
      "Iter 349/1000 - Loss: 1.757   log_lengthscale: 5.138   log_noise: -0.847\n",
      "Iter 350/1000 - Loss: 1.740   log_lengthscale: 5.131   log_noise: -0.850\n",
      "Iter 351/1000 - Loss: 1.536   log_lengthscale: 5.139   log_noise: -0.849\n",
      "Iter 352/1000 - Loss: 1.420   log_lengthscale: 5.151   log_noise: -0.843\n",
      "Iter 353/1000 - Loss: 1.789   log_lengthscale: 5.171   log_noise: -0.840\n",
      "Iter 354/1000 - Loss: 1.427   log_lengthscale: 5.181   log_noise: -0.830\n",
      "Iter 355/1000 - Loss: 1.793   log_lengthscale: 5.189   log_noise: -0.825\n",
      "Iter 356/1000 - Loss: 1.703   log_lengthscale: 5.200   log_noise: -0.808\n",
      "Iter 357/1000 - Loss: 1.890   log_lengthscale: 5.209   log_noise: -0.794\n",
      "Iter 358/1000 - Loss: 1.831   log_lengthscale: 5.232   log_noise: -0.772\n",
      "Iter 359/1000 - Loss: 1.733   log_lengthscale: 5.255   log_noise: -0.753\n",
      "Iter 360/1000 - Loss: 1.568   log_lengthscale: 5.270   log_noise: -0.740\n",
      "Iter 361/1000 - Loss: 1.423   log_lengthscale: 5.280   log_noise: -0.735\n",
      "Iter 362/1000 - Loss: 1.469   log_lengthscale: 5.290   log_noise: -0.744\n",
      "Iter 363/1000 - Loss: 1.914   log_lengthscale: 5.306   log_noise: -0.760\n",
      "Iter 364/1000 - Loss: 1.755   log_lengthscale: 5.325   log_noise: -0.770\n",
      "Iter 365/1000 - Loss: 1.664   log_lengthscale: 5.343   log_noise: -0.778\n",
      "Iter 366/1000 - Loss: 1.542   log_lengthscale: 5.357   log_noise: -0.784\n",
      "Iter 367/1000 - Loss: 1.377   log_lengthscale: 5.370   log_noise: -0.791\n",
      "Iter 368/1000 - Loss: 1.969   log_lengthscale: 5.382   log_noise: -0.808\n",
      "Iter 369/1000 - Loss: 1.612   log_lengthscale: 5.395   log_noise: -0.812\n",
      "Iter 370/1000 - Loss: 1.922   log_lengthscale: 5.408   log_noise: -0.813\n",
      "Iter 371/1000 - Loss: 1.459   log_lengthscale: 5.412   log_noise: -0.808\n",
      "Iter 372/1000 - Loss: 1.925   log_lengthscale: 5.415   log_noise: -0.803\n",
      "Iter 373/1000 - Loss: 1.721   log_lengthscale: 5.411   log_noise: -0.793\n",
      "Iter 374/1000 - Loss: 1.659   log_lengthscale: 5.410   log_noise: -0.786\n",
      "Iter 375/1000 - Loss: 1.881   log_lengthscale: 5.411   log_noise: -0.775\n",
      "Iter 376/1000 - Loss: 1.568   log_lengthscale: 5.418   log_noise: -0.761\n",
      "Iter 377/1000 - Loss: 1.438   log_lengthscale: 5.419   log_noise: -0.750\n",
      "Iter 378/1000 - Loss: 1.632   log_lengthscale: 5.424   log_noise: -0.751\n",
      "Iter 379/1000 - Loss: 1.450   log_lengthscale: 5.424   log_noise: -0.754\n",
      "Iter 380/1000 - Loss: 1.363   log_lengthscale: 5.423   log_noise: -0.765\n",
      "Iter 381/1000 - Loss: 1.218   log_lengthscale: 5.414   log_noise: -0.787\n",
      "Iter 382/1000 - Loss: 1.582   log_lengthscale: 5.406   log_noise: -0.819\n",
      "Iter 383/1000 - Loss: 1.770   log_lengthscale: 5.407   log_noise: -0.848\n",
      "Iter 384/1000 - Loss: 1.456   log_lengthscale: 5.415   log_noise: -0.864\n",
      "Iter 385/1000 - Loss: 1.439   log_lengthscale: 5.424   log_noise: -0.875\n",
      "Iter 386/1000 - Loss: 1.908   log_lengthscale: 5.428   log_noise: -0.885\n",
      "Iter 387/1000 - Loss: 1.780   log_lengthscale: 5.431   log_noise: -0.870\n",
      "Iter 388/1000 - Loss: 1.895   log_lengthscale: 5.440   log_noise: -0.850\n",
      "Iter 389/1000 - Loss: 1.261   log_lengthscale: 5.451   log_noise: -0.824\n",
      "Iter 390/1000 - Loss: 1.529   log_lengthscale: 5.461   log_noise: -0.806\n",
      "Iter 391/1000 - Loss: 1.503   log_lengthscale: 5.465   log_noise: -0.795\n",
      "Iter 392/1000 - Loss: 1.570   log_lengthscale: 5.465   log_noise: -0.791\n",
      "Iter 393/1000 - Loss: 1.578   log_lengthscale: 5.475   log_noise: -0.792\n",
      "Iter 394/1000 - Loss: 1.407   log_lengthscale: 5.482   log_noise: -0.792\n",
      "Iter 395/1000 - Loss: 1.538   log_lengthscale: 5.493   log_noise: -0.796\n",
      "Iter 396/1000 - Loss: 1.405   log_lengthscale: 5.503   log_noise: -0.803\n",
      "Iter 397/1000 - Loss: 1.423   log_lengthscale: 5.514   log_noise: -0.814\n",
      "Iter 398/1000 - Loss: 1.493   log_lengthscale: 5.524   log_noise: -0.826\n",
      "Iter 399/1000 - Loss: 1.398   log_lengthscale: 5.539   log_noise: -0.838\n",
      "Iter 400/1000 - Loss: 1.700   log_lengthscale: 5.553   log_noise: -0.854\n",
      "Iter 401/1000 - Loss: 1.363   log_lengthscale: 5.570   log_noise: -0.863\n",
      "Iter 402/1000 - Loss: 1.879   log_lengthscale: 5.587   log_noise: -0.869\n",
      "Iter 403/1000 - Loss: 1.483   log_lengthscale: 5.599   log_noise: -0.867\n",
      "Iter 404/1000 - Loss: 1.470   log_lengthscale: 5.613   log_noise: -0.864\n",
      "Iter 405/1000 - Loss: 1.415   log_lengthscale: 5.624   log_noise: -0.857\n",
      "Iter 406/1000 - Loss: 1.271   log_lengthscale: 5.637   log_noise: -0.849\n",
      "Iter 407/1000 - Loss: 1.417   log_lengthscale: 5.649   log_noise: -0.846\n",
      "Iter 408/1000 - Loss: 1.375   log_lengthscale: 5.661   log_noise: -0.846\n",
      "Iter 409/1000 - Loss: 1.864   log_lengthscale: 5.670   log_noise: -0.845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 410/1000 - Loss: 1.431   log_lengthscale: 5.685   log_noise: -0.832\n",
      "Iter 411/1000 - Loss: 1.572   log_lengthscale: 5.698   log_noise: -0.822\n",
      "Iter 412/1000 - Loss: 1.678   log_lengthscale: 5.709   log_noise: -0.815\n",
      "Iter 413/1000 - Loss: 1.651   log_lengthscale: 5.726   log_noise: -0.802\n",
      "Iter 414/1000 - Loss: 1.479   log_lengthscale: 5.732   log_noise: -0.792\n",
      "Iter 415/1000 - Loss: 1.787   log_lengthscale: 5.736   log_noise: -0.789\n",
      "Iter 416/1000 - Loss: 1.489   log_lengthscale: 5.740   log_noise: -0.780\n",
      "Iter 417/1000 - Loss: 1.499   log_lengthscale: 5.744   log_noise: -0.782\n",
      "Iter 418/1000 - Loss: 1.809   log_lengthscale: 5.754   log_noise: -0.792\n",
      "Iter 419/1000 - Loss: 1.734   log_lengthscale: 5.767   log_noise: -0.802\n",
      "Iter 420/1000 - Loss: 1.582   log_lengthscale: 5.782   log_noise: -0.811\n",
      "Iter 421/1000 - Loss: 1.827   log_lengthscale: 5.800   log_noise: -0.817\n",
      "Iter 422/1000 - Loss: 1.705   log_lengthscale: 5.809   log_noise: -0.815\n",
      "Iter 423/1000 - Loss: 1.434   log_lengthscale: 5.825   log_noise: -0.808\n",
      "Iter 424/1000 - Loss: 1.695   log_lengthscale: 5.836   log_noise: -0.810\n",
      "Iter 425/1000 - Loss: 1.478   log_lengthscale: 5.846   log_noise: -0.811\n",
      "Iter 426/1000 - Loss: 1.792   log_lengthscale: 5.857   log_noise: -0.812\n",
      "Iter 427/1000 - Loss: 1.644   log_lengthscale: 5.866   log_noise: -0.806\n",
      "Iter 428/1000 - Loss: 1.699   log_lengthscale: 5.874   log_noise: -0.801\n",
      "Iter 429/1000 - Loss: 1.232   log_lengthscale: 5.880   log_noise: -0.799\n",
      "Iter 430/1000 - Loss: 1.794   log_lengthscale: 5.886   log_noise: -0.808\n",
      "Iter 431/1000 - Loss: 1.550   log_lengthscale: 5.897   log_noise: -0.807\n",
      "Iter 432/1000 - Loss: 1.763   log_lengthscale: 5.906   log_noise: -0.807\n",
      "Iter 433/1000 - Loss: 1.838   log_lengthscale: 5.908   log_noise: -0.804\n",
      "Iter 434/1000 - Loss: 1.973   log_lengthscale: 5.916   log_noise: -0.795\n",
      "Iter 435/1000 - Loss: 1.349   log_lengthscale: 5.923   log_noise: -0.781\n",
      "Iter 436/1000 - Loss: 1.654   log_lengthscale: 5.929   log_noise: -0.777\n",
      "Iter 437/1000 - Loss: 2.077   log_lengthscale: 5.937   log_noise: -0.768\n",
      "Iter 438/1000 - Loss: 1.499   log_lengthscale: 5.945   log_noise: -0.756\n",
      "Iter 439/1000 - Loss: 1.882   log_lengthscale: 5.958   log_noise: -0.749\n",
      "Iter 440/1000 - Loss: 1.512   log_lengthscale: 5.965   log_noise: -0.743\n",
      "Iter 441/1000 - Loss: 1.167   log_lengthscale: 5.979   log_noise: -0.746\n",
      "Iter 442/1000 - Loss: 1.981   log_lengthscale: 5.989   log_noise: -0.765\n",
      "Iter 443/1000 - Loss: 1.783   log_lengthscale: 5.997   log_noise: -0.775\n",
      "Iter 444/1000 - Loss: 1.814   log_lengthscale: 6.005   log_noise: -0.777\n",
      "Iter 445/1000 - Loss: 1.471   log_lengthscale: 6.013   log_noise: -0.774\n",
      "Iter 446/1000 - Loss: 1.639   log_lengthscale: 6.018   log_noise: -0.782\n",
      "Iter 447/1000 - Loss: 1.374   log_lengthscale: 6.026   log_noise: -0.789\n",
      "Iter 448/1000 - Loss: 1.564   log_lengthscale: 6.035   log_noise: -0.806\n",
      "Iter 449/1000 - Loss: 1.503   log_lengthscale: 6.050   log_noise: -0.821\n",
      "Iter 450/1000 - Loss: 1.384   log_lengthscale: 6.063   log_noise: -0.835\n",
      "Iter 451/1000 - Loss: 1.526   log_lengthscale: 6.078   log_noise: -0.845\n",
      "Iter 452/1000 - Loss: 1.922   log_lengthscale: 6.092   log_noise: -0.856\n",
      "Iter 453/1000 - Loss: 1.330   log_lengthscale: 6.106   log_noise: -0.852\n",
      "Iter 454/1000 - Loss: 1.570   log_lengthscale: 6.113   log_noise: -0.852\n",
      "Iter 455/1000 - Loss: 1.830   log_lengthscale: 6.124   log_noise: -0.850\n",
      "Iter 456/1000 - Loss: 1.909   log_lengthscale: 6.135   log_noise: -0.838\n",
      "Iter 457/1000 - Loss: 1.719   log_lengthscale: 6.144   log_noise: -0.818\n",
      "Iter 458/1000 - Loss: 1.525   log_lengthscale: 6.152   log_noise: -0.796\n",
      "Iter 459/1000 - Loss: 1.552   log_lengthscale: 6.161   log_noise: -0.777\n",
      "Iter 460/1000 - Loss: 1.588   log_lengthscale: 6.169   log_noise: -0.764\n",
      "Iter 461/1000 - Loss: 1.695   log_lengthscale: 6.180   log_noise: -0.757\n",
      "Iter 462/1000 - Loss: 1.657   log_lengthscale: 6.195   log_noise: -0.751\n",
      "Iter 463/1000 - Loss: 1.374   log_lengthscale: 6.205   log_noise: -0.749\n",
      "Iter 464/1000 - Loss: 1.563   log_lengthscale: 6.217   log_noise: -0.762\n",
      "Iter 465/1000 - Loss: 1.490   log_lengthscale: 6.229   log_noise: -0.778\n",
      "Iter 466/1000 - Loss: 1.789   log_lengthscale: 6.243   log_noise: -0.790\n",
      "Iter 467/1000 - Loss: 1.620   log_lengthscale: 6.249   log_noise: -0.802\n",
      "Iter 468/1000 - Loss: 1.302   log_lengthscale: 6.252   log_noise: -0.814\n",
      "Iter 469/1000 - Loss: 1.561   log_lengthscale: 6.258   log_noise: -0.833\n",
      "Iter 470/1000 - Loss: 1.319   log_lengthscale: 6.266   log_noise: -0.848\n",
      "Iter 471/1000 - Loss: 1.730   log_lengthscale: 6.274   log_noise: -0.866\n",
      "Iter 472/1000 - Loss: 1.461   log_lengthscale: 6.282   log_noise: -0.875\n",
      "Iter 473/1000 - Loss: 1.965   log_lengthscale: 6.292   log_noise: -0.880\n",
      "Iter 474/1000 - Loss: 1.347   log_lengthscale: 6.298   log_noise: -0.868\n",
      "Iter 475/1000 - Loss: 1.234   log_lengthscale: 6.299   log_noise: -0.861\n",
      "Iter 476/1000 - Loss: 1.782   log_lengthscale: 6.302   log_noise: -0.855\n",
      "Iter 477/1000 - Loss: 1.453   log_lengthscale: 6.309   log_noise: -0.837\n",
      "Iter 478/1000 - Loss: 1.759   log_lengthscale: 6.316   log_noise: -0.824\n",
      "Iter 479/1000 - Loss: 1.451   log_lengthscale: 6.320   log_noise: -0.805\n",
      "Iter 480/1000 - Loss: 1.449   log_lengthscale: 6.323   log_noise: -0.793\n",
      "Iter 481/1000 - Loss: 1.852   log_lengthscale: 6.330   log_noise: -0.791\n",
      "Iter 482/1000 - Loss: 1.718   log_lengthscale: 6.337   log_noise: -0.784\n",
      "Iter 483/1000 - Loss: 1.621   log_lengthscale: 6.339   log_noise: -0.780\n",
      "Iter 484/1000 - Loss: 1.577   log_lengthscale: 6.339   log_noise: -0.775\n",
      "Iter 485/1000 - Loss: 1.828   log_lengthscale: 6.341   log_noise: -0.776\n",
      "Iter 486/1000 - Loss: 1.347   log_lengthscale: 6.341   log_noise: -0.770\n",
      "Iter 487/1000 - Loss: 1.389   log_lengthscale: 6.344   log_noise: -0.774\n",
      "Iter 488/1000 - Loss: 1.806   log_lengthscale: 6.350   log_noise: -0.790\n",
      "Iter 489/1000 - Loss: 1.381   log_lengthscale: 6.357   log_noise: -0.803\n",
      "Iter 490/1000 - Loss: 1.376   log_lengthscale: 6.368   log_noise: -0.822\n",
      "Iter 491/1000 - Loss: 1.687   log_lengthscale: 6.380   log_noise: -0.844\n",
      "Iter 492/1000 - Loss: 1.609   log_lengthscale: 6.393   log_noise: -0.857\n",
      "Iter 493/1000 - Loss: 1.405   log_lengthscale: 6.404   log_noise: -0.863\n",
      "Iter 494/1000 - Loss: 1.614   log_lengthscale: 6.412   log_noise: -0.870\n",
      "Iter 495/1000 - Loss: 1.615   log_lengthscale: 6.420   log_noise: -0.869\n",
      "Iter 496/1000 - Loss: 1.425   log_lengthscale: 6.428   log_noise: -0.864\n",
      "Iter 497/1000 - Loss: 1.929   log_lengthscale: 6.436   log_noise: -0.861\n",
      "Iter 498/1000 - Loss: 1.457   log_lengthscale: 6.444   log_noise: -0.842\n",
      "Iter 499/1000 - Loss: 2.060   log_lengthscale: 6.452   log_noise: -0.826\n",
      "Iter 500/1000 - Loss: 1.658   log_lengthscale: 6.459   log_noise: -0.798\n",
      "Iter 501/1000 - Loss: 1.524   log_lengthscale: 6.466   log_noise: -0.778\n",
      "Iter 502/1000 - Loss: 1.238   log_lengthscale: 6.472   log_noise: -0.765\n",
      "Iter 503/1000 - Loss: 1.736   log_lengthscale: 6.478   log_noise: -0.766\n",
      "Iter 504/1000 - Loss: 1.178   log_lengthscale: 6.481   log_noise: -0.766\n",
      "Iter 505/1000 - Loss: 1.323   log_lengthscale: 6.484   log_noise: -0.782\n",
      "Iter 506/1000 - Loss: 1.251   log_lengthscale: 6.489   log_noise: -0.805\n",
      "Iter 507/1000 - Loss: 1.769   log_lengthscale: 6.494   log_noise: -0.835\n",
      "Iter 508/1000 - Loss: 1.407   log_lengthscale: 6.500   log_noise: -0.856\n",
      "Iter 509/1000 - Loss: 1.285   log_lengthscale: 6.504   log_noise: -0.872\n",
      "Iter 510/1000 - Loss: 1.438   log_lengthscale: 6.509   log_noise: -0.885\n",
      "Iter 511/1000 - Loss: 1.475   log_lengthscale: 6.513   log_noise: -0.895\n",
      "Iter 512/1000 - Loss: 1.374   log_lengthscale: 6.518   log_noise: -0.893\n",
      "Iter 513/1000 - Loss: 1.306   log_lengthscale: 6.525   log_noise: -0.888\n",
      "Iter 514/1000 - Loss: 1.453   log_lengthscale: 6.535   log_noise: -0.882\n",
      "Iter 515/1000 - Loss: 1.407   log_lengthscale: 6.545   log_noise: -0.868\n",
      "Iter 516/1000 - Loss: 1.820   log_lengthscale: 6.556   log_noise: -0.849\n",
      "Iter 517/1000 - Loss: 1.352   log_lengthscale: 6.567   log_noise: -0.822\n",
      "Iter 518/1000 - Loss: 1.297   log_lengthscale: 6.581   log_noise: -0.803\n",
      "Iter 519/1000 - Loss: 1.411   log_lengthscale: 6.592   log_noise: -0.797\n",
      "Iter 520/1000 - Loss: 1.220   log_lengthscale: 6.601   log_noise: -0.798\n",
      "Iter 521/1000 - Loss: 1.547   log_lengthscale: 6.608   log_noise: -0.812\n",
      "Iter 522/1000 - Loss: 1.601   log_lengthscale: 6.615   log_noise: -0.821\n",
      "Iter 523/1000 - Loss: 1.716   log_lengthscale: 6.619   log_noise: -0.829\n",
      "Iter 524/1000 - Loss: 1.216   log_lengthscale: 6.623   log_noise: -0.828\n",
      "Iter 525/1000 - Loss: 1.939   log_lengthscale: 6.628   log_noise: -0.835\n",
      "Iter 526/1000 - Loss: 1.498   log_lengthscale: 6.631   log_noise: -0.835\n",
      "Iter 527/1000 - Loss: 1.574   log_lengthscale: 6.636   log_noise: -0.830\n",
      "Iter 528/1000 - Loss: 1.565   log_lengthscale: 6.642   log_noise: -0.823\n",
      "Iter 529/1000 - Loss: 1.463   log_lengthscale: 6.652   log_noise: -0.815\n",
      "Iter 530/1000 - Loss: 1.348   log_lengthscale: 6.659   log_noise: -0.808\n",
      "Iter 531/1000 - Loss: 1.761   log_lengthscale: 6.663   log_noise: -0.811\n",
      "Iter 532/1000 - Loss: 1.634   log_lengthscale: 6.664   log_noise: -0.808\n",
      "Iter 533/1000 - Loss: 1.310   log_lengthscale: 6.665   log_noise: -0.806\n",
      "Iter 534/1000 - Loss: 1.717   log_lengthscale: 6.666   log_noise: -0.812\n",
      "Iter 535/1000 - Loss: 1.389   log_lengthscale: 6.670   log_noise: -0.810\n",
      "Iter 536/1000 - Loss: 1.188   log_lengthscale: 6.675   log_noise: -0.816\n",
      "Iter 537/1000 - Loss: 1.564   log_lengthscale: 6.680   log_noise: -0.835\n",
      "Iter 538/1000 - Loss: 1.562   log_lengthscale: 6.683   log_noise: -0.851\n",
      "Iter 539/1000 - Loss: 1.424   log_lengthscale: 6.688   log_noise: -0.859\n",
      "Iter 540/1000 - Loss: 1.654   log_lengthscale: 6.691   log_noise: -0.866\n",
      "Iter 541/1000 - Loss: 1.667   log_lengthscale: 6.692   log_noise: -0.869\n",
      "Iter 542/1000 - Loss: 1.453   log_lengthscale: 6.694   log_noise: -0.857\n",
      "Iter 543/1000 - Loss: 2.009   log_lengthscale: 6.696   log_noise: -0.848\n",
      "Iter 544/1000 - Loss: 1.731   log_lengthscale: 6.701   log_noise: -0.816\n",
      "Iter 545/1000 - Loss: 1.708   log_lengthscale: 6.706   log_noise: -0.781\n",
      "Iter 546/1000 - Loss: 1.369   log_lengthscale: 6.709   log_noise: -0.747\n",
      "Iter 547/1000 - Loss: 1.394   log_lengthscale: 6.711   log_noise: -0.733\n",
      "Iter 548/1000 - Loss: 1.755   log_lengthscale: 6.712   log_noise: -0.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 549/1000 - Loss: 1.425   log_lengthscale: 6.711   log_noise: -0.736\n",
      "Iter 550/1000 - Loss: 1.501   log_lengthscale: 6.714   log_noise: -0.742\n",
      "Iter 551/1000 - Loss: 1.598   log_lengthscale: 6.718   log_noise: -0.758\n",
      "Iter 552/1000 - Loss: 1.333   log_lengthscale: 6.721   log_noise: -0.771\n",
      "Iter 553/1000 - Loss: 1.260   log_lengthscale: 6.723   log_noise: -0.794\n",
      "Iter 554/1000 - Loss: 1.207   log_lengthscale: 6.725   log_noise: -0.824\n",
      "Iter 555/1000 - Loss: 1.805   log_lengthscale: 6.726   log_noise: -0.861\n",
      "Iter 556/1000 - Loss: 1.586   log_lengthscale: 6.724   log_noise: -0.877\n",
      "Iter 557/1000 - Loss: 1.647   log_lengthscale: 6.719   log_noise: -0.887\n",
      "Iter 558/1000 - Loss: 1.800   log_lengthscale: 6.713   log_noise: -0.888\n",
      "Iter 559/1000 - Loss: 1.503   log_lengthscale: 6.709   log_noise: -0.876\n",
      "Iter 560/1000 - Loss: 1.590   log_lengthscale: 6.705   log_noise: -0.862\n",
      "Iter 561/1000 - Loss: 1.682   log_lengthscale: 6.701   log_noise: -0.842\n",
      "Iter 562/1000 - Loss: 1.298   log_lengthscale: 6.698   log_noise: -0.816\n",
      "Iter 563/1000 - Loss: 1.195   log_lengthscale: 6.695   log_noise: -0.803\n",
      "Iter 564/1000 - Loss: 1.321   log_lengthscale: 6.693   log_noise: -0.806\n",
      "Iter 565/1000 - Loss: 1.498   log_lengthscale: 6.693   log_noise: -0.819\n",
      "Iter 566/1000 - Loss: 1.282   log_lengthscale: 6.689   log_noise: -0.837\n",
      "Iter 567/1000 - Loss: 1.455   log_lengthscale: 6.686   log_noise: -0.859\n",
      "Iter 568/1000 - Loss: 1.387   log_lengthscale: 6.687   log_noise: -0.881\n",
      "Iter 569/1000 - Loss: 1.910   log_lengthscale: 6.687   log_noise: -0.894\n",
      "Iter 570/1000 - Loss: 1.594   log_lengthscale: 6.687   log_noise: -0.888\n",
      "Iter 571/1000 - Loss: 1.647   log_lengthscale: 6.688   log_noise: -0.875\n",
      "Iter 572/1000 - Loss: 1.538   log_lengthscale: 6.686   log_noise: -0.860\n",
      "Iter 573/1000 - Loss: 1.382   log_lengthscale: 6.685   log_noise: -0.839\n",
      "Iter 574/1000 - Loss: 1.503   log_lengthscale: 6.682   log_noise: -0.822\n",
      "Iter 575/1000 - Loss: 1.102   log_lengthscale: 6.678   log_noise: -0.811\n",
      "Iter 576/1000 - Loss: 1.420   log_lengthscale: 6.676   log_noise: -0.819\n",
      "Iter 577/1000 - Loss: 1.982   log_lengthscale: 6.676   log_noise: -0.829\n",
      "Iter 578/1000 - Loss: 1.306   log_lengthscale: 6.674   log_noise: -0.825\n",
      "Iter 579/1000 - Loss: 1.326   log_lengthscale: 6.674   log_noise: -0.829\n",
      "Iter 580/1000 - Loss: 1.682   log_lengthscale: 6.674   log_noise: -0.839\n",
      "Iter 581/1000 - Loss: 1.305   log_lengthscale: 6.676   log_noise: -0.835\n",
      "Iter 582/1000 - Loss: 1.429   log_lengthscale: 6.680   log_noise: -0.837\n",
      "Iter 583/1000 - Loss: 1.816   log_lengthscale: 6.686   log_noise: -0.832\n",
      "Iter 584/1000 - Loss: 1.433   log_lengthscale: 6.692   log_noise: -0.821\n",
      "Iter 585/1000 - Loss: 1.435   log_lengthscale: 6.702   log_noise: -0.812\n",
      "Iter 586/1000 - Loss: 1.568   log_lengthscale: 6.711   log_noise: -0.807\n",
      "Iter 587/1000 - Loss: 1.947   log_lengthscale: 6.719   log_noise: -0.801\n",
      "Iter 588/1000 - Loss: 1.430   log_lengthscale: 6.730   log_noise: -0.782\n",
      "Iter 589/1000 - Loss: 1.672   log_lengthscale: 6.740   log_noise: -0.770\n",
      "Iter 590/1000 - Loss: 1.545   log_lengthscale: 6.752   log_noise: -0.758\n",
      "Iter 591/1000 - Loss: 1.413   log_lengthscale: 6.763   log_noise: -0.751\n",
      "Iter 592/1000 - Loss: 1.844   log_lengthscale: 6.770   log_noise: -0.757\n",
      "Iter 593/1000 - Loss: 1.297   log_lengthscale: 6.778   log_noise: -0.760\n",
      "Iter 594/1000 - Loss: 1.736   log_lengthscale: 6.786   log_noise: -0.773\n",
      "Iter 595/1000 - Loss: 1.735   log_lengthscale: 6.793   log_noise: -0.784\n",
      "Iter 596/1000 - Loss: 1.341   log_lengthscale: 6.802   log_noise: -0.794\n",
      "Iter 597/1000 - Loss: 1.540   log_lengthscale: 6.813   log_noise: -0.815\n",
      "Iter 598/1000 - Loss: 1.411   log_lengthscale: 6.821   log_noise: -0.837\n",
      "Iter 599/1000 - Loss: 1.624   log_lengthscale: 6.831   log_noise: -0.858\n",
      "Iter 600/1000 - Loss: 1.462   log_lengthscale: 6.839   log_noise: -0.867\n",
      "Iter 601/1000 - Loss: 1.390   log_lengthscale: 6.846   log_noise: -0.876\n",
      "Iter 602/1000 - Loss: 1.598   log_lengthscale: 6.853   log_noise: -0.878\n",
      "Iter 603/1000 - Loss: 1.322   log_lengthscale: 6.858   log_noise: -0.874\n",
      "Iter 604/1000 - Loss: 1.468   log_lengthscale: 6.863   log_noise: -0.865\n",
      "Iter 605/1000 - Loss: 1.354   log_lengthscale: 6.869   log_noise: -0.852\n",
      "Iter 606/1000 - Loss: 1.606   log_lengthscale: 6.877   log_noise: -0.845\n",
      "Iter 607/1000 - Loss: 1.598   log_lengthscale: 6.886   log_noise: -0.832\n",
      "Iter 608/1000 - Loss: 1.670   log_lengthscale: 6.895   log_noise: -0.817\n",
      "Iter 609/1000 - Loss: 1.597   log_lengthscale: 6.906   log_noise: -0.804\n",
      "Iter 610/1000 - Loss: 1.722   log_lengthscale: 6.918   log_noise: -0.791\n",
      "Iter 611/1000 - Loss: 1.493   log_lengthscale: 6.928   log_noise: -0.778\n",
      "Iter 612/1000 - Loss: 1.432   log_lengthscale: 6.938   log_noise: -0.769\n",
      "Iter 613/1000 - Loss: 1.326   log_lengthscale: 6.950   log_noise: -0.769\n",
      "Iter 614/1000 - Loss: 1.493   log_lengthscale: 6.961   log_noise: -0.782\n",
      "Iter 615/1000 - Loss: 1.660   log_lengthscale: 6.969   log_noise: -0.798\n",
      "Iter 616/1000 - Loss: 1.561   log_lengthscale: 6.980   log_noise: -0.808\n",
      "Iter 617/1000 - Loss: 1.425   log_lengthscale: 6.993   log_noise: -0.814\n",
      "Iter 618/1000 - Loss: 1.168   log_lengthscale: 7.007   log_noise: -0.828\n",
      "Iter 619/1000 - Loss: 1.595   log_lengthscale: 7.018   log_noise: -0.853\n",
      "Iter 620/1000 - Loss: 1.444   log_lengthscale: 7.029   log_noise: -0.870\n",
      "Iter 621/1000 - Loss: 1.748   log_lengthscale: 7.040   log_noise: -0.885\n",
      "Iter 622/1000 - Loss: 1.493   log_lengthscale: 7.053   log_noise: -0.886\n",
      "Iter 623/1000 - Loss: 1.304   log_lengthscale: 7.065   log_noise: -0.884\n",
      "Iter 624/1000 - Loss: 1.403   log_lengthscale: 7.077   log_noise: -0.887\n",
      "Iter 625/1000 - Loss: 1.427   log_lengthscale: 7.088   log_noise: -0.887\n",
      "Iter 626/1000 - Loss: 1.247   log_lengthscale: 7.098   log_noise: -0.882\n",
      "Iter 627/1000 - Loss: 1.400   log_lengthscale: 7.106   log_noise: -0.881\n",
      "Iter 628/1000 - Loss: 1.351   log_lengthscale: 7.112   log_noise: -0.879\n",
      "Iter 629/1000 - Loss: 1.512   log_lengthscale: 7.118   log_noise: -0.878\n",
      "Iter 630/1000 - Loss: 1.658   log_lengthscale: 7.123   log_noise: -0.873\n",
      "Iter 631/1000 - Loss: 1.301   log_lengthscale: 7.132   log_noise: -0.853\n",
      "Iter 632/1000 - Loss: 1.380   log_lengthscale: 7.141   log_noise: -0.842\n",
      "Iter 633/1000 - Loss: 1.730   log_lengthscale: 7.150   log_noise: -0.834\n",
      "Iter 634/1000 - Loss: 1.468   log_lengthscale: 7.159   log_noise: -0.818\n",
      "Iter 635/1000 - Loss: 2.010   log_lengthscale: 7.173   log_noise: -0.801\n",
      "Iter 636/1000 - Loss: 1.331   log_lengthscale: 7.185   log_noise: -0.780\n",
      "Iter 637/1000 - Loss: 1.634   log_lengthscale: 7.196   log_noise: -0.765\n",
      "Iter 638/1000 - Loss: 1.369   log_lengthscale: 7.206   log_noise: -0.757\n",
      "Iter 639/1000 - Loss: 1.683   log_lengthscale: 7.216   log_noise: -0.759\n",
      "Iter 640/1000 - Loss: 1.392   log_lengthscale: 7.225   log_noise: -0.761\n",
      "Iter 641/1000 - Loss: 1.600   log_lengthscale: 7.234   log_noise: -0.770\n",
      "Iter 642/1000 - Loss: 1.202   log_lengthscale: 7.244   log_noise: -0.782\n",
      "Iter 643/1000 - Loss: 1.258   log_lengthscale: 7.254   log_noise: -0.803\n",
      "Iter 644/1000 - Loss: 1.709   log_lengthscale: 7.264   log_noise: -0.826\n",
      "Iter 645/1000 - Loss: 1.505   log_lengthscale: 7.276   log_noise: -0.839\n",
      "Iter 646/1000 - Loss: 1.515   log_lengthscale: 7.287   log_noise: -0.853\n",
      "Iter 647/1000 - Loss: 1.460   log_lengthscale: 7.298   log_noise: -0.861\n",
      "Iter 648/1000 - Loss: 1.473   log_lengthscale: 7.309   log_noise: -0.864\n",
      "Iter 649/1000 - Loss: 1.519   log_lengthscale: 7.318   log_noise: -0.864\n",
      "Iter 650/1000 - Loss: 1.645   log_lengthscale: 7.326   log_noise: -0.855\n",
      "Iter 651/1000 - Loss: 1.503   log_lengthscale: 7.334   log_noise: -0.840\n",
      "Iter 652/1000 - Loss: 1.443   log_lengthscale: 7.340   log_noise: -0.824\n",
      "Iter 653/1000 - Loss: 1.465   log_lengthscale: 7.348   log_noise: -0.811\n",
      "Iter 654/1000 - Loss: 1.322   log_lengthscale: 7.357   log_noise: -0.803\n",
      "Iter 655/1000 - Loss: 1.606   log_lengthscale: 7.367   log_noise: -0.805\n",
      "Iter 656/1000 - Loss: 1.400   log_lengthscale: 7.374   log_noise: -0.807\n",
      "Iter 657/1000 - Loss: 1.415   log_lengthscale: 7.384   log_noise: -0.812\n",
      "Iter 658/1000 - Loss: 1.379   log_lengthscale: 7.391   log_noise: -0.821\n",
      "Iter 659/1000 - Loss: 1.574   log_lengthscale: 7.398   log_noise: -0.835\n",
      "Iter 660/1000 - Loss: 1.497   log_lengthscale: 7.406   log_noise: -0.842\n",
      "Iter 661/1000 - Loss: 1.423   log_lengthscale: 7.414   log_noise: -0.847\n",
      "Iter 662/1000 - Loss: 1.420   log_lengthscale: 7.422   log_noise: -0.854\n",
      "Iter 663/1000 - Loss: 1.605   log_lengthscale: 7.429   log_noise: -0.859\n",
      "Iter 664/1000 - Loss: 1.264   log_lengthscale: 7.436   log_noise: -0.857\n",
      "Iter 665/1000 - Loss: 1.490   log_lengthscale: 7.443   log_noise: -0.860\n",
      "Iter 666/1000 - Loss: 1.736   log_lengthscale: 7.449   log_noise: -0.862\n",
      "Iter 667/1000 - Loss: 1.714   log_lengthscale: 7.454   log_noise: -0.849\n",
      "Iter 668/1000 - Loss: 1.252   log_lengthscale: 7.458   log_noise: -0.829\n",
      "Iter 669/1000 - Loss: 1.411   log_lengthscale: 7.464   log_noise: -0.813\n",
      "Iter 670/1000 - Loss: 1.292   log_lengthscale: 7.468   log_noise: -0.804\n",
      "Iter 671/1000 - Loss: 1.416   log_lengthscale: 7.473   log_noise: -0.806\n",
      "Iter 672/1000 - Loss: 1.492   log_lengthscale: 7.481   log_noise: -0.804\n",
      "Iter 673/1000 - Loss: 1.419   log_lengthscale: 7.489   log_noise: -0.802\n",
      "Iter 674/1000 - Loss: 1.479   log_lengthscale: 7.497   log_noise: -0.809\n",
      "Iter 675/1000 - Loss: 1.339   log_lengthscale: 7.505   log_noise: -0.818\n",
      "Iter 676/1000 - Loss: 1.685   log_lengthscale: 7.512   log_noise: -0.828\n",
      "Iter 677/1000 - Loss: 1.513   log_lengthscale: 7.521   log_noise: -0.830\n",
      "Iter 678/1000 - Loss: 1.766   log_lengthscale: 7.530   log_noise: -0.821\n",
      "Iter 679/1000 - Loss: 1.451   log_lengthscale: 7.540   log_noise: -0.807\n",
      "Iter 680/1000 - Loss: 1.684   log_lengthscale: 7.550   log_noise: -0.795\n",
      "Iter 681/1000 - Loss: 1.349   log_lengthscale: 7.559   log_noise: -0.781\n",
      "Iter 682/1000 - Loss: 1.389   log_lengthscale: 7.569   log_noise: -0.772\n",
      "Iter 683/1000 - Loss: 1.234   log_lengthscale: 7.580   log_noise: -0.766\n",
      "Iter 684/1000 - Loss: 1.297   log_lengthscale: 7.589   log_noise: -0.779\n",
      "Iter 685/1000 - Loss: 1.621   log_lengthscale: 7.597   log_noise: -0.804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 686/1000 - Loss: 1.288   log_lengthscale: 7.606   log_noise: -0.822\n",
      "Iter 687/1000 - Loss: 1.472   log_lengthscale: 7.615   log_noise: -0.838\n",
      "Iter 688/1000 - Loss: 1.518   log_lengthscale: 7.624   log_noise: -0.845\n",
      "Iter 689/1000 - Loss: 1.539   log_lengthscale: 7.632   log_noise: -0.853\n",
      "Iter 690/1000 - Loss: 1.169   log_lengthscale: 7.640   log_noise: -0.856\n",
      "Iter 691/1000 - Loss: 1.481   log_lengthscale: 7.648   log_noise: -0.863\n",
      "Iter 692/1000 - Loss: 1.775   log_lengthscale: 7.655   log_noise: -0.864\n",
      "Iter 693/1000 - Loss: 1.559   log_lengthscale: 7.662   log_noise: -0.846\n",
      "Iter 694/1000 - Loss: 1.255   log_lengthscale: 7.669   log_noise: -0.823\n",
      "Iter 695/1000 - Loss: 1.396   log_lengthscale: 7.675   log_noise: -0.813\n",
      "Iter 696/1000 - Loss: 1.295   log_lengthscale: 7.681   log_noise: -0.807\n",
      "Iter 697/1000 - Loss: 1.631   log_lengthscale: 7.687   log_noise: -0.810\n",
      "Iter 698/1000 - Loss: 1.473   log_lengthscale: 7.692   log_noise: -0.808\n",
      "Iter 699/1000 - Loss: 1.209   log_lengthscale: 7.697   log_noise: -0.806\n",
      "Iter 700/1000 - Loss: 1.267   log_lengthscale: 7.702   log_noise: -0.820\n",
      "Iter 701/1000 - Loss: 1.372   log_lengthscale: 7.708   log_noise: -0.833\n",
      "Iter 702/1000 - Loss: 1.281   log_lengthscale: 7.713   log_noise: -0.846\n",
      "Iter 703/1000 - Loss: 1.436   log_lengthscale: 7.719   log_noise: -0.863\n",
      "Iter 704/1000 - Loss: 2.042   log_lengthscale: 7.724   log_noise: -0.875\n",
      "Iter 705/1000 - Loss: 1.401   log_lengthscale: 7.730   log_noise: -0.868\n",
      "Iter 706/1000 - Loss: 1.562   log_lengthscale: 7.735   log_noise: -0.857\n",
      "Iter 707/1000 - Loss: 1.687   log_lengthscale: 7.742   log_noise: -0.841\n",
      "Iter 708/1000 - Loss: 1.254   log_lengthscale: 7.748   log_noise: -0.822\n",
      "Iter 709/1000 - Loss: 1.297   log_lengthscale: 7.755   log_noise: -0.810\n",
      "Iter 710/1000 - Loss: 1.738   log_lengthscale: 7.762   log_noise: -0.809\n",
      "Iter 711/1000 - Loss: 1.658   log_lengthscale: 7.768   log_noise: -0.805\n",
      "Iter 712/1000 - Loss: 1.455   log_lengthscale: 7.774   log_noise: -0.796\n",
      "Iter 713/1000 - Loss: 1.678   log_lengthscale: 7.780   log_noise: -0.794\n",
      "Iter 714/1000 - Loss: 1.434   log_lengthscale: 7.788   log_noise: -0.790\n",
      "Iter 715/1000 - Loss: 1.363   log_lengthscale: 7.794   log_noise: -0.790\n",
      "Iter 716/1000 - Loss: 1.712   log_lengthscale: 7.801   log_noise: -0.799\n",
      "Iter 717/1000 - Loss: 1.539   log_lengthscale: 7.809   log_noise: -0.800\n",
      "Iter 718/1000 - Loss: 1.505   log_lengthscale: 7.817   log_noise: -0.804\n",
      "Iter 719/1000 - Loss: 1.611   log_lengthscale: 7.824   log_noise: -0.811\n",
      "Iter 720/1000 - Loss: 1.161   log_lengthscale: 7.831   log_noise: -0.815\n",
      "Iter 721/1000 - Loss: 1.581   log_lengthscale: 7.838   log_noise: -0.829\n",
      "Iter 722/1000 - Loss: 1.438   log_lengthscale: 7.844   log_noise: -0.843\n",
      "Iter 723/1000 - Loss: 1.565   log_lengthscale: 7.851   log_noise: -0.850\n",
      "Iter 724/1000 - Loss: 1.375   log_lengthscale: 7.859   log_noise: -0.856\n",
      "Iter 725/1000 - Loss: 1.408   log_lengthscale: 7.866   log_noise: -0.860\n",
      "Iter 726/1000 - Loss: 1.365   log_lengthscale: 7.874   log_noise: -0.858\n",
      "Iter 727/1000 - Loss: 1.291   log_lengthscale: 7.881   log_noise: -0.854\n",
      "Iter 728/1000 - Loss: 1.594   log_lengthscale: 7.889   log_noise: -0.851\n",
      "Iter 729/1000 - Loss: 1.421   log_lengthscale: 7.894   log_noise: -0.844\n",
      "Iter 730/1000 - Loss: 1.453   log_lengthscale: 7.900   log_noise: -0.832\n",
      "Iter 731/1000 - Loss: 1.506   log_lengthscale: 7.905   log_noise: -0.820\n",
      "Iter 732/1000 - Loss: 1.250   log_lengthscale: 7.910   log_noise: -0.813\n",
      "Iter 733/1000 - Loss: 1.578   log_lengthscale: 7.915   log_noise: -0.812\n",
      "Iter 734/1000 - Loss: 1.296   log_lengthscale: 7.920   log_noise: -0.812\n",
      "Iter 735/1000 - Loss: 1.287   log_lengthscale: 7.925   log_noise: -0.817\n",
      "Iter 736/1000 - Loss: 1.603   log_lengthscale: 7.931   log_noise: -0.829\n",
      "Iter 737/1000 - Loss: 1.623   log_lengthscale: 7.936   log_noise: -0.838\n",
      "Iter 738/1000 - Loss: 1.300   log_lengthscale: 7.941   log_noise: -0.844\n",
      "Iter 739/1000 - Loss: 1.480   log_lengthscale: 7.947   log_noise: -0.849\n",
      "Iter 740/1000 - Loss: 1.902   log_lengthscale: 7.953   log_noise: -0.851\n",
      "Iter 741/1000 - Loss: 1.848   log_lengthscale: 7.959   log_noise: -0.841\n",
      "Iter 742/1000 - Loss: 1.307   log_lengthscale: 7.965   log_noise: -0.823\n",
      "Iter 743/1000 - Loss: 1.707   log_lengthscale: 7.970   log_noise: -0.813\n",
      "Iter 744/1000 - Loss: 1.522   log_lengthscale: 7.975   log_noise: -0.802\n",
      "Iter 745/1000 - Loss: 1.556   log_lengthscale: 7.981   log_noise: -0.791\n",
      "Iter 746/1000 - Loss: 1.659   log_lengthscale: 7.987   log_noise: -0.782\n",
      "Iter 747/1000 - Loss: 1.294   log_lengthscale: 7.993   log_noise: -0.776\n",
      "Iter 748/1000 - Loss: 1.328   log_lengthscale: 7.998   log_noise: -0.781\n",
      "Iter 749/1000 - Loss: 1.789   log_lengthscale: 8.004   log_noise: -0.788\n",
      "Iter 750/1000 - Loss: 1.483   log_lengthscale: 8.010   log_noise: -0.792\n",
      "Iter 751/1000 - Loss: 1.477   log_lengthscale: 8.018   log_noise: -0.792\n",
      "Iter 752/1000 - Loss: 1.293   log_lengthscale: 8.025   log_noise: -0.799\n",
      "Iter 753/1000 - Loss: 1.853   log_lengthscale: 8.032   log_noise: -0.817\n",
      "Iter 754/1000 - Loss: 1.637   log_lengthscale: 8.038   log_noise: -0.820\n",
      "Iter 755/1000 - Loss: 1.968   log_lengthscale: 8.042   log_noise: -0.824\n",
      "Iter 756/1000 - Loss: 1.470   log_lengthscale: 8.045   log_noise: -0.818\n",
      "Iter 757/1000 - Loss: 1.536   log_lengthscale: 8.049   log_noise: -0.812\n",
      "Iter 758/1000 - Loss: 1.400   log_lengthscale: 8.052   log_noise: -0.805\n",
      "Iter 759/1000 - Loss: 1.698   log_lengthscale: 8.054   log_noise: -0.805\n",
      "Iter 760/1000 - Loss: 1.440   log_lengthscale: 8.058   log_noise: -0.800\n",
      "Iter 761/1000 - Loss: 1.726   log_lengthscale: 8.062   log_noise: -0.802\n",
      "Iter 762/1000 - Loss: 1.363   log_lengthscale: 8.066   log_noise: -0.806\n",
      "Iter 763/1000 - Loss: 1.769   log_lengthscale: 8.070   log_noise: -0.818\n",
      "Iter 764/1000 - Loss: 1.682   log_lengthscale: 8.074   log_noise: -0.814\n",
      "Iter 765/1000 - Loss: 1.669   log_lengthscale: 8.079   log_noise: -0.805\n",
      "Iter 766/1000 - Loss: 1.644   log_lengthscale: 8.084   log_noise: -0.799\n",
      "Iter 767/1000 - Loss: 1.777   log_lengthscale: 8.088   log_noise: -0.797\n",
      "Iter 768/1000 - Loss: 1.498   log_lengthscale: 8.092   log_noise: -0.792\n",
      "Iter 769/1000 - Loss: 1.328   log_lengthscale: 8.096   log_noise: -0.791\n",
      "Iter 770/1000 - Loss: 1.770   log_lengthscale: 8.101   log_noise: -0.795\n",
      "Iter 771/1000 - Loss: 1.598   log_lengthscale: 8.106   log_noise: -0.794\n",
      "Iter 772/1000 - Loss: 1.548   log_lengthscale: 8.112   log_noise: -0.790\n",
      "Iter 773/1000 - Loss: 1.631   log_lengthscale: 8.118   log_noise: -0.793\n",
      "Iter 774/1000 - Loss: 1.429   log_lengthscale: 8.123   log_noise: -0.798\n",
      "Iter 775/1000 - Loss: 1.407   log_lengthscale: 8.129   log_noise: -0.807\n",
      "Iter 776/1000 - Loss: 1.689   log_lengthscale: 8.135   log_noise: -0.820\n",
      "Iter 777/1000 - Loss: 1.408   log_lengthscale: 8.140   log_noise: -0.830\n",
      "Iter 778/1000 - Loss: 1.396   log_lengthscale: 8.146   log_noise: -0.840\n",
      "Iter 779/1000 - Loss: 1.458   log_lengthscale: 8.152   log_noise: -0.852\n",
      "Iter 780/1000 - Loss: 1.433   log_lengthscale: 8.159   log_noise: -0.860\n",
      "Iter 781/1000 - Loss: 1.826   log_lengthscale: 8.166   log_noise: -0.855\n",
      "Iter 782/1000 - Loss: 1.459   log_lengthscale: 8.170   log_noise: -0.843\n",
      "Iter 783/1000 - Loss: 1.390   log_lengthscale: 8.175   log_noise: -0.828\n",
      "Iter 784/1000 - Loss: 1.531   log_lengthscale: 8.180   log_noise: -0.814\n",
      "Iter 785/1000 - Loss: 1.475   log_lengthscale: 8.183   log_noise: -0.809\n",
      "Iter 786/1000 - Loss: 1.461   log_lengthscale: 8.187   log_noise: -0.806\n",
      "Iter 787/1000 - Loss: 1.687   log_lengthscale: 8.189   log_noise: -0.809\n",
      "Iter 788/1000 - Loss: 1.579   log_lengthscale: 8.192   log_noise: -0.809\n",
      "Iter 789/1000 - Loss: 1.702   log_lengthscale: 8.194   log_noise: -0.813\n",
      "Iter 790/1000 - Loss: 2.165   log_lengthscale: 8.195   log_noise: -0.816\n",
      "Iter 791/1000 - Loss: 1.675   log_lengthscale: 8.197   log_noise: -0.802\n",
      "Iter 792/1000 - Loss: 1.330   log_lengthscale: 8.199   log_noise: -0.788\n",
      "Iter 793/1000 - Loss: 1.472   log_lengthscale: 8.202   log_noise: -0.782\n",
      "Iter 794/1000 - Loss: 1.425   log_lengthscale: 8.204   log_noise: -0.783\n",
      "Iter 795/1000 - Loss: 1.957   log_lengthscale: 8.206   log_noise: -0.790\n",
      "Iter 796/1000 - Loss: 1.458   log_lengthscale: 8.207   log_noise: -0.791\n",
      "Iter 797/1000 - Loss: 1.775   log_lengthscale: 8.210   log_noise: -0.788\n",
      "Iter 798/1000 - Loss: 1.809   log_lengthscale: 8.213   log_noise: -0.782\n",
      "Iter 799/1000 - Loss: 1.316   log_lengthscale: 8.216   log_noise: -0.770\n",
      "Iter 800/1000 - Loss: 1.346   log_lengthscale: 8.220   log_noise: -0.771\n",
      "Iter 801/1000 - Loss: 1.510   log_lengthscale: 8.224   log_noise: -0.780\n",
      "Iter 802/1000 - Loss: 1.437   log_lengthscale: 8.228   log_noise: -0.792\n",
      "Iter 803/1000 - Loss: 1.634   log_lengthscale: 8.232   log_noise: -0.809\n",
      "Iter 804/1000 - Loss: 1.464   log_lengthscale: 8.235   log_noise: -0.824\n",
      "Iter 805/1000 - Loss: 1.757   log_lengthscale: 8.239   log_noise: -0.841\n",
      "Iter 806/1000 - Loss: 1.432   log_lengthscale: 8.242   log_noise: -0.843\n",
      "Iter 807/1000 - Loss: 1.748   log_lengthscale: 8.245   log_noise: -0.842\n",
      "Iter 808/1000 - Loss: 1.518   log_lengthscale: 8.248   log_noise: -0.834\n",
      "Iter 809/1000 - Loss: 1.739   log_lengthscale: 8.251   log_noise: -0.824\n",
      "Iter 810/1000 - Loss: 1.337   log_lengthscale: 8.253   log_noise: -0.809\n",
      "Iter 811/1000 - Loss: 1.365   log_lengthscale: 8.255   log_noise: -0.804\n",
      "Iter 812/1000 - Loss: 1.378   log_lengthscale: 8.257   log_noise: -0.802\n",
      "Iter 813/1000 - Loss: 1.416   log_lengthscale: 8.260   log_noise: -0.807\n",
      "Iter 814/1000 - Loss: 2.080   log_lengthscale: 8.263   log_noise: -0.813\n",
      "Iter 815/1000 - Loss: 1.632   log_lengthscale: 8.265   log_noise: -0.802\n",
      "Iter 816/1000 - Loss: 1.625   log_lengthscale: 8.267   log_noise: -0.795\n",
      "Iter 817/1000 - Loss: 1.469   log_lengthscale: 8.268   log_noise: -0.786\n",
      "Iter 818/1000 - Loss: 1.429   log_lengthscale: 8.270   log_noise: -0.783\n",
      "Iter 819/1000 - Loss: 1.295   log_lengthscale: 8.273   log_noise: -0.786\n",
      "Iter 820/1000 - Loss: 2.015   log_lengthscale: 8.276   log_noise: -0.797\n",
      "Iter 821/1000 - Loss: 1.409   log_lengthscale: 8.278   log_noise: -0.795\n",
      "Iter 822/1000 - Loss: 1.279   log_lengthscale: 8.281   log_noise: -0.801\n",
      "Iter 823/1000 - Loss: 1.417   log_lengthscale: 8.282   log_noise: -0.818\n",
      "Iter 824/1000 - Loss: 1.266   log_lengthscale: 8.285   log_noise: -0.830\n",
      "Iter 825/1000 - Loss: 1.398   log_lengthscale: 8.288   log_noise: -0.849\n",
      "Iter 826/1000 - Loss: 1.554   log_lengthscale: 8.291   log_noise: -0.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 827/1000 - Loss: 1.707   log_lengthscale: 8.296   log_noise: -0.873\n",
      "Iter 828/1000 - Loss: 1.662   log_lengthscale: 8.299   log_noise: -0.865\n",
      "Iter 829/1000 - Loss: 1.181   log_lengthscale: 8.303   log_noise: -0.849\n",
      "Iter 830/1000 - Loss: 1.452   log_lengthscale: 8.307   log_noise: -0.839\n",
      "Iter 831/1000 - Loss: 1.526   log_lengthscale: 8.311   log_noise: -0.832\n",
      "Iter 832/1000 - Loss: 1.530   log_lengthscale: 8.314   log_noise: -0.820\n",
      "Iter 833/1000 - Loss: 1.344   log_lengthscale: 8.318   log_noise: -0.806\n",
      "Iter 834/1000 - Loss: 1.521   log_lengthscale: 8.321   log_noise: -0.804\n",
      "Iter 835/1000 - Loss: 1.722   log_lengthscale: 8.324   log_noise: -0.796\n",
      "Iter 836/1000 - Loss: 1.310   log_lengthscale: 8.329   log_noise: -0.786\n",
      "Iter 837/1000 - Loss: 1.273   log_lengthscale: 8.333   log_noise: -0.784\n",
      "Iter 838/1000 - Loss: 2.131   log_lengthscale: 8.338   log_noise: -0.786\n",
      "Iter 839/1000 - Loss: 1.455   log_lengthscale: 8.343   log_noise: -0.779\n",
      "Iter 840/1000 - Loss: 1.472   log_lengthscale: 8.347   log_noise: -0.779\n",
      "Iter 841/1000 - Loss: 1.608   log_lengthscale: 8.351   log_noise: -0.788\n",
      "Iter 842/1000 - Loss: 1.409   log_lengthscale: 8.353   log_noise: -0.797\n",
      "Iter 843/1000 - Loss: 1.346   log_lengthscale: 8.357   log_noise: -0.808\n",
      "Iter 844/1000 - Loss: 1.634   log_lengthscale: 8.360   log_noise: -0.825\n",
      "Iter 845/1000 - Loss: 1.361   log_lengthscale: 8.363   log_noise: -0.837\n",
      "Iter 846/1000 - Loss: 1.434   log_lengthscale: 8.366   log_noise: -0.849\n",
      "Iter 847/1000 - Loss: 1.533   log_lengthscale: 8.368   log_noise: -0.863\n",
      "Iter 848/1000 - Loss: 1.450   log_lengthscale: 8.369   log_noise: -0.874\n",
      "Iter 849/1000 - Loss: 1.337   log_lengthscale: 8.370   log_noise: -0.876\n",
      "Iter 850/1000 - Loss: 1.683   log_lengthscale: 8.371   log_noise: -0.877\n",
      "Iter 851/1000 - Loss: 1.556   log_lengthscale: 8.373   log_noise: -0.863\n",
      "Iter 852/1000 - Loss: 1.290   log_lengthscale: 8.375   log_noise: -0.846\n",
      "Iter 853/1000 - Loss: 1.931   log_lengthscale: 8.377   log_noise: -0.837\n",
      "Iter 854/1000 - Loss: 1.567   log_lengthscale: 8.378   log_noise: -0.812\n",
      "Iter 855/1000 - Loss: 1.385   log_lengthscale: 8.381   log_noise: -0.788\n",
      "Iter 856/1000 - Loss: 1.653   log_lengthscale: 8.383   log_noise: -0.775\n",
      "Iter 857/1000 - Loss: 1.356   log_lengthscale: 8.384   log_noise: -0.765\n",
      "Iter 858/1000 - Loss: 1.666   log_lengthscale: 8.388   log_noise: -0.755\n",
      "Iter 859/1000 - Loss: 1.375   log_lengthscale: 8.392   log_noise: -0.748\n",
      "Iter 860/1000 - Loss: 1.536   log_lengthscale: 8.396   log_noise: -0.755\n",
      "Iter 861/1000 - Loss: 1.604   log_lengthscale: 8.399   log_noise: -0.770\n",
      "Iter 862/1000 - Loss: 1.404   log_lengthscale: 8.401   log_noise: -0.790\n",
      "Iter 863/1000 - Loss: 1.250   log_lengthscale: 8.404   log_noise: -0.811\n",
      "Iter 864/1000 - Loss: 1.262   log_lengthscale: 8.407   log_noise: -0.835\n",
      "Iter 865/1000 - Loss: 1.466   log_lengthscale: 8.410   log_noise: -0.864\n",
      "Iter 866/1000 - Loss: 1.426   log_lengthscale: 8.412   log_noise: -0.885\n",
      "Iter 867/1000 - Loss: 1.414   log_lengthscale: 8.414   log_noise: -0.901\n",
      "Iter 868/1000 - Loss: 2.213   log_lengthscale: 8.416   log_noise: -0.901\n",
      "Iter 869/1000 - Loss: 1.357   log_lengthscale: 8.419   log_noise: -0.871\n",
      "Iter 870/1000 - Loss: 1.522   log_lengthscale: 8.421   log_noise: -0.839\n",
      "Iter 871/1000 - Loss: 1.510   log_lengthscale: 8.424   log_noise: -0.806\n",
      "Iter 872/1000 - Loss: 1.657   log_lengthscale: 8.427   log_noise: -0.779\n",
      "Iter 873/1000 - Loss: 1.345   log_lengthscale: 8.429   log_noise: -0.758\n",
      "Iter 874/1000 - Loss: 1.336   log_lengthscale: 8.431   log_noise: -0.749\n",
      "Iter 875/1000 - Loss: 1.606   log_lengthscale: 8.433   log_noise: -0.758\n",
      "Iter 876/1000 - Loss: 1.392   log_lengthscale: 8.435   log_noise: -0.772\n",
      "Iter 877/1000 - Loss: 1.574   log_lengthscale: 8.437   log_noise: -0.794\n",
      "Iter 878/1000 - Loss: 1.603   log_lengthscale: 8.438   log_noise: -0.816\n",
      "Iter 879/1000 - Loss: 1.593   log_lengthscale: 8.439   log_noise: -0.831\n",
      "Iter 880/1000 - Loss: 1.410   log_lengthscale: 8.441   log_noise: -0.831\n",
      "Iter 881/1000 - Loss: 1.363   log_lengthscale: 8.443   log_noise: -0.831\n",
      "Iter 882/1000 - Loss: 1.529   log_lengthscale: 8.444   log_noise: -0.831\n",
      "Iter 883/1000 - Loss: 1.847   log_lengthscale: 8.446   log_noise: -0.830\n",
      "Iter 884/1000 - Loss: 1.488   log_lengthscale: 8.449   log_noise: -0.817\n",
      "Iter 885/1000 - Loss: 1.554   log_lengthscale: 8.451   log_noise: -0.805\n",
      "Iter 886/1000 - Loss: 1.501   log_lengthscale: 8.455   log_noise: -0.784\n",
      "Iter 887/1000 - Loss: 1.887   log_lengthscale: 8.460   log_noise: -0.762\n",
      "Iter 888/1000 - Loss: 1.742   log_lengthscale: 8.466   log_noise: -0.735\n",
      "Iter 889/1000 - Loss: 1.586   log_lengthscale: 8.471   log_noise: -0.716\n",
      "Iter 890/1000 - Loss: 1.369   log_lengthscale: 8.475   log_noise: -0.706\n",
      "Iter 891/1000 - Loss: 1.647   log_lengthscale: 8.479   log_noise: -0.715\n",
      "Iter 892/1000 - Loss: 1.606   log_lengthscale: 8.483   log_noise: -0.735\n",
      "Iter 893/1000 - Loss: 1.563   log_lengthscale: 8.486   log_noise: -0.763\n",
      "Iter 894/1000 - Loss: 1.482   log_lengthscale: 8.488   log_noise: -0.792\n",
      "Iter 895/1000 - Loss: 1.537   log_lengthscale: 8.491   log_noise: -0.819\n",
      "Iter 896/1000 - Loss: 1.679   log_lengthscale: 8.494   log_noise: -0.839\n",
      "Iter 897/1000 - Loss: 1.467   log_lengthscale: 8.497   log_noise: -0.847\n",
      "Iter 898/1000 - Loss: 1.751   log_lengthscale: 8.500   log_noise: -0.848\n",
      "Iter 899/1000 - Loss: 1.660   log_lengthscale: 8.503   log_noise: -0.840\n",
      "Iter 900/1000 - Loss: 1.695   log_lengthscale: 8.505   log_noise: -0.827\n",
      "Iter 901/1000 - Loss: 1.738   log_lengthscale: 8.508   log_noise: -0.808\n",
      "Iter 902/1000 - Loss: 1.477   log_lengthscale: 8.511   log_noise: -0.782\n",
      "Iter 903/1000 - Loss: 1.596   log_lengthscale: 8.514   log_noise: -0.765\n",
      "Iter 904/1000 - Loss: 1.320   log_lengthscale: 8.516   log_noise: -0.759\n",
      "Iter 905/1000 - Loss: 1.632   log_lengthscale: 8.519   log_noise: -0.763\n",
      "Iter 906/1000 - Loss: 1.355   log_lengthscale: 8.521   log_noise: -0.774\n",
      "Iter 907/1000 - Loss: 1.403   log_lengthscale: 8.524   log_noise: -0.790\n",
      "Iter 908/1000 - Loss: 1.299   log_lengthscale: 8.525   log_noise: -0.814\n",
      "Iter 909/1000 - Loss: 1.458   log_lengthscale: 8.527   log_noise: -0.837\n",
      "Iter 910/1000 - Loss: 1.441   log_lengthscale: 8.529   log_noise: -0.860\n",
      "Iter 911/1000 - Loss: 1.313   log_lengthscale: 8.530   log_noise: -0.879\n",
      "Iter 912/1000 - Loss: 1.573   log_lengthscale: 8.532   log_noise: -0.895\n",
      "Iter 913/1000 - Loss: 1.752   log_lengthscale: 8.532   log_noise: -0.902\n",
      "Iter 914/1000 - Loss: 1.433   log_lengthscale: 8.533   log_noise: -0.895\n",
      "Iter 915/1000 - Loss: 1.379   log_lengthscale: 8.535   log_noise: -0.870\n",
      "Iter 916/1000 - Loss: 1.473   log_lengthscale: 8.537   log_noise: -0.847\n",
      "Iter 917/1000 - Loss: 1.528   log_lengthscale: 8.539   log_noise: -0.825\n",
      "Iter 918/1000 - Loss: 1.905   log_lengthscale: 8.542   log_noise: -0.799\n",
      "Iter 919/1000 - Loss: 1.235   log_lengthscale: 8.543   log_noise: -0.773\n",
      "Iter 920/1000 - Loss: 1.639   log_lengthscale: 8.546   log_noise: -0.757\n",
      "Iter 921/1000 - Loss: 1.264   log_lengthscale: 8.547   log_noise: -0.749\n",
      "Iter 922/1000 - Loss: 1.436   log_lengthscale: 8.549   log_noise: -0.754\n",
      "Iter 923/1000 - Loss: 1.640   log_lengthscale: 8.551   log_noise: -0.771\n",
      "Iter 924/1000 - Loss: 1.752   log_lengthscale: 8.553   log_noise: -0.788\n",
      "Iter 925/1000 - Loss: 1.519   log_lengthscale: 8.555   log_noise: -0.794\n",
      "Iter 926/1000 - Loss: 1.940   log_lengthscale: 8.557   log_noise: -0.805\n",
      "Iter 927/1000 - Loss: 1.339   log_lengthscale: 8.559   log_noise: -0.805\n",
      "Iter 928/1000 - Loss: 1.614   log_lengthscale: 8.561   log_noise: -0.812\n",
      "Iter 929/1000 - Loss: 1.655   log_lengthscale: 8.563   log_noise: -0.815\n",
      "Iter 930/1000 - Loss: 1.545   log_lengthscale: 8.566   log_noise: -0.807\n",
      "Iter 931/1000 - Loss: 1.404   log_lengthscale: 8.569   log_noise: -0.801\n",
      "Iter 932/1000 - Loss: 1.737   log_lengthscale: 8.572   log_noise: -0.798\n",
      "Iter 933/1000 - Loss: 1.797   log_lengthscale: 8.574   log_noise: -0.794\n",
      "Iter 934/1000 - Loss: 1.374   log_lengthscale: 8.576   log_noise: -0.785\n",
      "Iter 935/1000 - Loss: 1.711   log_lengthscale: 8.578   log_noise: -0.785\n",
      "Iter 936/1000 - Loss: 1.368   log_lengthscale: 8.581   log_noise: -0.780\n",
      "Iter 937/1000 - Loss: 1.435   log_lengthscale: 8.584   log_noise: -0.782\n",
      "Iter 938/1000 - Loss: 1.342   log_lengthscale: 8.587   log_noise: -0.793\n",
      "Iter 939/1000 - Loss: 2.060   log_lengthscale: 8.591   log_noise: -0.805\n",
      "Iter 940/1000 - Loss: 1.327   log_lengthscale: 8.595   log_noise: -0.796\n",
      "Iter 941/1000 - Loss: 1.527   log_lengthscale: 8.601   log_noise: -0.789\n",
      "Iter 942/1000 - Loss: 1.171   log_lengthscale: 8.605   log_noise: -0.789\n",
      "Iter 943/1000 - Loss: 1.451   log_lengthscale: 8.608   log_noise: -0.805\n",
      "Iter 944/1000 - Loss: 1.438   log_lengthscale: 8.612   log_noise: -0.820\n",
      "Iter 945/1000 - Loss: 1.890   log_lengthscale: 8.616   log_noise: -0.831\n",
      "Iter 946/1000 - Loss: 1.898   log_lengthscale: 8.619   log_noise: -0.830\n",
      "Iter 947/1000 - Loss: 1.570   log_lengthscale: 8.622   log_noise: -0.819\n",
      "Iter 948/1000 - Loss: 1.266   log_lengthscale: 8.625   log_noise: -0.801\n",
      "Iter 949/1000 - Loss: 1.506   log_lengthscale: 8.629   log_noise: -0.795\n",
      "Iter 950/1000 - Loss: 1.237   log_lengthscale: 8.632   log_noise: -0.794\n",
      "Iter 951/1000 - Loss: 1.411   log_lengthscale: 8.635   log_noise: -0.800\n",
      "Iter 952/1000 - Loss: 1.798   log_lengthscale: 8.639   log_noise: -0.809\n",
      "Iter 953/1000 - Loss: 1.899   log_lengthscale: 8.642   log_noise: -0.809\n",
      "Iter 954/1000 - Loss: 1.263   log_lengthscale: 8.646   log_noise: -0.799\n",
      "Iter 955/1000 - Loss: 1.194   log_lengthscale: 8.649   log_noise: -0.801\n",
      "Iter 956/1000 - Loss: 1.544   log_lengthscale: 8.651   log_noise: -0.813\n",
      "Iter 957/1000 - Loss: 1.317   log_lengthscale: 8.654   log_noise: -0.816\n",
      "Iter 958/1000 - Loss: 1.634   log_lengthscale: 8.657   log_noise: -0.829\n",
      "Iter 959/1000 - Loss: 1.921   log_lengthscale: 8.659   log_noise: -0.837\n",
      "Iter 960/1000 - Loss: 1.264   log_lengthscale: 8.660   log_noise: -0.828\n",
      "Iter 961/1000 - Loss: 1.522   log_lengthscale: 8.661   log_noise: -0.828\n",
      "Iter 962/1000 - Loss: 1.162   log_lengthscale: 8.661   log_noise: -0.829\n",
      "Iter 963/1000 - Loss: 1.310   log_lengthscale: 8.660   log_noise: -0.842\n",
      "Iter 964/1000 - Loss: 1.397   log_lengthscale: 8.659   log_noise: -0.852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 965/1000 - Loss: 1.704   log_lengthscale: 8.658   log_noise: -0.862\n",
      "Iter 966/1000 - Loss: 1.478   log_lengthscale: 8.657   log_noise: -0.858\n",
      "Iter 967/1000 - Loss: 1.323   log_lengthscale: 8.657   log_noise: -0.848\n",
      "Iter 968/1000 - Loss: 1.314   log_lengthscale: 8.658   log_noise: -0.839\n",
      "Iter 969/1000 - Loss: 1.286   log_lengthscale: 8.658   log_noise: -0.835\n",
      "Iter 970/1000 - Loss: 1.763   log_lengthscale: 8.658   log_noise: -0.838\n",
      "Iter 971/1000 - Loss: 1.380   log_lengthscale: 8.658   log_noise: -0.831\n",
      "Iter 972/1000 - Loss: 1.341   log_lengthscale: 8.657   log_noise: -0.825\n",
      "Iter 973/1000 - Loss: 1.426   log_lengthscale: 8.656   log_noise: -0.824\n",
      "Iter 974/1000 - Loss: 1.301   log_lengthscale: 8.657   log_noise: -0.823\n",
      "Iter 975/1000 - Loss: 1.532   log_lengthscale: 8.656   log_noise: -0.831\n",
      "Iter 976/1000 - Loss: 1.965   log_lengthscale: 8.656   log_noise: -0.833\n",
      "Iter 977/1000 - Loss: 1.312   log_lengthscale: 8.655   log_noise: -0.823\n",
      "Iter 978/1000 - Loss: 1.376   log_lengthscale: 8.654   log_noise: -0.816\n",
      "Iter 979/1000 - Loss: 1.620   log_lengthscale: 8.653   log_noise: -0.817\n",
      "Iter 980/1000 - Loss: 1.163   log_lengthscale: 8.652   log_noise: -0.816\n",
      "Iter 981/1000 - Loss: 1.799   log_lengthscale: 8.651   log_noise: -0.823\n",
      "Iter 982/1000 - Loss: 1.566   log_lengthscale: 8.649   log_noise: -0.823\n",
      "Iter 983/1000 - Loss: 1.630   log_lengthscale: 8.647   log_noise: -0.822\n",
      "Iter 984/1000 - Loss: 1.550   log_lengthscale: 8.645   log_noise: -0.821\n",
      "Iter 985/1000 - Loss: 1.254   log_lengthscale: 8.644   log_noise: -0.818\n",
      "Iter 986/1000 - Loss: 1.424   log_lengthscale: 8.643   log_noise: -0.822\n",
      "Iter 987/1000 - Loss: 1.852   log_lengthscale: 8.643   log_noise: -0.830\n",
      "Iter 988/1000 - Loss: 1.499   log_lengthscale: 8.643   log_noise: -0.823\n",
      "Iter 989/1000 - Loss: 1.490   log_lengthscale: 8.643   log_noise: -0.818\n",
      "Iter 990/1000 - Loss: 1.276   log_lengthscale: 8.642   log_noise: -0.817\n",
      "Iter 991/1000 - Loss: 1.658   log_lengthscale: 8.642   log_noise: -0.817\n",
      "Iter 992/1000 - Loss: 1.583   log_lengthscale: 8.642   log_noise: -0.811\n",
      "Iter 993/1000 - Loss: 1.941   log_lengthscale: 8.642   log_noise: -0.804\n",
      "Iter 994/1000 - Loss: 1.669   log_lengthscale: 8.644   log_noise: -0.782\n",
      "Iter 995/1000 - Loss: 1.469   log_lengthscale: 8.644   log_noise: -0.762\n",
      "Iter 996/1000 - Loss: 1.467   log_lengthscale: 8.644   log_noise: -0.754\n",
      "Iter 997/1000 - Loss: 1.633   log_lengthscale: 8.644   log_noise: -0.755\n",
      "Iter 998/1000 - Loss: 1.313   log_lengthscale: 8.644   log_noise: -0.761\n",
      "Iter 999/1000 - Loss: 1.496   log_lengthscale: 8.644   log_noise: -0.779\n",
      "Iter 1000/1000 - Loss: 1.714   log_lengthscale: 8.644   log_noise: -0.797\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 1000\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(x_tensor)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f   log_noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.data[0],\n",
    "        model.covar_module.log_lengthscale.data[0, 0],\n",
    "        model.likelihood.log_noise.data[0]\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The input matches the stored training data. Did you forget to call model.train()?\n",
      "/home/lerko/anaconda3/lib/python3.6/site-packages/gpytorch/functions/add_diag.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  val = diag.squeeze()[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument dimensions are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f0b4cf3ac9ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Plot the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0max_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Observed Values (Likelihood)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-f0b4cf3ac9ce>\u001b[0m in \u001b[0;36max_plot\u001b[0;34m(ax, rand_var, title)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Shade between the lower and upper confidence bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_between\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Observed Data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Confidence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lerko/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lerko/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mfill_between\u001b[0;34m(self, x, y1, y2, where, interpolate, step, **kwargs)\u001b[0m\n\u001b[1;32m   4791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4793\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Argument dimensions are incompatible\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4795\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_or\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument dimensions are incompatible"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAADFCAYAAACcjq09AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADVtJREFUeJzt3X9sXeddx/H3p04jX3eYtiQkbn6QSo1AYQJSWVk3kFJt\n7dRGFQHEjzaZqCohy6iFgUDgMglEIrQJIQRjkSNrBDoNLZpGoFEXFtqBlOWPjDpsdP1B1MjOSCIn\ncSnqBLM7LH/5456kl8Q/n3PuPefYn5d05XPOfXyeryPn43Oe89xzFBGYmaW4rewCzKy+HCBmlswB\nYmbJHCBmlswBYmbJHCBmlswBYmbJHCBmlswBYmbJ1pRdwELWrVsX27ZtK7sMs1Xn7Nmzb0XE+sXa\nVTpAtm3bxujoaNllmK06kr69lHY+hTGzZA4QM0tW+wCZmJhg9+7dXLlypexSzFad2gfIwYMHOX36\nNAcOHCi7FLNVR1W+H0h/f3/MN4jaaDSYnp6+ZXt3dzdTU1PtLs1sRZN0NiL6F2tX2yOQsbEx9u3b\nR09PDwA9PT3s37+f8fHxkiszWz1qGyB9fX309vYyPT1Nd3c309PT9Pb2snHjxrJLM1s1ahsgAFev\nXmVwcJAzZ84wODjogVSzDqvtGIiZtc+KHwMxs/I5QMwsmQPEzJI5QMwsmQPEzJI5QMwsmQPEzJI5\nQMwsWe0DxB/nNytPIQEi6Yika5Jened9Sfq0pPOSXpF0fxH9gj/Ob1amoo5A/hp4ZIH3HwW2Z68B\nYDhvh41GA0kMDw8zOzvL8PAwkmg0Gnl3bWZLVEiARMQp4O0FmuwFPhdNZ4A7JfXl6dMf5zcrX6fG\nQDYBF1vWL2XbbiFpQNKopNHJycl5d+iP85uVr3KDqBExEhH9EdG/fv3Cj6Xwx/nNytWp58JcBra0\nrG/OtuVy7NixG8uHDh3KuzszW6ZOHYEcB345uxrzAPBOREx0qG8za5NCjkAkfQF4EFgn6RLwB8Dt\nABFxGDgB7AHOA98FniqiXzMrVyEBEhFPLPJ+AE8X0ZeZVUflBlHNrD4cIGaWzAFiZskcIGaWzAFi\nZskcIGaWzAFiZskcIGaWzAFiZskcIGaWzAFiZskcIGaWzAFiZskcIGaWzAFiZskcIGaWzAFiZskc\nIGaWzAFiZskcIGaWzAFiZskcIGaWzAFiZskcIGaWzAFiZskKCRBJj0g6J+m8pKE53n9Q0juSvpm9\nfr+Ifs2sXLkfbSmpCzgEPAxcAl6WdDwiXr+p6dci4rG8/ZlZdRRxBLILOB8RYxHxPeAosLeA/ZpZ\nxRURIJuAiy3rl7JtN/uQpFck/YOkH51vZ5IGJI1KGp2cnFy084mJCXbv3s2VK1eWXbiZ5dOpQdR/\nBbZGxI8BfwH8/XwNI2IkIvojon/9+vWL7vjgwYOcPn2aAwcOFFetmS1JEQFyGdjSsr4523ZDRHwn\nIv47Wz4B3C5pXZ5OG40GkhgeHmZ2dpbh4WEk0Wg08uzWzJahiAB5Gdgu6V5Ja4HHgeOtDSRtlKRs\neVfW73/m6XRsbIx9+/bR09MDQE9PD/v372d8fDzPbs1sGXJfhYmIGUnPACeBLuBIRLwmaTB7/zDw\n88CvSpoBpoDHIyLy9NvX10dvby/T09N0d3czPT1Nb28vGzduzPkTmdlS5Q4QuHFacuKmbYdblj8D\nfKaIvlpdvXqVwcFBBgYGGBkZYWJiouguzGwBynkg0Fb9/f0xOjpadhlmq46ksxHRv1g7T2U3s2S1\nDxDPAzErT+0DxPNAzMpT2zGQRqPB9PT0Ldu7u7uZmppqd2lmK9qKHwPxPBCz8tU2QDwPxKx8tQ0Q\neG8eyJkzZxgcHPRAqlmH1XYMxMzaZ8WPgZhZ+RwgZpbMAWJmyRwgZpZsRQSIp7OblWNFBIins5uV\no9aXcT2d3aw9VsVlXE9nNytXrQPE09nNylXrAAFPZzcrU63HQMysPVbFGIiZlcsBYmbJHCBmlswB\nYmbJHCBmlqyQAJH0iKRzks5LGprjfUn6dPb+K5LuL6JfMytX7gCR1AUcAh4FdgBPSNpxU7NHge3Z\nawAYztuvmZWviCOQXcD5iBiLiO8BR4G9N7XZC3wums4Ad0rqK6BvMytREQ/X3gRcbFm/BHxgCW02\nAbc8DVvSAM2jFLZu3bpgxxHw7rvLL/i9vtK/t937rEptETA723yVXUsn91f0Pqvy8952W/NVlCIC\npFARMQKMQHMm6kJt330XGo2OlGW2Ihw5Ak89Vdz+igiQy8CWlvXN2bbltlm2NWvgk59M+952zOAv\nap9Vq62rq/kXr6i/okX/fFX792rnvvLu7/6CL18UESAvA9sl3UszFB4H9t3U5jjwjKSjNE9v3omI\nW05flmvNGhi65ZqPmXVK7gCJiBlJzwAngS7gSES8Jmkwe/8wcALYA5wHvgsUeBBlZmUpZAwkIk7Q\nDInWbYdblgN4uoi+zKw6PBPVzJI5QMwsmQPEzJI5QMwsmQPEzJI5QMwsmQPEzJI5QMws2YoIED9c\n26wcKyJA/HBts3LU+sFSfri2WXusigdL+eHaZuWqdYD44dpm5ap1gIAfrm1WplqPgZhZe6yKMRAz\nK9eKCBDPAzErx4oIEM8DMStHrcdAPA/ErD1WxRiI54GYlavWAeJ5IGblqnWAgOeBmJWp1mMgZtYe\nq2IMxMzKtSICxPNAzMqRK0Ak3S3pRUlvZl/vmqfdBUnfkvRNSYWfk3geiFk5co2BSPpj4O2I+JSk\nIeCuiPjdOdpdAPoj4q3l7N/zQMzK0akxkL3Ac9nyc8DP5NzfslyfB9JoNIBmoHgeiFnn5A2QDREx\nkS1fATbM0y6AlySdlTSw0A4lDUgalTQ6OTm5YOfX54FcP9qYmpryPBCzDlr0FEbSS8Bc/yM/ATwX\nEXe2tP2viLhlHETSpoi4LOkHgReBX4uIU4sV51MYs3IUdgoTEQ9FxPvneD0PXJXUl3XYB1ybZx+X\ns6/XgL8Ddi3nh5mPp7KblSvvKcxx4Mls+Ung+ZsbSLpD0vddXwY+Cryas1/AU9nNypY3QD4FPCzp\nTeChbB1J90g6kbXZAJyW9G/AvwBfjoiv5Oz3Bk9lNyuPp7Kb2S08ld3M2s4BYmbJHCBmlswBYmbJ\nHCBmlswBYmbJHCBmlswBYmbJHCBmlswBYmbJHCBmlswBYmbJHCBmlswBYmbJHCBmlswBYmbJHCBm\nlswBYmbJHCBmlswBYmbJVkyATExMsHv3bt+V3ayDVkyADA0NcerUKYaGhsouxWzVqP1jHfx4S7Pi\nrZrHOswXgFUORrOVIleASPoFSa9JmpU0b1pJekTSOUnnJRV6jjE+Ps599933/7Zt376dCxcuFNmN\nmc0h7xHIq8DPAafmayCpCzgEPArsAJ6QtCNnvzf09fUxMzMDwNq1awGYmZnx83HNOmBNnm+OiDcA\nJC3UbBdwPiLGsrZHgb3A63n6brVz50727NnDwMAAIyMjTExMFLVrM1tArgBZok3AxZb1S8AH5mss\naQAYANi6deuSOjh27NiN5UOHDqXUaGYJFg0QSS8Bc50PfCIini+6oIgYAUageRWm6P2bWXEWDZCI\neChnH5eBLS3rm7NtZlZznbiM+zKwXdK9ktYCjwPHO9CvmbVZ3su4PyvpEvBB4MuSTmbb75F0AiAi\nZoBngJPAG8AXI+K1fGWbWRVUeiaqpEng20toug54q83ltIPr7izXvXQ/FBHrF2tU6QBZKkmjS5l2\nWzWuu7Ncd/FqP5XdzMrjADGzZCslQEbKLiCR6+4s112wFTEGYmblWClHIGZWAgeImSWrdYC08z4j\nRZK0RdI/S3o9u3/Kx7Ptd0t6UdKb2de7yq51LpK6JH1D0gvZeuXrlnSnpC9J+ndJb0j6YE3q/s3s\nd+RVSV+Q1F3lumsbIO2+z0jBZoDfiogdwAPA01mtQ8BXI2I78NVsvYo+TnMW8XV1qPvPga9ExI8A\nP06z/krXLWkT8OtAf0S8H+ii+dGP6tYdEbV80Zw+f7Jl/Vng2bLrWmLtzwMPA+eAvmxbH3Cu7Nrm\nqHUzzV/aDwMvZNsqXTfw/cA42UWClu1Vr/v6rS/upvlB1xeAj1a57toegTD3fUY2lVTLkknaBuwE\nvg5siIjrdz+6AmwoqayF/BnwO8Bsy7aq130vMAn8VXbq9VlJd1DxuiPiMvAnwH8AE8A7EfGPVLju\nOgdI7Uh6H/C3wG9ExHda34vmn5dKXVOX9BhwLSLOzteminXT/Ot9PzAcETuB/+Gmw/4q1p2Nbeyl\nGYD3AHdI+lhrm6rVXecAqdV9RiTdTjM8/iYirt9C7aqkvuz9PuBaWfXN4yeBn5Z0ATgKfFjS56l+\n3ZeASxHx9Wz9SzQDpep1PwSMR8RkRPwvcAz4EBWuu84BUpv7jKh509i/BN6IiD9tees48GS2/CTN\nsZHKiIhnI2JzRGyj+e/7TxHxMapf9xXgoqQfzjZ9hOY9eCtdN81Tlwck9WS/Mx+hOfhb2bprPRNV\n0h6a5+hdwJGI+KOSS5qTpJ8CvgZ8i/fGEn6P5jjIF4GtNG9b8IsR8XYpRS5C0oPAb0fEY5J+gIrX\nLekngM8Ca4Ex4CmafzCrXvcfAr9E88rdN4BfAd5HReuudYCYWbnqfApjZiVzgJhZMgeImSVzgJhZ\nMgeImSVzgJhZMgeImSX7P265AMWAUCHtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f54644140b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put model and likelihood into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Test points are regularly spaced along [0,1] every 0.02\n",
    "# Make predictions by feeding model through likelihood\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(x_tensor))\n",
    "\n",
    "# Define plotting function\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = rand_var.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(x_tensor.data.numpy(), rand_var.mean().data.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.data.numpy(), lower.data.numpy(), upper.data.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot the predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_pred.mean().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5464115cf8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAD8CAYAAACl69mTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzFiQMcYYEzP/H5Hm3uwzyqmSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5464274ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(observed_pred.mean().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
