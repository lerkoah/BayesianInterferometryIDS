{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 11 points in [0,1] inclusive regularly spaced\n",
    "x = np.linspace(0,1,50)\n",
    "x_tensor = Variable(torch.from_numpy(x).float())\n",
    "all_index = np.arange(x.shape[0])\n",
    "\n",
    "train_x_index = np.sort(np.random.choice(np.arange(x.shape[0]),11, replace=False))\n",
    "H = np.zeros((x.shape[0], train_x_index.shape[0])).T\n",
    "\n",
    "for q in range(train_x_index.shape[0]):\n",
    "    for p in range(x.shape[0]):\n",
    "        if train_x_index[q] == all_index[p]:\n",
    "            H[q,p] = 1\n",
    "H = H.T\n",
    "\n",
    "train_x = x[train_x_index]\n",
    "train_x = Variable(torch.from_numpy(train_x).float())\n",
    "\n",
    "# True function is sin(2*pi*x) with Gaussian noise N(0,0.04)\n",
    "train_y = Variable(torch.sin(train_x.data * (2 * np.pi)) + torch.randn(train_x.size()) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.random_variables import GaussianRandomVariable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, W, H):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        # Our mean function is constant in the interval [-1,1]\n",
    "        self.mean_module = ConstantMean(constant_bounds=(-1, 1))\n",
    "        # We use the RBF kernel as a universal approximator\n",
    "        self.covar_module = RBFKernel(log_lengthscale_bounds=(-10, 10))\n",
    "        \n",
    "        self.W = torch.from_numpy(W).float()\n",
    "        self.H = torch.from_numpy(H).float()\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "#         print(covar_x.type())\n",
    "#         print(self.W.type())\n",
    "        if self.training:\n",
    "#             print(covar_x.shape)\n",
    "            covar_x = self.H.t().matmul(self.W.t().matmul(covar_x.matmul(self.W.matmul(self.H))))\n",
    "        # Return moddl output as GaussianRandomVariable\n",
    "        return GaussianRandomVariable(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = GaussianLikelihood(log_noise_bounds=(-5, 5))\n",
    "# W = 1*np.ones((train_x.data.shape[0], train_x.data.shape[0]), dtype=np.float)\n",
    "W = np.random.randn(x.shape[0], x.shape[0])\n",
    "W = np.matmul(W.T,W)\n",
    "\n",
    "model = ExactGPModel(x_tensor.data, train_y.data, likelihood, W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lerko/anaconda3/lib/python3.6/site-packages/gpytorch/functions/add_diag.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  val = diag.squeeze()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/1000 - Loss: 2.119   log_lengthscale: 0.000   log_noise: 0.000\n",
      "Iter 2/1000 - Loss: 2.300   log_lengthscale: 0.100   log_noise: -0.100\n",
      "Iter 3/1000 - Loss: 1.921   log_lengthscale: 0.176   log_noise: -0.199\n",
      "Iter 4/1000 - Loss: 2.071   log_lengthscale: 0.262   log_noise: -0.298\n",
      "Iter 5/1000 - Loss: 2.323   log_lengthscale: 0.346   log_noise: -0.397\n",
      "Iter 6/1000 - Loss: 2.296   log_lengthscale: 0.417   log_noise: -0.491\n",
      "Iter 7/1000 - Loss: 2.200   log_lengthscale: 0.483   log_noise: -0.582\n",
      "Iter 8/1000 - Loss: 2.509   log_lengthscale: 0.552   log_noise: -0.669\n",
      "Iter 9/1000 - Loss: 2.415   log_lengthscale: 0.620   log_noise: -0.747\n",
      "Iter 10/1000 - Loss: 2.037   log_lengthscale: 0.698   log_noise: -0.812\n",
      "Iter 11/1000 - Loss: 2.278   log_lengthscale: 0.759   log_noise: -0.874\n",
      "Iter 12/1000 - Loss: 2.253   log_lengthscale: 0.813   log_noise: -0.928\n",
      "Iter 13/1000 - Loss: 1.693   log_lengthscale: 0.874   log_noise: -0.973\n",
      "Iter 14/1000 - Loss: 1.909   log_lengthscale: 0.938   log_noise: -1.013\n",
      "Iter 15/1000 - Loss: 2.073   log_lengthscale: 1.003   log_noise: -1.044\n",
      "Iter 16/1000 - Loss: 1.989   log_lengthscale: 1.073   log_noise: -1.061\n",
      "Iter 17/1000 - Loss: 2.144   log_lengthscale: 1.135   log_noise: -1.067\n",
      "Iter 18/1000 - Loss: 1.973   log_lengthscale: 1.190   log_noise: -1.063\n",
      "Iter 19/1000 - Loss: 1.748   log_lengthscale: 1.224   log_noise: -1.052\n",
      "Iter 20/1000 - Loss: 1.929   log_lengthscale: 1.266   log_noise: -1.036\n",
      "Iter 21/1000 - Loss: 2.196   log_lengthscale: 1.293   log_noise: -1.014\n",
      "Iter 22/1000 - Loss: 2.079   log_lengthscale: 1.324   log_noise: -0.984\n",
      "Iter 23/1000 - Loss: 2.402   log_lengthscale: 1.346   log_noise: -0.946\n",
      "Iter 24/1000 - Loss: 1.708   log_lengthscale: 1.368   log_noise: -0.901\n",
      "Iter 25/1000 - Loss: 2.172   log_lengthscale: 1.402   log_noise: -0.858\n",
      "Iter 26/1000 - Loss: 1.901   log_lengthscale: 1.448   log_noise: -0.813\n",
      "Iter 27/1000 - Loss: 1.684   log_lengthscale: 1.491   log_noise: -0.772\n",
      "Iter 28/1000 - Loss: 2.042   log_lengthscale: 1.527   log_noise: -0.737\n",
      "Iter 29/1000 - Loss: 1.970   log_lengthscale: 1.566   log_noise: -0.705\n",
      "Iter 30/1000 - Loss: 2.027   log_lengthscale: 1.600   log_noise: -0.675\n",
      "Iter 31/1000 - Loss: 2.096   log_lengthscale: 1.639   log_noise: -0.645\n",
      "Iter 32/1000 - Loss: 1.501   log_lengthscale: 1.670   log_noise: -0.617\n",
      "Iter 33/1000 - Loss: 1.916   log_lengthscale: 1.686   log_noise: -0.600\n",
      "Iter 34/1000 - Loss: 1.780   log_lengthscale: 1.691   log_noise: -0.589\n",
      "Iter 35/1000 - Loss: 1.949   log_lengthscale: 1.712   log_noise: -0.585\n",
      "Iter 36/1000 - Loss: 2.075   log_lengthscale: 1.740   log_noise: -0.586\n",
      "Iter 37/1000 - Loss: 1.598   log_lengthscale: 1.772   log_noise: -0.584\n",
      "Iter 38/1000 - Loss: 2.471   log_lengthscale: 1.814   log_noise: -0.590\n",
      "Iter 39/1000 - Loss: 1.731   log_lengthscale: 1.856   log_noise: -0.590\n",
      "Iter 40/1000 - Loss: 1.914   log_lengthscale: 1.898   log_noise: -0.596\n",
      "Iter 41/1000 - Loss: 2.005   log_lengthscale: 1.939   log_noise: -0.601\n",
      "Iter 42/1000 - Loss: 1.831   log_lengthscale: 1.977   log_noise: -0.607\n",
      "Iter 43/1000 - Loss: 1.824   log_lengthscale: 2.002   log_noise: -0.612\n",
      "Iter 44/1000 - Loss: 1.892   log_lengthscale: 2.020   log_noise: -0.617\n",
      "Iter 45/1000 - Loss: 2.155   log_lengthscale: 2.054   log_noise: -0.617\n",
      "Iter 46/1000 - Loss: 1.730   log_lengthscale: 2.106   log_noise: -0.610\n",
      "Iter 47/1000 - Loss: 2.079   log_lengthscale: 2.147   log_noise: -0.602\n",
      "Iter 48/1000 - Loss: 1.919   log_lengthscale: 2.201   log_noise: -0.593\n",
      "Iter 49/1000 - Loss: 2.036   log_lengthscale: 2.258   log_noise: -0.581\n",
      "Iter 50/1000 - Loss: 1.900   log_lengthscale: 2.317   log_noise: -0.566\n",
      "Iter 51/1000 - Loss: 1.710   log_lengthscale: 2.376   log_noise: -0.551\n",
      "Iter 52/1000 - Loss: 2.165   log_lengthscale: 2.415   log_noise: -0.537\n",
      "Iter 53/1000 - Loss: 1.595   log_lengthscale: 2.448   log_noise: -0.521\n",
      "Iter 54/1000 - Loss: 2.031   log_lengthscale: 2.483   log_noise: -0.512\n",
      "Iter 55/1000 - Loss: 2.294   log_lengthscale: 2.514   log_noise: -0.499\n",
      "Iter 56/1000 - Loss: 1.857   log_lengthscale: 2.531   log_noise: -0.483\n",
      "Iter 57/1000 - Loss: 1.784   log_lengthscale: 2.549   log_noise: -0.472\n",
      "Iter 58/1000 - Loss: 2.298   log_lengthscale: 2.572   log_noise: -0.466\n",
      "Iter 59/1000 - Loss: 1.840   log_lengthscale: 2.602   log_noise: -0.459\n",
      "Iter 60/1000 - Loss: 2.083   log_lengthscale: 2.641   log_noise: -0.457\n",
      "Iter 61/1000 - Loss: 2.035   log_lengthscale: 2.681   log_noise: -0.457\n",
      "Iter 62/1000 - Loss: 1.787   log_lengthscale: 2.730   log_noise: -0.462\n",
      "Iter 63/1000 - Loss: 1.911   log_lengthscale: 2.761   log_noise: -0.469\n",
      "Iter 64/1000 - Loss: 1.877   log_lengthscale: 2.805   log_noise: -0.481\n",
      "Iter 65/1000 - Loss: 1.572   log_lengthscale: 2.842   log_noise: -0.492\n",
      "Iter 66/1000 - Loss: 1.994   log_lengthscale: 2.888   log_noise: -0.505\n",
      "Iter 67/1000 - Loss: 1.776   log_lengthscale: 2.933   log_noise: -0.517\n",
      "Iter 68/1000 - Loss: 1.869   log_lengthscale: 2.981   log_noise: -0.530\n",
      "Iter 69/1000 - Loss: 1.600   log_lengthscale: 3.020   log_noise: -0.540\n",
      "Iter 70/1000 - Loss: 1.544   log_lengthscale: 3.046   log_noise: -0.555\n",
      "Iter 71/1000 - Loss: 1.746   log_lengthscale: 3.089   log_noise: -0.572\n",
      "Iter 72/1000 - Loss: 1.958   log_lengthscale: 3.143   log_noise: -0.585\n",
      "Iter 73/1000 - Loss: 1.988   log_lengthscale: 3.202   log_noise: -0.592\n",
      "Iter 74/1000 - Loss: 1.910   log_lengthscale: 3.259   log_noise: -0.591\n",
      "Iter 75/1000 - Loss: 1.666   log_lengthscale: 3.308   log_noise: -0.586\n",
      "Iter 76/1000 - Loss: 1.623   log_lengthscale: 3.342   log_noise: -0.582\n",
      "Iter 77/1000 - Loss: 2.119   log_lengthscale: 3.385   log_noise: -0.575\n",
      "Iter 78/1000 - Loss: 1.733   log_lengthscale: 3.442   log_noise: -0.562\n",
      "Iter 79/1000 - Loss: 1.646   log_lengthscale: 3.506   log_noise: -0.544\n",
      "Iter 80/1000 - Loss: 1.636   log_lengthscale: 3.554   log_noise: -0.531\n",
      "Iter 81/1000 - Loss: 1.803   log_lengthscale: 3.617   log_noise: -0.520\n",
      "Iter 82/1000 - Loss: 1.699   log_lengthscale: 3.669   log_noise: -0.512\n",
      "Iter 83/1000 - Loss: 2.112   log_lengthscale: 3.688   log_noise: -0.510\n",
      "Iter 84/1000 - Loss: 2.447   log_lengthscale: 3.712   log_noise: -0.503\n",
      "Iter 85/1000 - Loss: 2.285   log_lengthscale: 3.704   log_noise: -0.488\n",
      "Iter 86/1000 - Loss: 1.547   log_lengthscale: 3.678   log_noise: -0.469\n",
      "Iter 87/1000 - Loss: 1.696   log_lengthscale: 3.676   log_noise: -0.459\n",
      "Iter 88/1000 - Loss: 1.669   log_lengthscale: 3.684   log_noise: -0.457\n",
      "Iter 89/1000 - Loss: 1.705   log_lengthscale: 3.675   log_noise: -0.460\n",
      "Iter 90/1000 - Loss: 1.932   log_lengthscale: 3.694   log_noise: -0.468\n",
      "Iter 91/1000 - Loss: 1.545   log_lengthscale: 3.718   log_noise: -0.477\n",
      "Iter 92/1000 - Loss: 1.798   log_lengthscale: 3.725   log_noise: -0.495\n",
      "Iter 93/1000 - Loss: 1.710   log_lengthscale: 3.740   log_noise: -0.513\n",
      "Iter 94/1000 - Loss: 1.735   log_lengthscale: 3.774   log_noise: -0.533\n",
      "Iter 95/1000 - Loss: 1.728   log_lengthscale: 3.810   log_noise: -0.550\n",
      "Iter 96/1000 - Loss: 2.152   log_lengthscale: 3.844   log_noise: -0.563\n",
      "Iter 97/1000 - Loss: 1.470   log_lengthscale: 3.869   log_noise: -0.563\n",
      "Iter 98/1000 - Loss: 1.528   log_lengthscale: 3.915   log_noise: -0.567\n",
      "Iter 99/1000 - Loss: 1.488   log_lengthscale: 3.958   log_noise: -0.574\n",
      "Iter 100/1000 - Loss: 1.829   log_lengthscale: 3.985   log_noise: -0.584\n",
      "Iter 101/1000 - Loss: 1.991   log_lengthscale: 4.031   log_noise: -0.586\n",
      "Iter 102/1000 - Loss: 2.035   log_lengthscale: 4.067   log_noise: -0.578\n",
      "Iter 103/1000 - Loss: 1.916   log_lengthscale: 4.105   log_noise: -0.557\n",
      "Iter 104/1000 - Loss: 1.578   log_lengthscale: 4.116   log_noise: -0.532\n",
      "Iter 105/1000 - Loss: 1.616   log_lengthscale: 4.126   log_noise: -0.512\n",
      "Iter 106/1000 - Loss: 1.890   log_lengthscale: 4.147   log_noise: -0.498\n",
      "Iter 107/1000 - Loss: 1.797   log_lengthscale: 4.179   log_noise: -0.482\n",
      "Iter 108/1000 - Loss: 1.819   log_lengthscale: 4.215   log_noise: -0.469\n",
      "Iter 109/1000 - Loss: 1.759   log_lengthscale: 4.253   log_noise: -0.459\n",
      "Iter 110/1000 - Loss: 1.872   log_lengthscale: 4.307   log_noise: -0.450\n",
      "Iter 111/1000 - Loss: 1.770   log_lengthscale: 4.358   log_noise: -0.445\n",
      "Iter 112/1000 - Loss: 2.131   log_lengthscale: 4.406   log_noise: -0.445\n",
      "Iter 113/1000 - Loss: 1.586   log_lengthscale: 4.443   log_noise: -0.441\n",
      "Iter 114/1000 - Loss: 1.775   log_lengthscale: 4.479   log_noise: -0.447\n",
      "Iter 115/1000 - Loss: 1.632   log_lengthscale: 4.523   log_noise: -0.458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 116/1000 - Loss: 1.630   log_lengthscale: 4.556   log_noise: -0.474\n",
      "Iter 117/1000 - Loss: 1.540   log_lengthscale: 4.600   log_noise: -0.492\n",
      "Iter 118/1000 - Loss: 1.804   log_lengthscale: 4.639   log_noise: -0.514\n",
      "Iter 119/1000 - Loss: 1.600   log_lengthscale: 4.671   log_noise: -0.535\n",
      "Iter 120/1000 - Loss: 1.791   log_lengthscale: 4.688   log_noise: -0.556\n",
      "Iter 121/1000 - Loss: 1.625   log_lengthscale: 4.710   log_noise: -0.569\n",
      "Iter 122/1000 - Loss: 1.746   log_lengthscale: 4.734   log_noise: -0.573\n",
      "Iter 123/1000 - Loss: 1.950   log_lengthscale: 4.757   log_noise: -0.570\n",
      "Iter 124/1000 - Loss: 2.039   log_lengthscale: 4.765   log_noise: -0.558\n",
      "Iter 125/1000 - Loss: 1.912   log_lengthscale: 4.776   log_noise: -0.537\n",
      "Iter 126/1000 - Loss: 1.805   log_lengthscale: 4.783   log_noise: -0.513\n",
      "Iter 127/1000 - Loss: 1.581   log_lengthscale: 4.802   log_noise: -0.488\n",
      "Iter 128/1000 - Loss: 1.716   log_lengthscale: 4.804   log_noise: -0.471\n",
      "Iter 129/1000 - Loss: 1.770   log_lengthscale: 4.803   log_noise: -0.459\n",
      "Iter 130/1000 - Loss: 1.775   log_lengthscale: 4.804   log_noise: -0.450\n",
      "Iter 131/1000 - Loss: 1.886   log_lengthscale: 4.801   log_noise: -0.441\n",
      "Iter 132/1000 - Loss: 1.654   log_lengthscale: 4.808   log_noise: -0.437\n",
      "Iter 133/1000 - Loss: 1.948   log_lengthscale: 4.815   log_noise: -0.439\n",
      "Iter 134/1000 - Loss: 1.916   log_lengthscale: 4.820   log_noise: -0.440\n",
      "Iter 135/1000 - Loss: 2.298   log_lengthscale: 4.813   log_noise: -0.445\n",
      "Iter 136/1000 - Loss: 1.522   log_lengthscale: 4.803   log_noise: -0.442\n",
      "Iter 137/1000 - Loss: 1.693   log_lengthscale: 4.800   log_noise: -0.452\n",
      "Iter 138/1000 - Loss: 1.979   log_lengthscale: 4.801   log_noise: -0.466\n",
      "Iter 139/1000 - Loss: 1.482   log_lengthscale: 4.806   log_noise: -0.481\n",
      "Iter 140/1000 - Loss: 1.888   log_lengthscale: 4.810   log_noise: -0.501\n",
      "Iter 141/1000 - Loss: 2.277   log_lengthscale: 4.815   log_noise: -0.516\n",
      "Iter 142/1000 - Loss: 1.399   log_lengthscale: 4.834   log_noise: -0.519\n",
      "Iter 143/1000 - Loss: 1.761   log_lengthscale: 4.846   log_noise: -0.529\n",
      "Iter 144/1000 - Loss: 2.277   log_lengthscale: 4.852   log_noise: -0.539\n",
      "Iter 145/1000 - Loss: 1.710   log_lengthscale: 4.858   log_noise: -0.537\n",
      "Iter 146/1000 - Loss: 1.581   log_lengthscale: 4.852   log_noise: -0.532\n",
      "Iter 147/1000 - Loss: 1.857   log_lengthscale: 4.844   log_noise: -0.527\n",
      "Iter 148/1000 - Loss: 2.217   log_lengthscale: 4.838   log_noise: -0.521\n",
      "Iter 149/1000 - Loss: 1.850   log_lengthscale: 4.823   log_noise: -0.502\n",
      "Iter 150/1000 - Loss: 1.804   log_lengthscale: 4.802   log_noise: -0.480\n",
      "Iter 151/1000 - Loss: 2.146   log_lengthscale: 4.769   log_noise: -0.462\n",
      "Iter 152/1000 - Loss: 1.478   log_lengthscale: 4.740   log_noise: -0.443\n",
      "Iter 153/1000 - Loss: 1.589   log_lengthscale: 4.710   log_noise: -0.435\n",
      "Iter 154/1000 - Loss: 1.725   log_lengthscale: 4.686   log_noise: -0.439\n",
      "Iter 155/1000 - Loss: 1.954   log_lengthscale: 4.663   log_noise: -0.447\n",
      "Iter 156/1000 - Loss: 1.925   log_lengthscale: 4.637   log_noise: -0.454\n",
      "Iter 157/1000 - Loss: 1.905   log_lengthscale: 4.621   log_noise: -0.456\n",
      "Iter 158/1000 - Loss: 1.589   log_lengthscale: 4.600   log_noise: -0.461\n",
      "Iter 159/1000 - Loss: 2.332   log_lengthscale: 4.582   log_noise: -0.471\n",
      "Iter 160/1000 - Loss: 1.742   log_lengthscale: 4.570   log_noise: -0.473\n",
      "Iter 161/1000 - Loss: 1.581   log_lengthscale: 4.544   log_noise: -0.479\n",
      "Iter 162/1000 - Loss: 1.930   log_lengthscale: 4.520   log_noise: -0.490\n",
      "Iter 163/1000 - Loss: 1.620   log_lengthscale: 4.488   log_noise: -0.497\n",
      "Iter 164/1000 - Loss: 1.610   log_lengthscale: 4.477   log_noise: -0.509\n",
      "Iter 165/1000 - Loss: 1.712   log_lengthscale: 4.470   log_noise: -0.527\n",
      "Iter 166/1000 - Loss: 1.726   log_lengthscale: 4.470   log_noise: -0.544\n",
      "Iter 167/1000 - Loss: 1.759   log_lengthscale: 4.470   log_noise: -0.558\n",
      "Iter 168/1000 - Loss: 1.633   log_lengthscale: 4.480   log_noise: -0.564\n",
      "Iter 169/1000 - Loss: 2.038   log_lengthscale: 4.479   log_noise: -0.569\n",
      "Iter 170/1000 - Loss: 1.948   log_lengthscale: 4.500   log_noise: -0.559\n",
      "Iter 171/1000 - Loss: 1.635   log_lengthscale: 4.523   log_noise: -0.536\n",
      "Iter 172/1000 - Loss: 1.741   log_lengthscale: 4.542   log_noise: -0.515\n",
      "Iter 173/1000 - Loss: 1.882   log_lengthscale: 4.562   log_noise: -0.493\n",
      "Iter 174/1000 - Loss: 1.696   log_lengthscale: 4.591   log_noise: -0.463\n",
      "Iter 175/1000 - Loss: 1.965   log_lengthscale: 4.619   log_noise: -0.440\n",
      "Iter 176/1000 - Loss: 2.092   log_lengthscale: 4.641   log_noise: -0.417\n",
      "Iter 177/1000 - Loss: 1.736   log_lengthscale: 4.665   log_noise: -0.396\n",
      "Iter 178/1000 - Loss: 1.544   log_lengthscale: 4.689   log_noise: -0.383\n",
      "Iter 179/1000 - Loss: 1.822   log_lengthscale: 4.720   log_noise: -0.389\n",
      "Iter 180/1000 - Loss: 1.483   log_lengthscale: 4.755   log_noise: -0.404\n",
      "Iter 181/1000 - Loss: 1.715   log_lengthscale: 4.797   log_noise: -0.435\n",
      "Iter 182/1000 - Loss: 1.614   log_lengthscale: 4.828   log_noise: -0.469\n",
      "Iter 183/1000 - Loss: 1.797   log_lengthscale: 4.865   log_noise: -0.506\n",
      "Iter 184/1000 - Loss: 1.550   log_lengthscale: 4.895   log_noise: -0.538\n",
      "Iter 185/1000 - Loss: 1.468   log_lengthscale: 4.910   log_noise: -0.570\n",
      "Iter 186/1000 - Loss: 1.515   log_lengthscale: 4.926   log_noise: -0.598\n",
      "Iter 187/1000 - Loss: 2.009   log_lengthscale: 4.935   log_noise: -0.621\n",
      "Iter 188/1000 - Loss: 1.701   log_lengthscale: 4.944   log_noise: -0.625\n",
      "Iter 189/1000 - Loss: 1.464   log_lengthscale: 4.956   log_noise: -0.618\n",
      "Iter 190/1000 - Loss: 1.909   log_lengthscale: 4.976   log_noise: -0.606\n",
      "Iter 191/1000 - Loss: 1.449   log_lengthscale: 4.998   log_noise: -0.578\n",
      "Iter 192/1000 - Loss: 1.889   log_lengthscale: 5.022   log_noise: -0.554\n",
      "Iter 193/1000 - Loss: 1.902   log_lengthscale: 5.048   log_noise: -0.524\n",
      "Iter 194/1000 - Loss: 1.571   log_lengthscale: 5.074   log_noise: -0.487\n",
      "Iter 195/1000 - Loss: 1.577   log_lengthscale: 5.095   log_noise: -0.461\n",
      "Iter 196/1000 - Loss: 2.095   log_lengthscale: 5.113   log_noise: -0.448\n",
      "Iter 197/1000 - Loss: 2.116   log_lengthscale: 5.137   log_noise: -0.428\n",
      "Iter 198/1000 - Loss: 1.752   log_lengthscale: 5.164   log_noise: -0.410\n",
      "Iter 199/1000 - Loss: 2.333   log_lengthscale: 5.194   log_noise: -0.400\n",
      "Iter 200/1000 - Loss: 1.856   log_lengthscale: 5.219   log_noise: -0.386\n",
      "Iter 201/1000 - Loss: 1.523   log_lengthscale: 5.238   log_noise: -0.383\n",
      "Iter 202/1000 - Loss: 2.136   log_lengthscale: 5.259   log_noise: -0.394\n",
      "Iter 203/1000 - Loss: 1.626   log_lengthscale: 5.284   log_noise: -0.404\n",
      "Iter 204/1000 - Loss: 1.695   log_lengthscale: 5.306   log_noise: -0.426\n",
      "Iter 205/1000 - Loss: 1.492   log_lengthscale: 5.318   log_noise: -0.455\n",
      "Iter 206/1000 - Loss: 1.726   log_lengthscale: 5.327   log_noise: -0.490\n",
      "Iter 207/1000 - Loss: 1.621   log_lengthscale: 5.345   log_noise: -0.523\n",
      "Iter 208/1000 - Loss: 1.390   log_lengthscale: 5.366   log_noise: -0.555\n",
      "Iter 209/1000 - Loss: 1.394   log_lengthscale: 5.390   log_noise: -0.588\n",
      "Iter 210/1000 - Loss: 1.791   log_lengthscale: 5.413   log_noise: -0.619\n",
      "Iter 211/1000 - Loss: 1.560   log_lengthscale: 5.444   log_noise: -0.637\n",
      "Iter 212/1000 - Loss: 1.913   log_lengthscale: 5.469   log_noise: -0.642\n",
      "Iter 213/1000 - Loss: 1.458   log_lengthscale: 5.493   log_noise: -0.627\n",
      "Iter 214/1000 - Loss: 1.693   log_lengthscale: 5.517   log_noise: -0.608\n",
      "Iter 215/1000 - Loss: 1.864   log_lengthscale: 5.545   log_noise: -0.582\n",
      "Iter 216/1000 - Loss: 1.777   log_lengthscale: 5.568   log_noise: -0.545\n",
      "Iter 217/1000 - Loss: 1.583   log_lengthscale: 5.591   log_noise: -0.507\n",
      "Iter 218/1000 - Loss: 1.597   log_lengthscale: 5.613   log_noise: -0.478\n",
      "Iter 219/1000 - Loss: 1.963   log_lengthscale: 5.632   log_noise: -0.457\n",
      "Iter 220/1000 - Loss: 1.739   log_lengthscale: 5.653   log_noise: -0.438\n",
      "Iter 221/1000 - Loss: 1.801   log_lengthscale: 5.674   log_noise: -0.428\n",
      "Iter 222/1000 - Loss: 1.499   log_lengthscale: 5.687   log_noise: -0.427\n",
      "Iter 223/1000 - Loss: 1.669   log_lengthscale: 5.699   log_noise: -0.440\n",
      "Iter 224/1000 - Loss: 1.882   log_lengthscale: 5.707   log_noise: -0.457\n",
      "Iter 225/1000 - Loss: 1.709   log_lengthscale: 5.715   log_noise: -0.468\n",
      "Iter 226/1000 - Loss: 1.835   log_lengthscale: 5.730   log_noise: -0.478\n",
      "Iter 227/1000 - Loss: 1.899   log_lengthscale: 5.751   log_noise: -0.484\n",
      "Iter 228/1000 - Loss: 1.820   log_lengthscale: 5.772   log_noise: -0.488\n",
      "Iter 229/1000 - Loss: 1.733   log_lengthscale: 5.795   log_noise: -0.490\n",
      "Iter 230/1000 - Loss: 1.542   log_lengthscale: 5.812   log_noise: -0.493\n",
      "Iter 231/1000 - Loss: 1.590   log_lengthscale: 5.823   log_noise: -0.502\n",
      "Iter 232/1000 - Loss: 1.629   log_lengthscale: 5.828   log_noise: -0.510\n",
      "Iter 233/1000 - Loss: 1.712   log_lengthscale: 5.836   log_noise: -0.517\n",
      "Iter 234/1000 - Loss: 1.742   log_lengthscale: 5.838   log_noise: -0.523\n",
      "Iter 235/1000 - Loss: 1.466   log_lengthscale: 5.843   log_noise: -0.527\n",
      "Iter 236/1000 - Loss: 1.502   log_lengthscale: 5.849   log_noise: -0.535\n",
      "Iter 237/1000 - Loss: 1.660   log_lengthscale: 5.852   log_noise: -0.545\n",
      "Iter 238/1000 - Loss: 1.700   log_lengthscale: 5.858   log_noise: -0.551\n",
      "Iter 239/1000 - Loss: 1.316   log_lengthscale: 5.869   log_noise: -0.546\n",
      "Iter 240/1000 - Loss: 1.793   log_lengthscale: 5.882   log_noise: -0.550\n",
      "Iter 241/1000 - Loss: 1.669   log_lengthscale: 5.887   log_noise: -0.544\n",
      "Iter 242/1000 - Loss: 1.624   log_lengthscale: 5.891   log_noise: -0.537\n",
      "Iter 243/1000 - Loss: 1.476   log_lengthscale: 5.895   log_noise: -0.528\n",
      "Iter 244/1000 - Loss: 1.737   log_lengthscale: 5.898   log_noise: -0.524\n",
      "Iter 245/1000 - Loss: 1.573   log_lengthscale: 5.901   log_noise: -0.522\n",
      "Iter 246/1000 - Loss: 1.694   log_lengthscale: 5.904   log_noise: -0.520\n",
      "Iter 247/1000 - Loss: 1.565   log_lengthscale: 5.909   log_noise: -0.510\n",
      "Iter 248/1000 - Loss: 1.817   log_lengthscale: 5.914   log_noise: -0.503\n",
      "Iter 249/1000 - Loss: 1.566   log_lengthscale: 5.919   log_noise: -0.491\n",
      "Iter 250/1000 - Loss: 1.926   log_lengthscale: 5.925   log_noise: -0.486\n",
      "Iter 251/1000 - Loss: 1.614   log_lengthscale: 5.929   log_noise: -0.478\n",
      "Iter 252/1000 - Loss: 1.519   log_lengthscale: 5.930   log_noise: -0.478\n",
      "Iter 253/1000 - Loss: 1.409   log_lengthscale: 5.934   log_noise: -0.489\n",
      "Iter 254/1000 - Loss: 1.641   log_lengthscale: 5.939   log_noise: -0.509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 255/1000 - Loss: 1.580   log_lengthscale: 5.942   log_noise: -0.526\n",
      "Iter 256/1000 - Loss: 1.484   log_lengthscale: 5.944   log_noise: -0.540\n",
      "Iter 257/1000 - Loss: 1.666   log_lengthscale: 5.942   log_noise: -0.551\n",
      "Iter 258/1000 - Loss: 1.908   log_lengthscale: 5.944   log_noise: -0.556\n",
      "Iter 259/1000 - Loss: 1.474   log_lengthscale: 5.951   log_noise: -0.549\n",
      "Iter 260/1000 - Loss: 1.606   log_lengthscale: 5.959   log_noise: -0.547\n",
      "Iter 261/1000 - Loss: 1.688   log_lengthscale: 5.973   log_noise: -0.539\n",
      "Iter 262/1000 - Loss: 1.582   log_lengthscale: 5.991   log_noise: -0.529\n",
      "Iter 263/1000 - Loss: 1.907   log_lengthscale: 6.004   log_noise: -0.523\n",
      "Iter 264/1000 - Loss: 1.510   log_lengthscale: 6.016   log_noise: -0.506\n",
      "Iter 265/1000 - Loss: 1.875   log_lengthscale: 6.029   log_noise: -0.490\n",
      "Iter 266/1000 - Loss: 1.766   log_lengthscale: 6.041   log_noise: -0.471\n",
      "Iter 267/1000 - Loss: 1.578   log_lengthscale: 6.049   log_noise: -0.456\n",
      "Iter 268/1000 - Loss: 1.647   log_lengthscale: 6.056   log_noise: -0.447\n",
      "Iter 269/1000 - Loss: 1.993   log_lengthscale: 6.063   log_noise: -0.449\n",
      "Iter 270/1000 - Loss: 1.707   log_lengthscale: 6.073   log_noise: -0.447\n",
      "Iter 271/1000 - Loss: 1.379   log_lengthscale: 6.083   log_noise: -0.449\n",
      "Iter 272/1000 - Loss: 2.181   log_lengthscale: 6.092   log_noise: -0.462\n",
      "Iter 273/1000 - Loss: 1.293   log_lengthscale: 6.103   log_noise: -0.461\n",
      "Iter 274/1000 - Loss: 1.581   log_lengthscale: 6.112   log_noise: -0.477\n",
      "Iter 275/1000 - Loss: 1.475   log_lengthscale: 6.122   log_noise: -0.494\n",
      "Iter 276/1000 - Loss: 1.774   log_lengthscale: 6.133   log_noise: -0.515\n",
      "Iter 277/1000 - Loss: 1.852   log_lengthscale: 6.147   log_noise: -0.528\n",
      "Iter 278/1000 - Loss: 1.847   log_lengthscale: 6.160   log_noise: -0.535\n",
      "Iter 279/1000 - Loss: 1.445   log_lengthscale: 6.175   log_noise: -0.532\n",
      "Iter 280/1000 - Loss: 1.457   log_lengthscale: 6.185   log_noise: -0.536\n",
      "Iter 281/1000 - Loss: 1.748   log_lengthscale: 6.195   log_noise: -0.543\n",
      "Iter 282/1000 - Loss: 1.479   log_lengthscale: 6.208   log_noise: -0.544\n",
      "Iter 283/1000 - Loss: 1.631   log_lengthscale: 6.219   log_noise: -0.549\n",
      "Iter 284/1000 - Loss: 1.407   log_lengthscale: 6.231   log_noise: -0.554\n",
      "Iter 285/1000 - Loss: 1.786   log_lengthscale: 6.242   log_noise: -0.557\n",
      "Iter 286/1000 - Loss: 1.833   log_lengthscale: 6.254   log_noise: -0.551\n",
      "Iter 287/1000 - Loss: 1.953   log_lengthscale: 6.266   log_noise: -0.539\n",
      "Iter 288/1000 - Loss: 1.970   log_lengthscale: 6.279   log_noise: -0.516\n",
      "Iter 289/1000 - Loss: 2.037   log_lengthscale: 6.289   log_noise: -0.486\n",
      "Iter 290/1000 - Loss: 1.521   log_lengthscale: 6.300   log_noise: -0.451\n",
      "Iter 291/1000 - Loss: 1.452   log_lengthscale: 6.313   log_noise: -0.424\n",
      "Iter 292/1000 - Loss: 1.660   log_lengthscale: 6.321   log_noise: -0.414\n",
      "Iter 293/1000 - Loss: 1.433   log_lengthscale: 6.332   log_noise: -0.415\n",
      "Iter 294/1000 - Loss: 1.505   log_lengthscale: 6.342   log_noise: -0.430\n",
      "Iter 295/1000 - Loss: 1.577   log_lengthscale: 6.352   log_noise: -0.454\n",
      "Iter 296/1000 - Loss: 1.545   log_lengthscale: 6.357   log_noise: -0.486\n",
      "Iter 297/1000 - Loss: 1.525   log_lengthscale: 6.358   log_noise: -0.522\n",
      "Iter 298/1000 - Loss: 1.679   log_lengthscale: 6.362   log_noise: -0.550\n",
      "Iter 299/1000 - Loss: 1.389   log_lengthscale: 6.366   log_noise: -0.570\n",
      "Iter 300/1000 - Loss: 1.729   log_lengthscale: 6.371   log_noise: -0.591\n",
      "Iter 301/1000 - Loss: 1.503   log_lengthscale: 6.377   log_noise: -0.598\n",
      "Iter 302/1000 - Loss: 1.431   log_lengthscale: 6.381   log_noise: -0.601\n",
      "Iter 303/1000 - Loss: 1.949   log_lengthscale: 6.384   log_noise: -0.598\n",
      "Iter 304/1000 - Loss: 1.369   log_lengthscale: 6.388   log_noise: -0.576\n",
      "Iter 305/1000 - Loss: 1.724   log_lengthscale: 6.392   log_noise: -0.559\n",
      "Iter 306/1000 - Loss: 1.471   log_lengthscale: 6.398   log_noise: -0.533\n",
      "Iter 307/1000 - Loss: 1.740   log_lengthscale: 6.407   log_noise: -0.509\n",
      "Iter 308/1000 - Loss: 1.922   log_lengthscale: 6.418   log_noise: -0.480\n",
      "Iter 309/1000 - Loss: 1.780   log_lengthscale: 6.427   log_noise: -0.453\n",
      "Iter 310/1000 - Loss: 1.624   log_lengthscale: 6.438   log_noise: -0.432\n",
      "Iter 311/1000 - Loss: 2.086   log_lengthscale: 6.452   log_noise: -0.417\n",
      "Iter 312/1000 - Loss: 1.477   log_lengthscale: 6.462   log_noise: -0.405\n",
      "Iter 313/1000 - Loss: 1.549   log_lengthscale: 6.474   log_noise: -0.405\n",
      "Iter 314/1000 - Loss: 2.172   log_lengthscale: 6.489   log_noise: -0.420\n",
      "Iter 315/1000 - Loss: 1.470   log_lengthscale: 6.503   log_noise: -0.429\n",
      "Iter 316/1000 - Loss: 1.715   log_lengthscale: 6.518   log_noise: -0.453\n",
      "Iter 317/1000 - Loss: 1.755   log_lengthscale: 6.532   log_noise: -0.473\n",
      "Iter 318/1000 - Loss: 1.485   log_lengthscale: 6.546   log_noise: -0.487\n",
      "Iter 319/1000 - Loss: 1.410   log_lengthscale: 6.557   log_noise: -0.508\n",
      "Iter 320/1000 - Loss: 1.677   log_lengthscale: 6.564   log_noise: -0.535\n",
      "Iter 321/1000 - Loss: 1.605   log_lengthscale: 6.571   log_noise: -0.553\n",
      "Iter 322/1000 - Loss: 1.789   log_lengthscale: 6.577   log_noise: -0.570\n",
      "Iter 323/1000 - Loss: 1.865   log_lengthscale: 6.584   log_noise: -0.579\n",
      "Iter 324/1000 - Loss: 1.475   log_lengthscale: 6.591   log_noise: -0.571\n",
      "Iter 325/1000 - Loss: 2.351   log_lengthscale: 6.599   log_noise: -0.563\n",
      "Iter 326/1000 - Loss: 1.746   log_lengthscale: 6.605   log_noise: -0.529\n",
      "Iter 327/1000 - Loss: 1.692   log_lengthscale: 6.611   log_noise: -0.498\n",
      "Iter 328/1000 - Loss: 1.440   log_lengthscale: 6.620   log_noise: -0.469\n",
      "Iter 329/1000 - Loss: 1.791   log_lengthscale: 6.630   log_noise: -0.454\n",
      "Iter 330/1000 - Loss: 1.680   log_lengthscale: 6.638   log_noise: -0.442\n",
      "Iter 331/1000 - Loss: 1.657   log_lengthscale: 6.648   log_noise: -0.432\n",
      "Iter 332/1000 - Loss: 1.863   log_lengthscale: 6.657   log_noise: -0.431\n",
      "Iter 333/1000 - Loss: 1.598   log_lengthscale: 6.663   log_noise: -0.432\n",
      "Iter 334/1000 - Loss: 1.460   log_lengthscale: 6.668   log_noise: -0.446\n",
      "Iter 335/1000 - Loss: 1.998   log_lengthscale: 6.673   log_noise: -0.471\n",
      "Iter 336/1000 - Loss: 1.721   log_lengthscale: 6.680   log_noise: -0.492\n",
      "Iter 337/1000 - Loss: 1.626   log_lengthscale: 6.684   log_noise: -0.514\n",
      "Iter 338/1000 - Loss: 1.751   log_lengthscale: 6.688   log_noise: -0.539\n",
      "Iter 339/1000 - Loss: 1.502   log_lengthscale: 6.691   log_noise: -0.558\n",
      "Iter 340/1000 - Loss: 1.340   log_lengthscale: 6.695   log_noise: -0.574\n",
      "Iter 341/1000 - Loss: 1.493   log_lengthscale: 6.702   log_noise: -0.588\n",
      "Iter 342/1000 - Loss: 1.751   log_lengthscale: 6.709   log_noise: -0.600\n",
      "Iter 343/1000 - Loss: 1.852   log_lengthscale: 6.721   log_noise: -0.594\n",
      "Iter 344/1000 - Loss: 1.686   log_lengthscale: 6.730   log_noise: -0.572\n",
      "Iter 345/1000 - Loss: 1.472   log_lengthscale: 6.739   log_noise: -0.545\n",
      "Iter 346/1000 - Loss: 1.782   log_lengthscale: 6.749   log_noise: -0.521\n",
      "Iter 347/1000 - Loss: 2.011   log_lengthscale: 6.757   log_noise: -0.497\n",
      "Iter 348/1000 - Loss: 1.727   log_lengthscale: 6.769   log_noise: -0.463\n",
      "Iter 349/1000 - Loss: 1.569   log_lengthscale: 6.782   log_noise: -0.438\n",
      "Iter 350/1000 - Loss: 1.718   log_lengthscale: 6.795   log_noise: -0.426\n",
      "Iter 351/1000 - Loss: 1.902   log_lengthscale: 6.808   log_noise: -0.422\n",
      "Iter 352/1000 - Loss: 1.803   log_lengthscale: 6.821   log_noise: -0.420\n",
      "Iter 353/1000 - Loss: 1.558   log_lengthscale: 6.835   log_noise: -0.424\n",
      "Iter 354/1000 - Loss: 1.380   log_lengthscale: 6.850   log_noise: -0.432\n",
      "Iter 355/1000 - Loss: 1.534   log_lengthscale: 6.864   log_noise: -0.458\n",
      "Iter 356/1000 - Loss: 1.964   log_lengthscale: 6.878   log_noise: -0.490\n",
      "Iter 357/1000 - Loss: 1.607   log_lengthscale: 6.891   log_noise: -0.508\n",
      "Iter 358/1000 - Loss: 1.464   log_lengthscale: 6.904   log_noise: -0.529\n",
      "Iter 359/1000 - Loss: 1.683   log_lengthscale: 6.917   log_noise: -0.550\n",
      "Iter 360/1000 - Loss: 2.027   log_lengthscale: 6.929   log_noise: -0.564\n",
      "Iter 361/1000 - Loss: 1.624   log_lengthscale: 6.940   log_noise: -0.558\n",
      "Iter 362/1000 - Loss: 1.979   log_lengthscale: 6.953   log_noise: -0.546\n",
      "Iter 363/1000 - Loss: 1.582   log_lengthscale: 6.967   log_noise: -0.516\n",
      "Iter 364/1000 - Loss: 1.735   log_lengthscale: 6.982   log_noise: -0.489\n",
      "Iter 365/1000 - Loss: 1.598   log_lengthscale: 6.997   log_noise: -0.453\n",
      "Iter 366/1000 - Loss: 1.817   log_lengthscale: 7.012   log_noise: -0.423\n",
      "Iter 367/1000 - Loss: 1.651   log_lengthscale: 7.028   log_noise: -0.402\n",
      "Iter 368/1000 - Loss: 1.352   log_lengthscale: 7.042   log_noise: -0.398\n",
      "Iter 369/1000 - Loss: 1.253   log_lengthscale: 7.054   log_noise: -0.416\n",
      "Iter 370/1000 - Loss: 1.823   log_lengthscale: 7.065   log_noise: -0.455\n",
      "Iter 371/1000 - Loss: 1.744   log_lengthscale: 7.075   log_noise: -0.493\n",
      "Iter 372/1000 - Loss: 1.774   log_lengthscale: 7.083   log_noise: -0.525\n",
      "Iter 373/1000 - Loss: 1.539   log_lengthscale: 7.090   log_noise: -0.550\n",
      "Iter 374/1000 - Loss: 1.465   log_lengthscale: 7.099   log_noise: -0.567\n",
      "Iter 375/1000 - Loss: 1.895   log_lengthscale: 7.108   log_noise: -0.580\n",
      "Iter 376/1000 - Loss: 1.696   log_lengthscale: 7.116   log_noise: -0.576\n",
      "Iter 377/1000 - Loss: 1.642   log_lengthscale: 7.124   log_noise: -0.566\n",
      "Iter 378/1000 - Loss: 1.337   log_lengthscale: 7.132   log_noise: -0.550\n",
      "Iter 379/1000 - Loss: 1.885   log_lengthscale: 7.141   log_noise: -0.535\n",
      "Iter 380/1000 - Loss: 1.409   log_lengthscale: 7.151   log_noise: -0.515\n",
      "Iter 381/1000 - Loss: 1.759   log_lengthscale: 7.161   log_noise: -0.502\n",
      "Iter 382/1000 - Loss: 1.499   log_lengthscale: 7.171   log_noise: -0.482\n",
      "Iter 383/1000 - Loss: 1.473   log_lengthscale: 7.181   log_noise: -0.474\n",
      "Iter 384/1000 - Loss: 1.396   log_lengthscale: 7.192   log_noise: -0.472\n",
      "Iter 385/1000 - Loss: 2.163   log_lengthscale: 7.201   log_noise: -0.484\n",
      "Iter 386/1000 - Loss: 1.668   log_lengthscale: 7.210   log_noise: -0.476\n",
      "Iter 387/1000 - Loss: 1.410   log_lengthscale: 7.220   log_noise: -0.469\n",
      "Iter 388/1000 - Loss: 1.490   log_lengthscale: 7.230   log_noise: -0.471\n",
      "Iter 389/1000 - Loss: 1.625   log_lengthscale: 7.241   log_noise: -0.476\n",
      "Iter 390/1000 - Loss: 1.778   log_lengthscale: 7.249   log_noise: -0.486\n",
      "Iter 391/1000 - Loss: 1.550   log_lengthscale: 7.256   log_noise: -0.495\n",
      "Iter 392/1000 - Loss: 1.841   log_lengthscale: 7.265   log_noise: -0.512\n",
      "Iter 393/1000 - Loss: 1.672   log_lengthscale: 7.273   log_noise: -0.525\n",
      "Iter 394/1000 - Loss: 1.960   log_lengthscale: 7.281   log_noise: -0.536\n",
      "Iter 395/1000 - Loss: 1.640   log_lengthscale: 7.289   log_noise: -0.538\n",
      "Iter 396/1000 - Loss: 1.553   log_lengthscale: 7.298   log_noise: -0.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 397/1000 - Loss: 1.808   log_lengthscale: 7.307   log_noise: -0.527\n",
      "Iter 398/1000 - Loss: 1.887   log_lengthscale: 7.317   log_noise: -0.511\n",
      "Iter 399/1000 - Loss: 1.749   log_lengthscale: 7.327   log_noise: -0.482\n",
      "Iter 400/1000 - Loss: 1.576   log_lengthscale: 7.337   log_noise: -0.456\n",
      "Iter 401/1000 - Loss: 1.522   log_lengthscale: 7.348   log_noise: -0.432\n",
      "Iter 402/1000 - Loss: 1.944   log_lengthscale: 7.360   log_noise: -0.419\n",
      "Iter 403/1000 - Loss: 1.583   log_lengthscale: 7.374   log_noise: -0.404\n",
      "Iter 404/1000 - Loss: 1.474   log_lengthscale: 7.387   log_noise: -0.403\n",
      "Iter 405/1000 - Loss: 1.475   log_lengthscale: 7.401   log_noise: -0.418\n",
      "Iter 406/1000 - Loss: 1.543   log_lengthscale: 7.412   log_noise: -0.446\n",
      "Iter 407/1000 - Loss: 1.799   log_lengthscale: 7.423   log_noise: -0.485\n",
      "Iter 408/1000 - Loss: 1.896   log_lengthscale: 7.432   log_noise: -0.518\n",
      "Iter 409/1000 - Loss: 1.704   log_lengthscale: 7.442   log_noise: -0.542\n",
      "Iter 410/1000 - Loss: 1.531   log_lengthscale: 7.452   log_noise: -0.555\n",
      "Iter 411/1000 - Loss: 1.666   log_lengthscale: 7.460   log_noise: -0.569\n",
      "Iter 412/1000 - Loss: 1.456   log_lengthscale: 7.466   log_noise: -0.573\n",
      "Iter 413/1000 - Loss: 1.594   log_lengthscale: 7.473   log_noise: -0.570\n",
      "Iter 414/1000 - Loss: 1.696   log_lengthscale: 7.479   log_noise: -0.565\n",
      "Iter 415/1000 - Loss: 1.502   log_lengthscale: 7.487   log_noise: -0.549\n",
      "Iter 416/1000 - Loss: 1.629   log_lengthscale: 7.494   log_noise: -0.532\n",
      "Iter 417/1000 - Loss: 1.618   log_lengthscale: 7.501   log_noise: -0.516\n",
      "Iter 418/1000 - Loss: 1.431   log_lengthscale: 7.507   log_noise: -0.502\n",
      "Iter 419/1000 - Loss: 1.594   log_lengthscale: 7.512   log_noise: -0.499\n",
      "Iter 420/1000 - Loss: 1.863   log_lengthscale: 7.518   log_noise: -0.498\n",
      "Iter 421/1000 - Loss: 2.077   log_lengthscale: 7.524   log_noise: -0.493\n",
      "Iter 422/1000 - Loss: 1.638   log_lengthscale: 7.529   log_noise: -0.483\n",
      "Iter 423/1000 - Loss: 1.761   log_lengthscale: 7.534   log_noise: -0.477\n",
      "Iter 424/1000 - Loss: 2.114   log_lengthscale: 7.540   log_noise: -0.469\n",
      "Iter 425/1000 - Loss: 1.452   log_lengthscale: 7.545   log_noise: -0.454\n",
      "Iter 426/1000 - Loss: 1.271   log_lengthscale: 7.551   log_noise: -0.451\n",
      "Iter 427/1000 - Loss: 1.607   log_lengthscale: 7.557   log_noise: -0.462\n",
      "Iter 428/1000 - Loss: 1.354   log_lengthscale: 7.563   log_noise: -0.479\n",
      "Iter 429/1000 - Loss: 1.606   log_lengthscale: 7.568   log_noise: -0.505\n",
      "Iter 430/1000 - Loss: 1.813   log_lengthscale: 7.575   log_noise: -0.528\n",
      "Iter 431/1000 - Loss: 1.752   log_lengthscale: 7.582   log_noise: -0.547\n",
      "Iter 432/1000 - Loss: 1.546   log_lengthscale: 7.587   log_noise: -0.558\n",
      "Iter 433/1000 - Loss: 1.857   log_lengthscale: 7.595   log_noise: -0.556\n",
      "Iter 434/1000 - Loss: 1.464   log_lengthscale: 7.603   log_noise: -0.545\n",
      "Iter 435/1000 - Loss: 1.734   log_lengthscale: 7.611   log_noise: -0.534\n",
      "Iter 436/1000 - Loss: 1.283   log_lengthscale: 7.618   log_noise: -0.522\n",
      "Iter 437/1000 - Loss: 1.382   log_lengthscale: 7.625   log_noise: -0.522\n",
      "Iter 438/1000 - Loss: 1.294   log_lengthscale: 7.633   log_noise: -0.526\n",
      "Iter 439/1000 - Loss: 1.391   log_lengthscale: 7.640   log_noise: -0.539\n",
      "Iter 440/1000 - Loss: 1.557   log_lengthscale: 7.648   log_noise: -0.552\n",
      "Iter 441/1000 - Loss: 1.934   log_lengthscale: 7.654   log_noise: -0.561\n",
      "Iter 442/1000 - Loss: 1.513   log_lengthscale: 7.661   log_noise: -0.554\n",
      "Iter 443/1000 - Loss: 1.536   log_lengthscale: 7.668   log_noise: -0.545\n",
      "Iter 444/1000 - Loss: 1.415   log_lengthscale: 7.676   log_noise: -0.532\n",
      "Iter 445/1000 - Loss: 1.583   log_lengthscale: 7.684   log_noise: -0.526\n",
      "Iter 446/1000 - Loss: 1.778   log_lengthscale: 7.691   log_noise: -0.518\n",
      "Iter 447/1000 - Loss: 1.659   log_lengthscale: 7.699   log_noise: -0.504\n",
      "Iter 448/1000 - Loss: 1.637   log_lengthscale: 7.707   log_noise: -0.486\n",
      "Iter 449/1000 - Loss: 1.450   log_lengthscale: 7.715   log_noise: -0.473\n",
      "Iter 450/1000 - Loss: 1.572   log_lengthscale: 7.724   log_noise: -0.467\n",
      "Iter 451/1000 - Loss: 1.930   log_lengthscale: 7.733   log_noise: -0.465\n",
      "Iter 452/1000 - Loss: 1.610   log_lengthscale: 7.743   log_noise: -0.451\n",
      "Iter 453/1000 - Loss: 1.589   log_lengthscale: 7.754   log_noise: -0.445\n",
      "Iter 454/1000 - Loss: 1.723   log_lengthscale: 7.765   log_noise: -0.448\n",
      "Iter 455/1000 - Loss: 1.573   log_lengthscale: 7.774   log_noise: -0.457\n",
      "Iter 456/1000 - Loss: 1.462   log_lengthscale: 7.784   log_noise: -0.473\n",
      "Iter 457/1000 - Loss: 1.967   log_lengthscale: 7.793   log_noise: -0.494\n",
      "Iter 458/1000 - Loss: 2.155   log_lengthscale: 7.803   log_noise: -0.501\n",
      "Iter 459/1000 - Loss: 1.430   log_lengthscale: 7.813   log_noise: -0.490\n",
      "Iter 460/1000 - Loss: 2.136   log_lengthscale: 7.823   log_noise: -0.485\n",
      "Iter 461/1000 - Loss: 1.792   log_lengthscale: 7.833   log_noise: -0.467\n",
      "Iter 462/1000 - Loss: 1.605   log_lengthscale: 7.842   log_noise: -0.454\n",
      "Iter 463/1000 - Loss: 1.620   log_lengthscale: 7.850   log_noise: -0.446\n",
      "Iter 464/1000 - Loss: 1.863   log_lengthscale: 7.858   log_noise: -0.444\n",
      "Iter 465/1000 - Loss: 1.572   log_lengthscale: 7.865   log_noise: -0.443\n",
      "Iter 466/1000 - Loss: 1.581   log_lengthscale: 7.872   log_noise: -0.450\n",
      "Iter 467/1000 - Loss: 1.414   log_lengthscale: 7.879   log_noise: -0.463\n",
      "Iter 468/1000 - Loss: 1.472   log_lengthscale: 7.885   log_noise: -0.487\n",
      "Iter 469/1000 - Loss: 1.812   log_lengthscale: 7.892   log_noise: -0.507\n",
      "Iter 470/1000 - Loss: 1.628   log_lengthscale: 7.899   log_noise: -0.521\n",
      "Iter 471/1000 - Loss: 1.526   log_lengthscale: 7.906   log_noise: -0.532\n",
      "Iter 472/1000 - Loss: 1.607   log_lengthscale: 7.911   log_noise: -0.549\n",
      "Iter 473/1000 - Loss: 1.663   log_lengthscale: 7.915   log_noise: -0.563\n",
      "Iter 474/1000 - Loss: 1.837   log_lengthscale: 7.920   log_noise: -0.569\n",
      "Iter 475/1000 - Loss: 1.653   log_lengthscale: 7.925   log_noise: -0.563\n",
      "Iter 476/1000 - Loss: 1.493   log_lengthscale: 7.931   log_noise: -0.548\n",
      "Iter 477/1000 - Loss: 1.733   log_lengthscale: 7.937   log_noise: -0.535\n",
      "Iter 478/1000 - Loss: 1.579   log_lengthscale: 7.943   log_noise: -0.517\n",
      "Iter 479/1000 - Loss: 1.659   log_lengthscale: 7.949   log_noise: -0.500\n",
      "Iter 480/1000 - Loss: 1.833   log_lengthscale: 7.955   log_noise: -0.483\n",
      "Iter 481/1000 - Loss: 1.463   log_lengthscale: 7.961   log_noise: -0.467\n",
      "Iter 482/1000 - Loss: 1.680   log_lengthscale: 7.967   log_noise: -0.460\n",
      "Iter 483/1000 - Loss: 1.865   log_lengthscale: 7.973   log_noise: -0.456\n",
      "Iter 484/1000 - Loss: 1.522   log_lengthscale: 7.979   log_noise: -0.453\n",
      "Iter 485/1000 - Loss: 1.603   log_lengthscale: 7.985   log_noise: -0.458\n",
      "Iter 486/1000 - Loss: 1.494   log_lengthscale: 7.992   log_noise: -0.464\n",
      "Iter 487/1000 - Loss: 1.502   log_lengthscale: 8.000   log_noise: -0.473\n",
      "Iter 488/1000 - Loss: 1.655   log_lengthscale: 8.008   log_noise: -0.486\n",
      "Iter 489/1000 - Loss: 1.500   log_lengthscale: 8.015   log_noise: -0.499\n",
      "Iter 490/1000 - Loss: 1.707   log_lengthscale: 8.022   log_noise: -0.516\n",
      "Iter 491/1000 - Loss: 1.748   log_lengthscale: 8.028   log_noise: -0.528\n",
      "Iter 492/1000 - Loss: 1.414   log_lengthscale: 8.033   log_noise: -0.534\n",
      "Iter 493/1000 - Loss: 2.016   log_lengthscale: 8.039   log_noise: -0.541\n",
      "Iter 494/1000 - Loss: 1.505   log_lengthscale: 8.044   log_noise: -0.529\n",
      "Iter 495/1000 - Loss: 1.316   log_lengthscale: 8.048   log_noise: -0.521\n",
      "Iter 496/1000 - Loss: 1.790   log_lengthscale: 8.053   log_noise: -0.521\n",
      "Iter 497/1000 - Loss: 1.784   log_lengthscale: 8.058   log_noise: -0.514\n",
      "Iter 498/1000 - Loss: 1.823   log_lengthscale: 8.063   log_noise: -0.502\n",
      "Iter 499/1000 - Loss: 1.574   log_lengthscale: 8.070   log_noise: -0.478\n",
      "Iter 500/1000 - Loss: 1.507   log_lengthscale: 8.077   log_noise: -0.461\n",
      "Iter 501/1000 - Loss: 1.595   log_lengthscale: 8.084   log_noise: -0.449\n",
      "Iter 502/1000 - Loss: 1.726   log_lengthscale: 8.092   log_noise: -0.442\n",
      "Iter 503/1000 - Loss: 1.471   log_lengthscale: 8.100   log_noise: -0.441\n",
      "Iter 504/1000 - Loss: 1.911   log_lengthscale: 8.107   log_noise: -0.450\n",
      "Iter 505/1000 - Loss: 1.783   log_lengthscale: 8.114   log_noise: -0.456\n",
      "Iter 506/1000 - Loss: 1.679   log_lengthscale: 8.120   log_noise: -0.465\n",
      "Iter 507/1000 - Loss: 1.668   log_lengthscale: 8.127   log_noise: -0.474\n",
      "Iter 508/1000 - Loss: 1.533   log_lengthscale: 8.132   log_noise: -0.489\n",
      "Iter 509/1000 - Loss: 1.420   log_lengthscale: 8.137   log_noise: -0.510\n",
      "Iter 510/1000 - Loss: 1.736   log_lengthscale: 8.142   log_noise: -0.536\n",
      "Iter 511/1000 - Loss: 1.336   log_lengthscale: 8.148   log_noise: -0.552\n",
      "Iter 512/1000 - Loss: 1.650   log_lengthscale: 8.154   log_noise: -0.567\n",
      "Iter 513/1000 - Loss: 1.842   log_lengthscale: 8.160   log_noise: -0.568\n",
      "Iter 514/1000 - Loss: 1.978   log_lengthscale: 8.166   log_noise: -0.557\n",
      "Iter 515/1000 - Loss: 1.825   log_lengthscale: 8.172   log_noise: -0.535\n",
      "Iter 516/1000 - Loss: 1.777   log_lengthscale: 8.177   log_noise: -0.512\n",
      "Iter 517/1000 - Loss: 1.511   log_lengthscale: 8.181   log_noise: -0.485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 518/1000 - Loss: 1.707   log_lengthscale: 8.186   log_noise: -0.465\n",
      "Iter 519/1000 - Loss: 1.450   log_lengthscale: 8.190   log_noise: -0.454\n",
      "Iter 520/1000 - Loss: 1.576   log_lengthscale: 8.195   log_noise: -0.454\n",
      "Iter 521/1000 - Loss: 2.135   log_lengthscale: 8.200   log_noise: -0.460\n",
      "Iter 522/1000 - Loss: 1.845   log_lengthscale: 8.205   log_noise: -0.458\n",
      "Iter 523/1000 - Loss: 1.598   log_lengthscale: 8.211   log_noise: -0.456\n",
      "Iter 524/1000 - Loss: 1.730   log_lengthscale: 8.215   log_noise: -0.464\n",
      "Iter 525/1000 - Loss: 1.366   log_lengthscale: 8.220   log_noise: -0.477\n",
      "Iter 526/1000 - Loss: 1.863   log_lengthscale: 8.226   log_noise: -0.494\n",
      "Iter 527/1000 - Loss: 1.660   log_lengthscale: 8.232   log_noise: -0.506\n",
      "Iter 528/1000 - Loss: 1.685   log_lengthscale: 8.238   log_noise: -0.516\n",
      "Iter 529/1000 - Loss: 1.689   log_lengthscale: 8.244   log_noise: -0.517\n",
      "Iter 530/1000 - Loss: 1.372   log_lengthscale: 8.251   log_noise: -0.512\n",
      "Iter 531/1000 - Loss: 1.770   log_lengthscale: 8.259   log_noise: -0.505\n",
      "Iter 532/1000 - Loss: 1.419   log_lengthscale: 8.266   log_noise: -0.495\n",
      "Iter 533/1000 - Loss: 1.608   log_lengthscale: 8.274   log_noise: -0.492\n",
      "Iter 534/1000 - Loss: 1.414   log_lengthscale: 8.280   log_noise: -0.493\n",
      "Iter 535/1000 - Loss: 1.472   log_lengthscale: 8.286   log_noise: -0.499\n",
      "Iter 536/1000 - Loss: 2.292   log_lengthscale: 8.292   log_noise: -0.508\n",
      "Iter 537/1000 - Loss: 1.453   log_lengthscale: 8.296   log_noise: -0.499\n",
      "Iter 538/1000 - Loss: 1.973   log_lengthscale: 8.301   log_noise: -0.496\n",
      "Iter 539/1000 - Loss: 1.660   log_lengthscale: 8.305   log_noise: -0.488\n",
      "Iter 540/1000 - Loss: 1.642   log_lengthscale: 8.308   log_noise: -0.481\n",
      "Iter 541/1000 - Loss: 1.309   log_lengthscale: 8.312   log_noise: -0.476\n",
      "Iter 542/1000 - Loss: 1.599   log_lengthscale: 8.315   log_noise: -0.487\n",
      "Iter 543/1000 - Loss: 1.574   log_lengthscale: 8.318   log_noise: -0.502\n",
      "Iter 544/1000 - Loss: 1.614   log_lengthscale: 8.320   log_noise: -0.520\n",
      "Iter 545/1000 - Loss: 1.999   log_lengthscale: 8.323   log_noise: -0.534\n",
      "Iter 546/1000 - Loss: 1.530   log_lengthscale: 8.327   log_noise: -0.529\n",
      "Iter 547/1000 - Loss: 1.553   log_lengthscale: 8.330   log_noise: -0.527\n",
      "Iter 548/1000 - Loss: 1.591   log_lengthscale: 8.332   log_noise: -0.529\n",
      "Iter 549/1000 - Loss: 1.597   log_lengthscale: 8.335   log_noise: -0.527\n",
      "Iter 550/1000 - Loss: 1.696   log_lengthscale: 8.339   log_noise: -0.519\n",
      "Iter 551/1000 - Loss: 1.930   log_lengthscale: 8.342   log_noise: -0.512\n",
      "Iter 552/1000 - Loss: 2.015   log_lengthscale: 8.345   log_noise: -0.497\n",
      "Iter 553/1000 - Loss: 1.535   log_lengthscale: 8.346   log_noise: -0.475\n",
      "Iter 554/1000 - Loss: 1.680   log_lengthscale: 8.348   log_noise: -0.461\n",
      "Iter 555/1000 - Loss: 1.636   log_lengthscale: 8.351   log_noise: -0.448\n",
      "Iter 556/1000 - Loss: 1.598   log_lengthscale: 8.353   log_noise: -0.445\n",
      "Iter 557/1000 - Loss: 1.755   log_lengthscale: 8.355   log_noise: -0.452\n",
      "Iter 558/1000 - Loss: 1.399   log_lengthscale: 8.358   log_noise: -0.460\n",
      "Iter 559/1000 - Loss: 1.526   log_lengthscale: 8.361   log_noise: -0.481\n",
      "Iter 560/1000 - Loss: 1.465   log_lengthscale: 8.364   log_noise: -0.507\n",
      "Iter 561/1000 - Loss: 1.704   log_lengthscale: 8.368   log_noise: -0.530\n",
      "Iter 562/1000 - Loss: 1.707   log_lengthscale: 8.372   log_noise: -0.545\n",
      "Iter 563/1000 - Loss: 1.980   log_lengthscale: 8.377   log_noise: -0.550\n",
      "Iter 564/1000 - Loss: 1.470   log_lengthscale: 8.380   log_noise: -0.542\n",
      "Iter 565/1000 - Loss: 1.626   log_lengthscale: 8.383   log_noise: -0.534\n",
      "Iter 566/1000 - Loss: 1.732   log_lengthscale: 8.385   log_noise: -0.524\n",
      "Iter 567/1000 - Loss: 1.776   log_lengthscale: 8.389   log_noise: -0.508\n",
      "Iter 568/1000 - Loss: 1.686   log_lengthscale: 8.392   log_noise: -0.489\n",
      "Iter 569/1000 - Loss: 1.324   log_lengthscale: 8.396   log_noise: -0.470\n",
      "Iter 570/1000 - Loss: 1.702   log_lengthscale: 8.399   log_noise: -0.472\n",
      "Iter 571/1000 - Loss: 1.726   log_lengthscale: 8.402   log_noise: -0.475\n",
      "Iter 572/1000 - Loss: 1.518   log_lengthscale: 8.405   log_noise: -0.480\n",
      "Iter 573/1000 - Loss: 1.912   log_lengthscale: 8.408   log_noise: -0.489\n",
      "Iter 574/1000 - Loss: 1.654   log_lengthscale: 8.411   log_noise: -0.492\n",
      "Iter 575/1000 - Loss: 1.735   log_lengthscale: 8.414   log_noise: -0.493\n",
      "Iter 576/1000 - Loss: 1.709   log_lengthscale: 8.417   log_noise: -0.495\n",
      "Iter 577/1000 - Loss: 1.399   log_lengthscale: 8.419   log_noise: -0.500\n",
      "Iter 578/1000 - Loss: 1.462   log_lengthscale: 8.421   log_noise: -0.513\n",
      "Iter 579/1000 - Loss: 1.161   log_lengthscale: 8.423   log_noise: -0.529\n",
      "Iter 580/1000 - Loss: 1.315   log_lengthscale: 8.426   log_noise: -0.556\n",
      "Iter 581/1000 - Loss: 1.540   log_lengthscale: 8.429   log_noise: -0.577\n",
      "Iter 582/1000 - Loss: 1.419   log_lengthscale: 8.432   log_noise: -0.590\n",
      "Iter 583/1000 - Loss: 1.793   log_lengthscale: 8.436   log_noise: -0.597\n",
      "Iter 584/1000 - Loss: 1.656   log_lengthscale: 8.439   log_noise: -0.589\n",
      "Iter 585/1000 - Loss: 1.522   log_lengthscale: 8.442   log_noise: -0.572\n",
      "Iter 586/1000 - Loss: 1.823   log_lengthscale: 8.444   log_noise: -0.552\n",
      "Iter 587/1000 - Loss: 1.497   log_lengthscale: 8.448   log_noise: -0.519\n",
      "Iter 588/1000 - Loss: 1.442   log_lengthscale: 8.452   log_noise: -0.492\n",
      "Iter 589/1000 - Loss: 1.910   log_lengthscale: 8.456   log_noise: -0.476\n",
      "Iter 590/1000 - Loss: 1.870   log_lengthscale: 8.460   log_noise: -0.458\n",
      "Iter 591/1000 - Loss: 1.539   log_lengthscale: 8.463   log_noise: -0.440\n",
      "Iter 592/1000 - Loss: 1.619   log_lengthscale: 8.466   log_noise: -0.438\n",
      "Iter 593/1000 - Loss: 1.449   log_lengthscale: 8.469   log_noise: -0.447\n",
      "Iter 594/1000 - Loss: 1.513   log_lengthscale: 8.472   log_noise: -0.465\n",
      "Iter 595/1000 - Loss: 1.373   log_lengthscale: 8.475   log_noise: -0.492\n",
      "Iter 596/1000 - Loss: 1.554   log_lengthscale: 8.479   log_noise: -0.527\n",
      "Iter 597/1000 - Loss: 1.852   log_lengthscale: 8.482   log_noise: -0.560\n",
      "Iter 598/1000 - Loss: 1.452   log_lengthscale: 8.485   log_noise: -0.578\n",
      "Iter 599/1000 - Loss: 1.481   log_lengthscale: 8.488   log_noise: -0.588\n",
      "Iter 600/1000 - Loss: 1.621   log_lengthscale: 8.492   log_noise: -0.593\n",
      "Iter 601/1000 - Loss: 1.465   log_lengthscale: 8.496   log_noise: -0.584\n",
      "Iter 602/1000 - Loss: 1.694   log_lengthscale: 8.500   log_noise: -0.573\n",
      "Iter 603/1000 - Loss: 1.579   log_lengthscale: 8.505   log_noise: -0.547\n",
      "Iter 604/1000 - Loss: 1.476   log_lengthscale: 8.510   log_noise: -0.518\n",
      "Iter 605/1000 - Loss: 1.401   log_lengthscale: 8.515   log_noise: -0.494\n",
      "Iter 606/1000 - Loss: 1.763   log_lengthscale: 8.520   log_noise: -0.481\n",
      "Iter 607/1000 - Loss: 1.390   log_lengthscale: 8.524   log_noise: -0.464\n",
      "Iter 608/1000 - Loss: 1.456   log_lengthscale: 8.529   log_noise: -0.460\n",
      "Iter 609/1000 - Loss: 1.793   log_lengthscale: 8.534   log_noise: -0.460\n",
      "Iter 610/1000 - Loss: 1.619   log_lengthscale: 8.539   log_noise: -0.461\n",
      "Iter 611/1000 - Loss: 1.882   log_lengthscale: 8.545   log_noise: -0.467\n",
      "Iter 612/1000 - Loss: 1.384   log_lengthscale: 8.548   log_noise: -0.474\n",
      "Iter 613/1000 - Loss: 1.891   log_lengthscale: 8.553   log_noise: -0.490\n",
      "Iter 614/1000 - Loss: 1.612   log_lengthscale: 8.557   log_noise: -0.498\n",
      "Iter 615/1000 - Loss: 1.657   log_lengthscale: 8.561   log_noise: -0.509\n",
      "Iter 616/1000 - Loss: 1.663   log_lengthscale: 8.564   log_noise: -0.517\n",
      "Iter 617/1000 - Loss: 1.342   log_lengthscale: 8.568   log_noise: -0.521\n",
      "Iter 618/1000 - Loss: 1.406   log_lengthscale: 8.571   log_noise: -0.531\n",
      "Iter 619/1000 - Loss: 2.046   log_lengthscale: 8.575   log_noise: -0.542\n",
      "Iter 620/1000 - Loss: 1.755   log_lengthscale: 8.579   log_noise: -0.534\n",
      "Iter 621/1000 - Loss: 1.454   log_lengthscale: 8.584   log_noise: -0.515\n",
      "Iter 622/1000 - Loss: 1.344   log_lengthscale: 8.587   log_noise: -0.502\n",
      "Iter 623/1000 - Loss: 1.432   log_lengthscale: 8.591   log_noise: -0.495\n",
      "Iter 624/1000 - Loss: 1.496   log_lengthscale: 8.595   log_noise: -0.497\n",
      "Iter 625/1000 - Loss: 1.871   log_lengthscale: 8.598   log_noise: -0.503\n",
      "Iter 626/1000 - Loss: 1.521   log_lengthscale: 8.602   log_noise: -0.501\n",
      "Iter 627/1000 - Loss: 1.479   log_lengthscale: 8.605   log_noise: -0.505\n",
      "Iter 628/1000 - Loss: 1.343   log_lengthscale: 8.608   log_noise: -0.511\n",
      "Iter 629/1000 - Loss: 1.781   log_lengthscale: 8.613   log_noise: -0.518\n",
      "Iter 630/1000 - Loss: 1.523   log_lengthscale: 8.618   log_noise: -0.514\n",
      "Iter 631/1000 - Loss: 1.560   log_lengthscale: 8.623   log_noise: -0.509\n",
      "Iter 632/1000 - Loss: 1.738   log_lengthscale: 8.628   log_noise: -0.506\n",
      "Iter 633/1000 - Loss: 1.456   log_lengthscale: 8.633   log_noise: -0.499\n",
      "Iter 634/1000 - Loss: 1.511   log_lengthscale: 8.637   log_noise: -0.498\n",
      "Iter 635/1000 - Loss: 1.560   log_lengthscale: 8.640   log_noise: -0.503\n",
      "Iter 636/1000 - Loss: 1.545   log_lengthscale: 8.642   log_noise: -0.510\n",
      "Iter 637/1000 - Loss: 2.018   log_lengthscale: 8.644   log_noise: -0.519\n",
      "Iter 638/1000 - Loss: 1.421   log_lengthscale: 8.646   log_noise: -0.513\n",
      "Iter 639/1000 - Loss: 1.416   log_lengthscale: 8.649   log_noise: -0.510\n",
      "Iter 640/1000 - Loss: 1.552   log_lengthscale: 8.650   log_noise: -0.515\n",
      "Iter 641/1000 - Loss: 1.813   log_lengthscale: 8.652   log_noise: -0.517\n",
      "Iter 642/1000 - Loss: 1.615   log_lengthscale: 8.654   log_noise: -0.513\n",
      "Iter 643/1000 - Loss: 1.893   log_lengthscale: 8.656   log_noise: -0.509\n",
      "Iter 644/1000 - Loss: 1.534   log_lengthscale: 8.658   log_noise: -0.501\n",
      "Iter 645/1000 - Loss: 1.652   log_lengthscale: 8.659   log_noise: -0.499\n",
      "Iter 646/1000 - Loss: 1.740   log_lengthscale: 8.661   log_noise: -0.494\n",
      "Iter 647/1000 - Loss: 1.563   log_lengthscale: 8.664   log_noise: -0.488\n",
      "Iter 648/1000 - Loss: 1.672   log_lengthscale: 8.666   log_noise: -0.487\n",
      "Iter 649/1000 - Loss: 1.304   log_lengthscale: 8.668   log_noise: -0.486\n",
      "Iter 650/1000 - Loss: 1.536   log_lengthscale: 8.670   log_noise: -0.497\n",
      "Iter 651/1000 - Loss: 1.550   log_lengthscale: 8.672   log_noise: -0.514\n",
      "Iter 652/1000 - Loss: 1.701   log_lengthscale: 8.675   log_noise: -0.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 653/1000 - Loss: 1.883   log_lengthscale: 8.677   log_noise: -0.535\n",
      "Iter 654/1000 - Loss: 1.522   log_lengthscale: 8.680   log_noise: -0.527\n",
      "Iter 655/1000 - Loss: 1.511   log_lengthscale: 8.684   log_noise: -0.519\n",
      "Iter 656/1000 - Loss: 1.532   log_lengthscale: 8.688   log_noise: -0.513\n",
      "Iter 657/1000 - Loss: 1.592   log_lengthscale: 8.691   log_noise: -0.511\n",
      "Iter 658/1000 - Loss: 1.445   log_lengthscale: 8.695   log_noise: -0.504\n",
      "Iter 659/1000 - Loss: 1.499   log_lengthscale: 8.698   log_noise: -0.502\n",
      "Iter 660/1000 - Loss: 1.380   log_lengthscale: 8.703   log_noise: -0.501\n",
      "Iter 661/1000 - Loss: 1.424   log_lengthscale: 8.707   log_noise: -0.509\n",
      "Iter 662/1000 - Loss: 1.675   log_lengthscale: 8.711   log_noise: -0.520\n",
      "Iter 663/1000 - Loss: 1.597   log_lengthscale: 8.715   log_noise: -0.525\n",
      "Iter 664/1000 - Loss: 1.743   log_lengthscale: 8.719   log_noise: -0.526\n",
      "Iter 665/1000 - Loss: 2.141   log_lengthscale: 8.723   log_noise: -0.521\n",
      "Iter 666/1000 - Loss: 1.316   log_lengthscale: 8.726   log_noise: -0.499\n",
      "Iter 667/1000 - Loss: 1.557   log_lengthscale: 8.729   log_noise: -0.488\n",
      "Iter 668/1000 - Loss: 1.921   log_lengthscale: 8.732   log_noise: -0.484\n",
      "Iter 669/1000 - Loss: 1.521   log_lengthscale: 8.734   log_noise: -0.476\n",
      "Iter 670/1000 - Loss: 1.632   log_lengthscale: 8.736   log_noise: -0.475\n",
      "Iter 671/1000 - Loss: 1.732   log_lengthscale: 8.738   log_noise: -0.477\n",
      "Iter 672/1000 - Loss: 1.918   log_lengthscale: 8.740   log_noise: -0.476\n",
      "Iter 673/1000 - Loss: 1.459   log_lengthscale: 8.743   log_noise: -0.469\n",
      "Iter 674/1000 - Loss: 1.337   log_lengthscale: 8.744   log_noise: -0.476\n",
      "Iter 675/1000 - Loss: 1.647   log_lengthscale: 8.745   log_noise: -0.498\n",
      "Iter 676/1000 - Loss: 1.409   log_lengthscale: 8.747   log_noise: -0.511\n",
      "Iter 677/1000 - Loss: 1.747   log_lengthscale: 8.750   log_noise: -0.527\n",
      "Iter 678/1000 - Loss: 1.635   log_lengthscale: 8.753   log_noise: -0.531\n",
      "Iter 679/1000 - Loss: 1.490   log_lengthscale: 8.757   log_noise: -0.531\n",
      "Iter 680/1000 - Loss: 1.769   log_lengthscale: 8.763   log_noise: -0.516\n",
      "Iter 681/1000 - Loss: 1.525   log_lengthscale: 8.769   log_noise: -0.494\n",
      "Iter 682/1000 - Loss: 1.715   log_lengthscale: 8.774   log_noise: -0.480\n",
      "Iter 683/1000 - Loss: 2.052   log_lengthscale: 8.778   log_noise: -0.474\n",
      "Iter 684/1000 - Loss: 1.429   log_lengthscale: 8.783   log_noise: -0.453\n",
      "Iter 685/1000 - Loss: 1.409   log_lengthscale: 8.788   log_noise: -0.444\n",
      "Iter 686/1000 - Loss: 1.303   log_lengthscale: 8.793   log_noise: -0.447\n",
      "Iter 687/1000 - Loss: 1.264   log_lengthscale: 8.799   log_noise: -0.463\n",
      "Iter 688/1000 - Loss: 1.684   log_lengthscale: 8.805   log_noise: -0.493\n",
      "Iter 689/1000 - Loss: 1.947   log_lengthscale: 8.809   log_noise: -0.523\n",
      "Iter 690/1000 - Loss: 1.720   log_lengthscale: 8.814   log_noise: -0.540\n",
      "Iter 691/1000 - Loss: 1.575   log_lengthscale: 8.817   log_noise: -0.548\n",
      "Iter 692/1000 - Loss: 1.348   log_lengthscale: 8.821   log_noise: -0.555\n",
      "Iter 693/1000 - Loss: 1.665   log_lengthscale: 8.824   log_noise: -0.564\n",
      "Iter 694/1000 - Loss: 1.503   log_lengthscale: 8.827   log_noise: -0.561\n",
      "Iter 695/1000 - Loss: 1.577   log_lengthscale: 8.830   log_noise: -0.555\n",
      "Iter 696/1000 - Loss: 1.276   log_lengthscale: 8.832   log_noise: -0.547\n",
      "Iter 697/1000 - Loss: 1.621   log_lengthscale: 8.833   log_noise: -0.548\n",
      "Iter 698/1000 - Loss: 1.534   log_lengthscale: 8.834   log_noise: -0.542\n",
      "Iter 699/1000 - Loss: 1.509   log_lengthscale: 8.835   log_noise: -0.536\n",
      "Iter 700/1000 - Loss: 1.761   log_lengthscale: 8.837   log_noise: -0.524\n",
      "Iter 701/1000 - Loss: 1.706   log_lengthscale: 8.839   log_noise: -0.510\n",
      "Iter 702/1000 - Loss: 1.788   log_lengthscale: 8.839   log_noise: -0.496\n",
      "Iter 703/1000 - Loss: 1.452   log_lengthscale: 8.840   log_noise: -0.473\n",
      "Iter 704/1000 - Loss: 1.476   log_lengthscale: 8.842   log_noise: -0.459\n",
      "Iter 705/1000 - Loss: 1.844   log_lengthscale: 8.843   log_noise: -0.460\n",
      "Iter 706/1000 - Loss: 1.492   log_lengthscale: 8.844   log_noise: -0.457\n",
      "Iter 707/1000 - Loss: 1.554   log_lengthscale: 8.846   log_noise: -0.459\n",
      "Iter 708/1000 - Loss: 1.474   log_lengthscale: 8.848   log_noise: -0.466\n",
      "Iter 709/1000 - Loss: 1.503   log_lengthscale: 8.850   log_noise: -0.480\n",
      "Iter 710/1000 - Loss: 1.947   log_lengthscale: 8.853   log_noise: -0.497\n",
      "Iter 711/1000 - Loss: 1.416   log_lengthscale: 8.855   log_noise: -0.504\n",
      "Iter 712/1000 - Loss: 1.518   log_lengthscale: 8.857   log_noise: -0.520\n",
      "Iter 713/1000 - Loss: 1.572   log_lengthscale: 8.858   log_noise: -0.538\n",
      "Iter 714/1000 - Loss: 1.556   log_lengthscale: 8.859   log_noise: -0.550\n",
      "Iter 715/1000 - Loss: 1.463   log_lengthscale: 8.861   log_noise: -0.549\n",
      "Iter 716/1000 - Loss: 1.652   log_lengthscale: 8.864   log_noise: -0.545\n",
      "Iter 717/1000 - Loss: 1.581   log_lengthscale: 8.866   log_noise: -0.536\n",
      "Iter 718/1000 - Loss: 1.577   log_lengthscale: 8.868   log_noise: -0.524\n",
      "Iter 719/1000 - Loss: 1.821   log_lengthscale: 8.872   log_noise: -0.504\n",
      "Iter 720/1000 - Loss: 1.841   log_lengthscale: 8.876   log_noise: -0.478\n",
      "Iter 721/1000 - Loss: 1.700   log_lengthscale: 8.879   log_noise: -0.456\n",
      "Iter 722/1000 - Loss: 1.705   log_lengthscale: 8.882   log_noise: -0.436\n",
      "Iter 723/1000 - Loss: 1.564   log_lengthscale: 8.885   log_noise: -0.427\n",
      "Iter 724/1000 - Loss: 1.728   log_lengthscale: 8.888   log_noise: -0.427\n",
      "Iter 725/1000 - Loss: 1.681   log_lengthscale: 8.890   log_noise: -0.437\n",
      "Iter 726/1000 - Loss: 1.463   log_lengthscale: 8.892   log_noise: -0.453\n",
      "Iter 727/1000 - Loss: 1.681   log_lengthscale: 8.894   log_noise: -0.479\n",
      "Iter 728/1000 - Loss: 1.534   log_lengthscale: 8.894   log_noise: -0.509\n",
      "Iter 729/1000 - Loss: 1.637   log_lengthscale: 8.894   log_noise: -0.539\n",
      "Iter 730/1000 - Loss: 1.416   log_lengthscale: 8.894   log_noise: -0.560\n",
      "Iter 731/1000 - Loss: 2.020   log_lengthscale: 8.894   log_noise: -0.577\n",
      "Iter 732/1000 - Loss: 1.614   log_lengthscale: 8.895   log_noise: -0.564\n",
      "Iter 733/1000 - Loss: 1.442   log_lengthscale: 8.896   log_noise: -0.544\n",
      "Iter 734/1000 - Loss: 2.284   log_lengthscale: 8.897   log_noise: -0.524\n",
      "Iter 735/1000 - Loss: 1.295   log_lengthscale: 8.897   log_noise: -0.483\n",
      "Iter 736/1000 - Loss: 1.454   log_lengthscale: 8.898   log_noise: -0.459\n",
      "Iter 737/1000 - Loss: 1.660   log_lengthscale: 8.899   log_noise: -0.445\n",
      "Iter 738/1000 - Loss: 1.452   log_lengthscale: 8.901   log_noise: -0.439\n",
      "Iter 739/1000 - Loss: 1.446   log_lengthscale: 8.901   log_noise: -0.450\n",
      "Iter 740/1000 - Loss: 1.235   log_lengthscale: 8.903   log_noise: -0.469\n",
      "Iter 741/1000 - Loss: 1.692   log_lengthscale: 8.903   log_noise: -0.507\n",
      "Iter 742/1000 - Loss: 1.500   log_lengthscale: 8.904   log_noise: -0.542\n",
      "Iter 743/1000 - Loss: 1.549   log_lengthscale: 8.904   log_noise: -0.571\n",
      "Iter 744/1000 - Loss: 1.474   log_lengthscale: 8.903   log_noise: -0.593\n",
      "Iter 745/1000 - Loss: 1.716   log_lengthscale: 8.903   log_noise: -0.603\n",
      "Iter 746/1000 - Loss: 1.738   log_lengthscale: 8.904   log_noise: -0.593\n",
      "Iter 747/1000 - Loss: 1.925   log_lengthscale: 8.904   log_noise: -0.572\n",
      "Iter 748/1000 - Loss: 1.415   log_lengthscale: 8.904   log_noise: -0.535\n",
      "Iter 749/1000 - Loss: 1.856   log_lengthscale: 8.903   log_noise: -0.503\n",
      "Iter 750/1000 - Loss: 1.706   log_lengthscale: 8.903   log_noise: -0.467\n",
      "Iter 751/1000 - Loss: 1.742   log_lengthscale: 8.904   log_noise: -0.436\n",
      "Iter 752/1000 - Loss: 1.556   log_lengthscale: 8.905   log_noise: -0.407\n",
      "Iter 753/1000 - Loss: 1.589   log_lengthscale: 8.906   log_noise: -0.393\n",
      "Iter 754/1000 - Loss: 1.970   log_lengthscale: 8.910   log_noise: -0.384\n",
      "Iter 755/1000 - Loss: 1.491   log_lengthscale: 8.913   log_noise: -0.381\n",
      "Iter 756/1000 - Loss: 1.805   log_lengthscale: 8.916   log_noise: -0.395\n",
      "Iter 757/1000 - Loss: 1.677   log_lengthscale: 8.919   log_noise: -0.416\n",
      "Iter 758/1000 - Loss: 1.637   log_lengthscale: 8.921   log_noise: -0.447\n",
      "Iter 759/1000 - Loss: 1.347   log_lengthscale: 8.923   log_noise: -0.479\n",
      "Iter 760/1000 - Loss: 1.478   log_lengthscale: 8.925   log_noise: -0.518\n",
      "Iter 761/1000 - Loss: 1.449   log_lengthscale: 8.927   log_noise: -0.555\n",
      "Iter 762/1000 - Loss: 1.655   log_lengthscale: 8.931   log_noise: -0.579\n",
      "Iter 763/1000 - Loss: 1.351   log_lengthscale: 8.935   log_noise: -0.587\n",
      "Iter 764/1000 - Loss: 1.433   log_lengthscale: 8.938   log_noise: -0.593\n",
      "Iter 765/1000 - Loss: 1.816   log_lengthscale: 8.942   log_noise: -0.591\n",
      "Iter 766/1000 - Loss: 1.672   log_lengthscale: 8.946   log_noise: -0.566\n",
      "Iter 767/1000 - Loss: 1.434   log_lengthscale: 8.949   log_noise: -0.535\n",
      "Iter 768/1000 - Loss: 1.728   log_lengthscale: 8.953   log_noise: -0.508\n",
      "Iter 769/1000 - Loss: 1.435   log_lengthscale: 8.956   log_noise: -0.479\n",
      "Iter 770/1000 - Loss: 1.676   log_lengthscale: 8.960   log_noise: -0.456\n",
      "Iter 771/1000 - Loss: 1.969   log_lengthscale: 8.964   log_noise: -0.439\n",
      "Iter 772/1000 - Loss: 1.655   log_lengthscale: 8.967   log_noise: -0.420\n",
      "Iter 773/1000 - Loss: 1.520   log_lengthscale: 8.969   log_noise: -0.414\n",
      "Iter 774/1000 - Loss: 1.682   log_lengthscale: 8.971   log_noise: -0.420\n",
      "Iter 775/1000 - Loss: 1.498   log_lengthscale: 8.973   log_noise: -0.436\n",
      "Iter 776/1000 - Loss: 1.433   log_lengthscale: 8.975   log_noise: -0.463\n",
      "Iter 777/1000 - Loss: 1.641   log_lengthscale: 8.976   log_noise: -0.501\n",
      "Iter 778/1000 - Loss: 1.505   log_lengthscale: 8.977   log_noise: -0.535\n",
      "Iter 779/1000 - Loss: 1.570   log_lengthscale: 8.977   log_noise: -0.567\n",
      "Iter 780/1000 - Loss: 1.462   log_lengthscale: 8.977   log_noise: -0.593\n",
      "Iter 781/1000 - Loss: 1.834   log_lengthscale: 8.977   log_noise: -0.605\n",
      "Iter 782/1000 - Loss: 1.644   log_lengthscale: 8.978   log_noise: -0.593\n",
      "Iter 783/1000 - Loss: 1.689   log_lengthscale: 8.979   log_noise: -0.568\n",
      "Iter 784/1000 - Loss: 1.568   log_lengthscale: 8.980   log_noise: -0.533\n",
      "Iter 785/1000 - Loss: 1.778   log_lengthscale: 8.982   log_noise: -0.491\n",
      "Iter 786/1000 - Loss: 1.611   log_lengthscale: 8.985   log_noise: -0.450\n",
      "Iter 787/1000 - Loss: 1.516   log_lengthscale: 8.988   log_noise: -0.415\n",
      "Iter 788/1000 - Loss: 1.503   log_lengthscale: 8.991   log_noise: -0.397\n",
      "Iter 789/1000 - Loss: 1.815   log_lengthscale: 8.995   log_noise: -0.392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 790/1000 - Loss: 1.806   log_lengthscale: 8.998   log_noise: -0.394\n",
      "Iter 791/1000 - Loss: 1.673   log_lengthscale: 9.002   log_noise: -0.398\n",
      "Iter 792/1000 - Loss: 1.439   log_lengthscale: 9.005   log_noise: -0.415\n",
      "Iter 793/1000 - Loss: 1.593   log_lengthscale: 9.008   log_noise: -0.445\n",
      "Iter 794/1000 - Loss: 1.578   log_lengthscale: 9.011   log_noise: -0.477\n",
      "Iter 795/1000 - Loss: 1.692   log_lengthscale: 9.014   log_noise: -0.507\n",
      "Iter 796/1000 - Loss: 2.001   log_lengthscale: 9.015   log_noise: -0.533\n",
      "Iter 797/1000 - Loss: 1.855   log_lengthscale: 9.016   log_noise: -0.540\n",
      "Iter 798/1000 - Loss: 1.648   log_lengthscale: 9.018   log_noise: -0.529\n",
      "Iter 799/1000 - Loss: 1.420   log_lengthscale: 9.021   log_noise: -0.511\n",
      "Iter 800/1000 - Loss: 1.468   log_lengthscale: 9.024   log_noise: -0.498\n",
      "Iter 801/1000 - Loss: 1.491   log_lengthscale: 9.025   log_noise: -0.495\n",
      "Iter 802/1000 - Loss: 1.772   log_lengthscale: 9.026   log_noise: -0.497\n",
      "Iter 803/1000 - Loss: 1.249   log_lengthscale: 9.027   log_noise: -0.496\n",
      "Iter 804/1000 - Loss: 1.654   log_lengthscale: 9.027   log_noise: -0.510\n",
      "Iter 805/1000 - Loss: 2.160   log_lengthscale: 9.027   log_noise: -0.515\n",
      "Iter 806/1000 - Loss: 1.549   log_lengthscale: 9.029   log_noise: -0.500\n",
      "Iter 807/1000 - Loss: 1.426   log_lengthscale: 9.030   log_noise: -0.487\n",
      "Iter 808/1000 - Loss: 1.975   log_lengthscale: 9.031   log_noise: -0.478\n",
      "Iter 809/1000 - Loss: 1.568   log_lengthscale: 9.032   log_noise: -0.462\n",
      "Iter 810/1000 - Loss: 1.455   log_lengthscale: 9.033   log_noise: -0.455\n",
      "Iter 811/1000 - Loss: 1.710   log_lengthscale: 9.032   log_noise: -0.460\n",
      "Iter 812/1000 - Loss: 2.010   log_lengthscale: 9.033   log_noise: -0.465\n",
      "Iter 813/1000 - Loss: 1.380   log_lengthscale: 9.033   log_noise: -0.466\n",
      "Iter 814/1000 - Loss: 1.742   log_lengthscale: 9.033   log_noise: -0.476\n",
      "Iter 815/1000 - Loss: 1.614   log_lengthscale: 9.033   log_noise: -0.483\n",
      "Iter 816/1000 - Loss: 1.573   log_lengthscale: 9.033   log_noise: -0.494\n",
      "Iter 817/1000 - Loss: 1.734   log_lengthscale: 9.034   log_noise: -0.501\n",
      "Iter 818/1000 - Loss: 1.648   log_lengthscale: 9.034   log_noise: -0.507\n",
      "Iter 819/1000 - Loss: 1.489   log_lengthscale: 9.034   log_noise: -0.510\n",
      "Iter 820/1000 - Loss: 1.465   log_lengthscale: 9.033   log_noise: -0.518\n",
      "Iter 821/1000 - Loss: 1.796   log_lengthscale: 9.033   log_noise: -0.528\n",
      "Iter 822/1000 - Loss: 1.421   log_lengthscale: 9.032   log_noise: -0.527\n",
      "Iter 823/1000 - Loss: 1.485   log_lengthscale: 9.031   log_noise: -0.529\n",
      "Iter 824/1000 - Loss: 1.664   log_lengthscale: 9.031   log_noise: -0.532\n",
      "Iter 825/1000 - Loss: 1.996   log_lengthscale: 9.030   log_noise: -0.531\n",
      "Iter 826/1000 - Loss: 1.435   log_lengthscale: 9.030   log_noise: -0.511\n",
      "Iter 827/1000 - Loss: 1.458   log_lengthscale: 9.030   log_noise: -0.501\n",
      "Iter 828/1000 - Loss: 1.668   log_lengthscale: 9.029   log_noise: -0.494\n",
      "Iter 829/1000 - Loss: 1.376   log_lengthscale: 9.029   log_noise: -0.488\n",
      "Iter 830/1000 - Loss: 1.585   log_lengthscale: 9.028   log_noise: -0.495\n",
      "Iter 831/1000 - Loss: 1.425   log_lengthscale: 9.026   log_noise: -0.504\n",
      "Iter 832/1000 - Loss: 1.388   log_lengthscale: 9.025   log_noise: -0.518\n",
      "Iter 833/1000 - Loss: 1.446   log_lengthscale: 9.024   log_noise: -0.535\n",
      "Iter 834/1000 - Loss: 1.521   log_lengthscale: 9.024   log_noise: -0.549\n",
      "Iter 835/1000 - Loss: 1.384   log_lengthscale: 9.024   log_noise: -0.555\n",
      "Iter 836/1000 - Loss: 1.558   log_lengthscale: 9.024   log_noise: -0.562\n",
      "Iter 837/1000 - Loss: 1.686   log_lengthscale: 9.023   log_noise: -0.564\n",
      "Iter 838/1000 - Loss: 1.578   log_lengthscale: 9.022   log_noise: -0.550\n",
      "Iter 839/1000 - Loss: 1.782   log_lengthscale: 9.021   log_noise: -0.533\n",
      "Iter 840/1000 - Loss: 1.829   log_lengthscale: 9.020   log_noise: -0.510\n",
      "Iter 841/1000 - Loss: 1.630   log_lengthscale: 9.019   log_noise: -0.481\n",
      "Iter 842/1000 - Loss: 1.620   log_lengthscale: 9.018   log_noise: -0.457\n",
      "Iter 843/1000 - Loss: 1.416   log_lengthscale: 9.017   log_noise: -0.444\n",
      "Iter 844/1000 - Loss: 1.565   log_lengthscale: 9.017   log_noise: -0.440\n",
      "Iter 845/1000 - Loss: 1.335   log_lengthscale: 9.019   log_noise: -0.444\n",
      "Iter 846/1000 - Loss: 1.559   log_lengthscale: 9.020   log_noise: -0.459\n",
      "Iter 847/1000 - Loss: 1.602   log_lengthscale: 9.023   log_noise: -0.480\n",
      "Iter 848/1000 - Loss: 1.299   log_lengthscale: 9.024   log_noise: -0.503\n",
      "Iter 849/1000 - Loss: 1.879   log_lengthscale: 9.026   log_noise: -0.533\n",
      "Iter 850/1000 - Loss: 1.398   log_lengthscale: 9.027   log_noise: -0.548\n",
      "Iter 851/1000 - Loss: 1.611   log_lengthscale: 9.029   log_noise: -0.561\n",
      "Iter 852/1000 - Loss: 1.475   log_lengthscale: 9.030   log_noise: -0.564\n",
      "Iter 853/1000 - Loss: 1.648   log_lengthscale: 9.032   log_noise: -0.560\n",
      "Iter 854/1000 - Loss: 1.888   log_lengthscale: 9.033   log_noise: -0.549\n",
      "Iter 855/1000 - Loss: 1.508   log_lengthscale: 9.034   log_noise: -0.526\n",
      "Iter 856/1000 - Loss: 1.971   log_lengthscale: 9.033   log_noise: -0.507\n",
      "Iter 857/1000 - Loss: 1.402   log_lengthscale: 9.033   log_noise: -0.479\n",
      "Iter 858/1000 - Loss: 2.298   log_lengthscale: 9.033   log_noise: -0.463\n",
      "Iter 859/1000 - Loss: 1.591   log_lengthscale: 9.033   log_noise: -0.431\n",
      "Iter 860/1000 - Loss: 1.496   log_lengthscale: 9.033   log_noise: -0.409\n",
      "Iter 861/1000 - Loss: 1.409   log_lengthscale: 9.034   log_noise: -0.402\n",
      "Iter 862/1000 - Loss: 2.055   log_lengthscale: 9.036   log_noise: -0.411\n",
      "Iter 863/1000 - Loss: 1.615   log_lengthscale: 9.038   log_noise: -0.417\n",
      "Iter 864/1000 - Loss: 1.506   log_lengthscale: 9.039   log_noise: -0.435\n",
      "Iter 865/1000 - Loss: 1.528   log_lengthscale: 9.039   log_noise: -0.464\n",
      "Iter 866/1000 - Loss: 1.532   log_lengthscale: 9.039   log_noise: -0.499\n",
      "Iter 867/1000 - Loss: 1.974   log_lengthscale: 9.038   log_noise: -0.537\n",
      "Iter 868/1000 - Loss: 1.439   log_lengthscale: 9.037   log_noise: -0.555\n",
      "Iter 869/1000 - Loss: 1.592   log_lengthscale: 9.037   log_noise: -0.563\n",
      "Iter 870/1000 - Loss: 2.226   log_lengthscale: 9.036   log_noise: -0.563\n",
      "Iter 871/1000 - Loss: 1.864   log_lengthscale: 9.035   log_noise: -0.536\n",
      "Iter 872/1000 - Loss: 1.420   log_lengthscale: 9.034   log_noise: -0.498\n",
      "Iter 873/1000 - Loss: 1.415   log_lengthscale: 9.033   log_noise: -0.472\n",
      "Iter 874/1000 - Loss: 1.483   log_lengthscale: 9.031   log_noise: -0.461\n",
      "Iter 875/1000 - Loss: 1.554   log_lengthscale: 9.030   log_noise: -0.458\n",
      "Iter 876/1000 - Loss: 1.578   log_lengthscale: 9.029   log_noise: -0.463\n",
      "Iter 877/1000 - Loss: 1.243   log_lengthscale: 9.028   log_noise: -0.474\n",
      "Iter 878/1000 - Loss: 1.551   log_lengthscale: 9.027   log_noise: -0.498\n",
      "Iter 879/1000 - Loss: 2.028   log_lengthscale: 9.027   log_noise: -0.514\n",
      "Iter 880/1000 - Loss: 1.378   log_lengthscale: 9.028   log_noise: -0.515\n",
      "Iter 881/1000 - Loss: 1.561   log_lengthscale: 9.030   log_noise: -0.517\n",
      "Iter 882/1000 - Loss: 1.442   log_lengthscale: 9.032   log_noise: -0.517\n",
      "Iter 883/1000 - Loss: 1.754   log_lengthscale: 9.033   log_noise: -0.519\n",
      "Iter 884/1000 - Loss: 1.515   log_lengthscale: 9.036   log_noise: -0.505\n",
      "Iter 885/1000 - Loss: 1.482   log_lengthscale: 9.041   log_noise: -0.488\n",
      "Iter 886/1000 - Loss: 1.585   log_lengthscale: 9.045   log_noise: -0.477\n",
      "Iter 887/1000 - Loss: 1.539   log_lengthscale: 9.048   log_noise: -0.473\n",
      "Iter 888/1000 - Loss: 1.515   log_lengthscale: 9.051   log_noise: -0.477\n",
      "Iter 889/1000 - Loss: 1.367   log_lengthscale: 9.053   log_noise: -0.489\n",
      "Iter 890/1000 - Loss: 1.784   log_lengthscale: 9.054   log_noise: -0.509\n",
      "Iter 891/1000 - Loss: 1.439   log_lengthscale: 9.055   log_noise: -0.522\n",
      "Iter 892/1000 - Loss: 1.858   log_lengthscale: 9.057   log_noise: -0.536\n",
      "Iter 893/1000 - Loss: 1.386   log_lengthscale: 9.058   log_noise: -0.533\n",
      "Iter 894/1000 - Loss: 1.711   log_lengthscale: 9.059   log_noise: -0.536\n",
      "Iter 895/1000 - Loss: 1.489   log_lengthscale: 9.060   log_noise: -0.526\n",
      "Iter 896/1000 - Loss: 1.317   log_lengthscale: 9.062   log_noise: -0.515\n",
      "Iter 897/1000 - Loss: 1.323   log_lengthscale: 9.063   log_noise: -0.510\n",
      "Iter 898/1000 - Loss: 1.451   log_lengthscale: 9.065   log_noise: -0.510\n",
      "Iter 899/1000 - Loss: 1.422   log_lengthscale: 9.067   log_noise: -0.516\n",
      "Iter 900/1000 - Loss: 1.513   log_lengthscale: 9.069   log_noise: -0.522\n",
      "Iter 901/1000 - Loss: 1.725   log_lengthscale: 9.071   log_noise: -0.527\n",
      "Iter 902/1000 - Loss: 1.679   log_lengthscale: 9.073   log_noise: -0.524\n",
      "Iter 903/1000 - Loss: 1.496   log_lengthscale: 9.075   log_noise: -0.519\n",
      "Iter 904/1000 - Loss: 1.699   log_lengthscale: 9.077   log_noise: -0.512\n",
      "Iter 905/1000 - Loss: 1.311   log_lengthscale: 9.078   log_noise: -0.503\n",
      "Iter 906/1000 - Loss: 1.638   log_lengthscale: 9.079   log_noise: -0.506\n",
      "Iter 907/1000 - Loss: 1.676   log_lengthscale: 9.078   log_noise: -0.512\n",
      "Iter 908/1000 - Loss: 1.525   log_lengthscale: 9.077   log_noise: -0.517\n",
      "Iter 909/1000 - Loss: 1.369   log_lengthscale: 9.075   log_noise: -0.521\n",
      "Iter 910/1000 - Loss: 2.023   log_lengthscale: 9.075   log_noise: -0.522\n",
      "Iter 911/1000 - Loss: 1.519   log_lengthscale: 9.074   log_noise: -0.507\n",
      "Iter 912/1000 - Loss: 1.251   log_lengthscale: 9.074   log_noise: -0.494\n",
      "Iter 913/1000 - Loss: 1.547   log_lengthscale: 9.073   log_noise: -0.495\n",
      "Iter 914/1000 - Loss: 1.456   log_lengthscale: 9.072   log_noise: -0.501\n",
      "Iter 915/1000 - Loss: 1.589   log_lengthscale: 9.071   log_noise: -0.510\n",
      "Iter 916/1000 - Loss: 1.552   log_lengthscale: 9.069   log_noise: -0.519\n",
      "Iter 917/1000 - Loss: 1.579   log_lengthscale: 9.068   log_noise: -0.526\n",
      "Iter 918/1000 - Loss: 1.422   log_lengthscale: 9.066   log_noise: -0.530\n",
      "Iter 919/1000 - Loss: 1.972   log_lengthscale: 9.065   log_noise: -0.532\n",
      "Iter 920/1000 - Loss: 1.723   log_lengthscale: 9.063   log_noise: -0.520\n",
      "Iter 921/1000 - Loss: 1.857   log_lengthscale: 9.062   log_noise: -0.500\n",
      "Iter 922/1000 - Loss: 1.726   log_lengthscale: 9.061   log_noise: -0.475\n",
      "Iter 923/1000 - Loss: 1.645   log_lengthscale: 9.060   log_noise: -0.450\n",
      "Iter 924/1000 - Loss: 1.747   log_lengthscale: 9.059   log_noise: -0.432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 925/1000 - Loss: 1.960   log_lengthscale: 9.058   log_noise: -0.421\n",
      "Iter 926/1000 - Loss: 1.520   log_lengthscale: 9.057   log_noise: -0.409\n",
      "Iter 927/1000 - Loss: 1.500   log_lengthscale: 9.057   log_noise: -0.412\n",
      "Iter 928/1000 - Loss: 1.535   log_lengthscale: 9.057   log_noise: -0.429\n",
      "Iter 929/1000 - Loss: 1.658   log_lengthscale: 9.058   log_noise: -0.453\n",
      "Iter 930/1000 - Loss: 1.776   log_lengthscale: 9.058   log_noise: -0.478\n",
      "Iter 931/1000 - Loss: 1.835   log_lengthscale: 9.059   log_noise: -0.499\n",
      "Iter 932/1000 - Loss: 1.400   log_lengthscale: 9.060   log_noise: -0.513\n",
      "Iter 933/1000 - Loss: 1.535   log_lengthscale: 9.061   log_noise: -0.529\n",
      "Iter 934/1000 - Loss: 1.623   log_lengthscale: 9.062   log_noise: -0.538\n",
      "Iter 935/1000 - Loss: 1.535   log_lengthscale: 9.064   log_noise: -0.537\n",
      "Iter 936/1000 - Loss: 1.576   log_lengthscale: 9.067   log_noise: -0.531\n",
      "Iter 937/1000 - Loss: 1.426   log_lengthscale: 9.068   log_noise: -0.523\n",
      "Iter 938/1000 - Loss: 1.706   log_lengthscale: 9.069   log_noise: -0.520\n",
      "Iter 939/1000 - Loss: 1.840   log_lengthscale: 9.070   log_noise: -0.511\n",
      "Iter 940/1000 - Loss: 2.020   log_lengthscale: 9.070   log_noise: -0.496\n",
      "Iter 941/1000 - Loss: 1.410   log_lengthscale: 9.071   log_noise: -0.466\n",
      "Iter 942/1000 - Loss: 1.791   log_lengthscale: 9.072   log_noise: -0.448\n",
      "Iter 943/1000 - Loss: 1.759   log_lengthscale: 9.074   log_noise: -0.431\n",
      "Iter 944/1000 - Loss: 1.628   log_lengthscale: 9.075   log_noise: -0.421\n",
      "Iter 945/1000 - Loss: 1.763   log_lengthscale: 9.075   log_noise: -0.423\n",
      "Iter 946/1000 - Loss: 1.583   log_lengthscale: 9.077   log_noise: -0.425\n",
      "Iter 947/1000 - Loss: 1.852   log_lengthscale: 9.079   log_noise: -0.433\n",
      "Iter 948/1000 - Loss: 2.058   log_lengthscale: 9.081   log_noise: -0.442\n",
      "Iter 949/1000 - Loss: 1.569   log_lengthscale: 9.082   log_noise: -0.446\n",
      "Iter 950/1000 - Loss: 1.476   log_lengthscale: 9.083   log_noise: -0.460\n",
      "Iter 951/1000 - Loss: 1.730   log_lengthscale: 9.084   log_noise: -0.481\n",
      "Iter 952/1000 - Loss: 1.613   log_lengthscale: 9.085   log_noise: -0.498\n",
      "Iter 953/1000 - Loss: 1.590   log_lengthscale: 9.085   log_noise: -0.516\n",
      "Iter 954/1000 - Loss: 1.512   log_lengthscale: 9.086   log_noise: -0.530\n",
      "Iter 955/1000 - Loss: 1.462   log_lengthscale: 9.086   log_noise: -0.542\n",
      "Iter 956/1000 - Loss: 2.084   log_lengthscale: 9.086   log_noise: -0.551\n",
      "Iter 957/1000 - Loss: 1.371   log_lengthscale: 9.087   log_noise: -0.537\n",
      "Iter 958/1000 - Loss: 1.720   log_lengthscale: 9.087   log_noise: -0.526\n",
      "Iter 959/1000 - Loss: 1.578   log_lengthscale: 9.089   log_noise: -0.505\n",
      "Iter 960/1000 - Loss: 2.055   log_lengthscale: 9.090   log_noise: -0.487\n",
      "Iter 961/1000 - Loss: 1.686   log_lengthscale: 9.091   log_noise: -0.457\n",
      "Iter 962/1000 - Loss: 1.428   log_lengthscale: 9.093   log_noise: -0.430\n",
      "Iter 963/1000 - Loss: 1.693   log_lengthscale: 9.095   log_noise: -0.423\n",
      "Iter 964/1000 - Loss: 1.482   log_lengthscale: 9.095   log_noise: -0.426\n",
      "Iter 965/1000 - Loss: 1.684   log_lengthscale: 9.097   log_noise: -0.441\n",
      "Iter 966/1000 - Loss: 1.418   log_lengthscale: 9.098   log_noise: -0.460\n",
      "Iter 967/1000 - Loss: 1.479   log_lengthscale: 9.098   log_noise: -0.487\n",
      "Iter 968/1000 - Loss: 1.435   log_lengthscale: 9.099   log_noise: -0.520\n",
      "Iter 969/1000 - Loss: 1.807   log_lengthscale: 9.099   log_noise: -0.553\n",
      "Iter 970/1000 - Loss: 1.581   log_lengthscale: 9.099   log_noise: -0.571\n",
      "Iter 971/1000 - Loss: 1.796   log_lengthscale: 9.099   log_noise: -0.574\n",
      "Iter 972/1000 - Loss: 1.447   log_lengthscale: 9.100   log_noise: -0.560\n",
      "Iter 973/1000 - Loss: 1.643   log_lengthscale: 9.100   log_noise: -0.548\n",
      "Iter 974/1000 - Loss: 1.546   log_lengthscale: 9.101   log_noise: -0.525\n",
      "Iter 975/1000 - Loss: 1.779   log_lengthscale: 9.101   log_noise: -0.507\n",
      "Iter 976/1000 - Loss: 1.442   log_lengthscale: 9.101   log_noise: -0.486\n",
      "Iter 977/1000 - Loss: 1.482   log_lengthscale: 9.100   log_noise: -0.477\n",
      "Iter 978/1000 - Loss: 1.706   log_lengthscale: 9.100   log_noise: -0.477\n",
      "Iter 979/1000 - Loss: 1.427   log_lengthscale: 9.099   log_noise: -0.479\n",
      "Iter 980/1000 - Loss: 1.463   log_lengthscale: 9.099   log_noise: -0.489\n",
      "Iter 981/1000 - Loss: 1.831   log_lengthscale: 9.098   log_noise: -0.506\n",
      "Iter 982/1000 - Loss: 1.503   log_lengthscale: 9.097   log_noise: -0.512\n",
      "Iter 983/1000 - Loss: 1.665   log_lengthscale: 9.097   log_noise: -0.513\n",
      "Iter 984/1000 - Loss: 1.485   log_lengthscale: 9.096   log_noise: -0.513\n",
      "Iter 985/1000 - Loss: 1.330   log_lengthscale: 9.095   log_noise: -0.517\n",
      "Iter 986/1000 - Loss: 1.784   log_lengthscale: 9.093   log_noise: -0.529\n",
      "Iter 987/1000 - Loss: 1.704   log_lengthscale: 9.092   log_noise: -0.530\n",
      "Iter 988/1000 - Loss: 1.639   log_lengthscale: 9.090   log_noise: -0.522\n",
      "Iter 989/1000 - Loss: 1.944   log_lengthscale: 9.089   log_noise: -0.510\n",
      "Iter 990/1000 - Loss: 1.775   log_lengthscale: 9.087   log_noise: -0.489\n",
      "Iter 991/1000 - Loss: 1.606   log_lengthscale: 9.085   log_noise: -0.467\n",
      "Iter 992/1000 - Loss: 1.781   log_lengthscale: 9.083   log_noise: -0.450\n",
      "Iter 993/1000 - Loss: 1.430   log_lengthscale: 9.080   log_noise: -0.440\n",
      "Iter 994/1000 - Loss: 1.642   log_lengthscale: 9.078   log_noise: -0.445\n",
      "Iter 995/1000 - Loss: 1.440   log_lengthscale: 9.077   log_noise: -0.454\n",
      "Iter 996/1000 - Loss: 1.529   log_lengthscale: 9.076   log_noise: -0.473\n",
      "Iter 997/1000 - Loss: 1.628   log_lengthscale: 9.075   log_noise: -0.498\n",
      "Iter 998/1000 - Loss: 1.585   log_lengthscale: 9.073   log_noise: -0.524\n",
      "Iter 999/1000 - Loss: 1.395   log_lengthscale: 9.071   log_noise: -0.544\n",
      "Iter 1000/1000 - Loss: 1.642   log_lengthscale: 9.068   log_noise: -0.563\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iter = 1000\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(x_tensor)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   log_lengthscale: %.3f   log_noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.data[0],\n",
    "        model.covar_module.log_lengthscale.data[0, 0],\n",
    "        model.likelihood.log_noise.data[0]\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The input matches the stored training data. Did you forget to call model.train()?\n",
      "/home/lerko/anaconda3/lib/python3.6/site-packages/gpytorch/functions/add_diag.py:14: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  val = diag.squeeze()[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (89,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-30e95647551a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Plot the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0max_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobserved_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Observed Values (Likelihood)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-30e95647551a>\u001b[0m in \u001b[0;36max_plot\u001b[0;34m(ax, rand_var, title)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'k*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Plot predictive means as blue line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Shade between the lower and upper confidence bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_between\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lerko/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lerko/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lerko/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lerko/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lerko/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 244\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (89,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARAAAADFCAYAAACcjq09AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e8d544e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put model and likelihood into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Initialize plot\n",
    "f, observed_ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "# Test points are regularly spaced along [0,1] every 0.02\n",
    "# Make predictions by feeding model through likelihood\n",
    "with gpytorch.fast_pred_var():\n",
    "    observed_pred = likelihood(model(x_tensor))\n",
    "\n",
    "# Define plotting function\n",
    "def ax_plot(ax, rand_var, title):\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = rand_var.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(train_x.data.numpy(), train_y.data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(x_tensor.data.numpy(), rand_var.mean().data.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.data.numpy(), lower.data.numpy(), upper.data.numpy(), alpha=0.5)\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n",
    "    ax.set_title(title)\n",
    "# Plot the predictions\n",
    "ax_plot(observed_ax, observed_pred, 'Observed Values (Likelihood)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_pred.mean().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6e2c471dd8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAD9CAYAAABjqXpxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e2c4e40f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(observed_pred.mean().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
